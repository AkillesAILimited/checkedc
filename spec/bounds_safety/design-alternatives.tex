% !Tex root = checkedc.tex

\chapter{Design choices considered but not chosen}
\label{chapter:design-alternatives}

\section{Removing relative alignment}
\label{section:design-alternatives:always-unaligned}

We consider removing the concept of relative alignment from the design to simplify
the design.  Relative alignment is described in Sections~\ref{section:relative-alignment}
and~\ref{section:pointer-cast-results}.  If relative alignment
is removed, however, the compiler has to assume that bounds and pointers are
not relatively aligned.   This would result in more costly bounds checks
as well as significantly more bounds checks in optimized code.

Checks against upper bounds would  take several more instructions.
Given a pointer \var{p} to type \var{T}, \texttt{*\var{p}} accesses the memory from
\var{p} to \texttt{\var{p} + sizeof(\var{T}) - 1}. Given an upper bound \var{ub}, the
upper bounds check for \var{p} becomes \texttt{\var{p} + sizeof(\var{T}) - 1 < \var{ub}},
not \texttt{\var{p} < \var{ub}}.  The
computation of \texttt{\var{p} + sizeof(\var{T}) - 1} would need an overflow check also, 
so there would typically be several extra instructions added to an upper bounds check, 
not just an extra addition.

There will also be more bounds checks because it will be harder for compiler optimizers
to eliminate upper bounds checks in loops.  Most programmers would write code that
strides through an array using a comparison that
\texttt{\var{p} \textless{} \var{ub}}. The comparison 
\texttt{\var{p} < \var{ub}} does not imply
\texttt{\var{p} + sizeof(\var{T}) - 1 < \var{ub}}, so the comparison is
not sufficient for a compiler to optimize away
the upper bounds check. A compiler would have to know that a pointer
and bounds are relatively aligned in order to eliminate the upper bounds
check. It would be hard for a compiler to prove this because it would
require interprocedural or whole-program analysis.

\section{Allowing pointer variables to be assigned values with no relationship to their bounds}

We considered allowing pointer variables to be assigned pointer values
not derived in some way from the object with which their bounds are
associated. The idea would be to avoid unnecessary restrictions on
operations involving pointers and give pointers more leeway to encode
information by modifying bits in pointers.

In this approach, the meaning of a bounds expression would be defined
differently than that given in Section~\ref{section:bounds-declarations}. 
The meaning would be the
following. Given an expression \var{e} with a bounds expression
\texttt{bounds(}\var{lb}\texttt{,} \var{ub}\texttt{)}, let the runtime
values of \var{e}, \var{lb}, and \var{ub} be \var{ev}, \var{lbv},
and \var{ubv}, respectively. If \var{ev} is not null, there will
always exist some object at runtime with the bounds (\var{low},
\var{high}) such that \var{low} \texttt{\textless{}=} \var{lbv} \&\&
\var{ubv} \texttt{\textless{}=} \var{high}. In other words, the
requirement is that expression bounds are always a subrange of the range
of memory for some valid object. This is provided that the value of the
expression with which those bounds are associated is non-null.

The problem with this approach is that it has unexpected consequences
for the bounds that are allowed to be declared for pointer variables.
Any valid pointer bounds could be declared for a variable because there
is no longer a requirement that a pointer stored in the variable is
derived from a pointer to the object associated with the bounds. The
following example would be valid:

\begin{verbatim}
array_ptr<int> x : count(5) = malloc(sizeof(int) * 5);
array_ptr<int> y : bounds(x, x + 5) = malloc(sizeof(int) * 2);
\end{verbatim}

Because the bounds are disassociated from the actual pointer values,
there is much more potential for errors to be made by programmers that
are only detected at runtime. This approach was not pursued further for
this reason.

\section{Address-of and array-to-pointer conversion always produce safe pointer types}

We considered a designed where the address-of operator (\&) and
array-to-pointer type conversion always produced safe pointers. To
preserve compatibility with existing C code, we introduce implicit
conversions from safe pointers to unsafe pointers. We found that we were
not able to preserve backwards compatibility for the address-of operator
and that implicit array-to-pointer conversions required bounds checking.

\subsection{Proposed rules for an address-of operator that produces safe pointer type.}

The address-of operator (\texttt{\&}) applied to an lvalue expression of
type \var{T} would produce a value of type
\ptrT.

Existing C code expects the address-of operator to produce a \var{T} *.
To allow most code to compile without changes, we add an implicit cast
rule: \ptrT can be cast
implicitly to a \var{T} * in those situations where a \var{T}
\texttt{*} type is expected, except for pointer arithmetic operators
that add or subtract a pointer and an integer. Those situations include
pointer assignment, arguments to function calls, return statements, and
conditional expressions. In all these situations a \var{T} \texttt{*}
type must have been declared explicitly in the code already, so this
implicit cast does not introduce unsafe pointer types where none existed
before.

Pointer arithmetic operators are excluded to avoid the silent
introduction of unsafe pointer types and to preserve the value of having
the \ptrT type. If
there were always an implicit cast from \ptrT to \var{T} \texttt{*},
then any expression that uses pointer arithmetic could do pointer
arithmetic on \ptrT
values.

Code takes the address of an array element and immediately does pointer
arithmetic will still fail to type check, introducing a potential
backward compatibility issue:
\begin{verbatim}
f()
{
    int a[10];
    int *x = &a[0] + 5; // &a[0] has type ptr<T>.  Pointer arithmetic is not allowed
    ...
}
\end{verbatim}

We expect this kind of code to be rare because the succinct style is to
use \texttt{a} instead of \texttt{\&a[0]}, but is nonetheless a
possibility, so this proposal still violates the principle of not
changing the meaning of existing C code.

\begin{verbatim}
f()
{
    int a[10];
    int *x = ((int *) &a[0]) + 5; // redundant but OK under old rule
    ...
}
\end{verbatim}

\subsection{Proposed rules for conversion of array types to pointer types}

Array types may be complete or incomplete. A complete array type
specifies the number of elements in the array using a constant
expression. In incomplete array type does not specify the number of
elements in the array. Examples of complete array types are int[10]
and int[10][10]. Examples of incomplete array types are
int[] and int[][10].

If the type of an expression or a subexpression is an ``array of
\var{T}'', the following rules would apply. If the array is a complete
type, the type of the expression is altered to
\arrayptrT . If it is
an incomplete type, the type of the expression is altered to \var{T} *.
This alteration does not happen if the expression is an operand of an
address-of operator, \texttt{++}, \texttt{-\/-}, \texttt{sizeof}, or the
left operand of an assignment operator or the `\texttt{.}' operator.

These rules would have an interesting effect for arrays of complete
types: all array references involving those arrays would be bounds
checked. Any address computations involving those arrays will be checked
for overflow also. Because the existing C language definition leaves
out-of-bounds access of arrays of complete type undefined, as well as
the meaning of overflowing address computations undefined, this is
compatible with the existing C language definition.

However, these rules by themselves are problematic for existing C code.
It is common in C code to use array types interchangeably with pointer
types. The rule that complete array types are converted to
\arrayptr\ types could cause problems for such code

\begin{verbatim}
f(int *arg, int len)
{ 
   ...
}

g() {
   int x[10];
   f(x, 10);
}

h() {
   int x[10];
   int *ptr = x;
   f(ptr, 10);
}
\end{verbatim}

To allow existing code to continue to compile unchanged, we adopt the
rule that an \arrayptrT\ can be
implicitly cast to a \var{T} * in situations where a T * type is
expected. Those situations may include pointer assignment, arguments to
function calls, return statements, and conditional expressions. For
conditional, expressions of the form exp1 \texttt{?} exp2 \texttt{:}
exp3, the implicit coercion occurs when exp2 or exp3 has type T * and
the other expression has type
\arrayptrT. These situations do not
include array references and adding or subtracting a pointer type and an
integer. \arrayptrT\ is an acceptable
type for those operations and a coercion to T * is not needed.

We allow \arrayptr\ values to not be within bounds. Because of
this, any implicit conversion of an \arrayptr\ value with a
bounds to an unsafe pointer type must be bounds checked. Otherwise, it
is easy to write ``safe'' code that creates undetected buffer overruns:

\begin{verbatim}
// f looks safe, but does something bad that is undetected before calling unsafe code
f(array_ptr<int> p where bounds(p) == (p, p + 10))
{
    // first argument implicitly converted to int *
    poke(p + random_large_value(), 31415);  
}

void poke(int *p, int val)
{
    *p val
}
\end{verbatim}

The silent introduction of a bounds check at a call to a method violates
the design principles of control and clarity. The implicit conversion
introduces an invisible failure point in a program where one does not
otherwise exist. Pointer arithmetic is not normally bounds checked, so
it is not expected fail.

\section{Alternate semantics for bounds declarations}
\label{section:bounds-declarations-alternate-semantics}

There are a variety of possible semantics for
bounds declarations. A bounds declaration has the form:

\begin{quote}
\boundsdecl{\var{x}}{\var{bounds-exp}}
\end{quote}

\begin{tabbing}
\var{bounds}\=\var{-exp:} \\
\> \texttt{count(}\var{non-modifying-exp}\texttt{)} \\
\> \bounds{\var{non-modifying-exp}}{\var{non-modifying-exp}} \\
\> \boundsnone \\
\> \boundsany
\end{tabbing}

It may be attached to declarators, parameter declarations, or assignment statements:

\begin{tabbing}
\var{init-}\=\var{declarator:} \\
\>\var{declarator inline-bounds-specifier\textsubscript{opt} where-clause\textsubscript{opt}} \\
\>\var{declarator inline-bounds-specifier\textsubscript{opt} 
where-clause\textsubscript{opt}} \texttt{=} \var{initializer
where-clause\textsubscript{opt}} \\
\>\ldots{} \\
\\
\var{parameter-declaration:} \\
\>\var{declaration-specifiers declarator} \\
\>\var{inline-bounds-specifier\textsubscript{opt} where-clause\textsubscript{opt}} \\
\\
\var{expression-statement:}\\
\>\var{expression\textsubscript{opt} where-clause\textsubscript{opt}}\texttt{;}
\end{tabbing}

The information in the bounds declaration is used at pointer
dereferences involving either (1) the variable or (2) pointers
constructed from the value of the variable.

One design choice for bounds declarations is when
bounds expressions are evaluated.  In the design, evaluation of
bounds expressions is {\em deferred} until bounds checks.  The bounds
expressions could be evaluated {\em eagerly} at the point of the bounds declarations.

If bounds expressions in a bounds declaration \boundsdecl{\var{v}}{\var{e}} are evaluated 
eagerly, they must  be evaluated only when \var{v} is non-null. If \var{v} is null,
the bounds might not be meaningful.  This keeps eager evaluation from
causing accidental runtime failures when null values are encountered.    

Consider the code for the use of \texttt{malloc}.   With eager evaluation,
the bounds expressions in \bounds{result}{result + size} would not
be evaluated if \texttt{malloc} returns \texttt{null}:
\begin{verbatim}
array_ptr<int> result = malloc(size) where result : bounds (result, result + size);
if (result != NULL) {
      ... *result = ...
}
\end{verbatim}

We considered eager evaluation, but rejected it because it would turn \arrayptr\
types into \arrayview\ types.  When bounds expressions are always eagerly
evaluated, the results need to be stored somewhere so that they can be used
when \var{v} is used.  For local variables, hidden temporary variables could be
introduced.  This breaks the design principle of not introducing hidden
costs, though.  To avoid introducing hidden costs, the semantics of \arrayptr\ types could 
be changed so that they carry their bounds with them.   This just turns \arrayptr\ types into 
\arrayview\ types.   For structures, introducing hidden state or converting \arrayptr\ types to 
\arrayview\ types is especially problematic because it breaks data layout compatibility.

For these reasons, we think it is better to think of bounds declarations as being
program invariants describing the bounds of variables.   Normally, 
program invariants are not evaluated at runtime.  However, in the case of pointers,
the program invariants are used to provide bounds safety at runtime.

Deferred evaluation of bounds expressions has issues, too, though. First, there
can be problems if a programmer modifies a variable used in a bounds expression
within the extent of a bounds declaration.  Static checking could fail if the
bounds declaration no longer holds.  These would be unexpected errors for
C progammers.  Second, it is a new concept for C programmers that could
cause confusion.  We recommend a carefully designed study of
programmers to evaluate the difficulty of learning the concept.

Because bounds declarations constrain assignments to variables within the scope
of the bounds declarations, we considered several alternate definitions of 
bounds declarations.   First, we considered not having lexically-scoped bounds
declarations and just having flow-sensitive bounds declarations.  Flow-sensitive
bounds declarations are more subtle to understand, though, while lexically-scoped
bounds declarations can be understood at a glance.  We decided to keep
lexically-scoped bounds declarations because they are simpler to understand and
allow bounds invariants to be declared that always cover a set of statements.
In contrast, with only flow-sensitive bounds declarations, a programmer might need 
to redeclare the bounds invariant at  assignments to variables that occur in the
bounds declaration. This could lead to verbose code, something C tries to
avoid, and it could also be error-prone.

We considered the opposite approach of having only lexically-scoped
bounds declarations.   However, this introduces the opposite problem of
redeclaring invariants.  A pointer variable could not have different
bounds declarations during at different points in the program.  This could
make modifying existing C code to be bounds-safe more complex: an existing
variable might need to be replaced with several new variables.

Finally, we considered several alternate definitions of the extent of a
flow-sensitive bounds declaration for a pointer variable:
\begin{compactitem}
    \item Defining extent to be the set of statements up to the first assignment
          to any variable occurring in the bounds declaration.   This is a
          ``minimal'' notion of extent.  It removes the special case for
          pointer increment and decrement, so bounds
          declarations would be required at those statements.  We believe
          the special case will lead to more succinct code, so we chose to
          keep it.
    \item Defining extent to be all the statements between the bounds
          declaration and the next bounds declaration for
         the pointer variable or the last use of the pointer variable.  This
         is a ``maximal'' notion of extent.  We thought this case might
         lead to surprising error messages when modifying existing
         code.  In particular, with this definition, extending
         the lifetime of a pointer variable could lead to errors
         at assignments within the new part of the lifetime, specifically
         assignments to variables that occur in the bounds declaration.
         The current definition is more conservative.  It could produce errors
         only at new uses of the pointer variable or assignments in
         the new part of the lifetime that increment or decrement the pointer 
         variable.
  \item Adding special cases to the current definition beyond
        pointer increment and decrement.  
\end{compactitem}
We believe that we need experience using flow-sensitive bounds declarations
to choose between these different possible definitions of extent.

