\documentclass[11pt]{report}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{alltt}
\usepackage{amssymb,amsmath}
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{longtable,booktabs}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{3}

%
% meta variables are italicized.  Use the macro name var
% to save on typing.
\newcommand{\var}[1]{\textit{#1}}
%
% macro for font for keywords

%
\newcommand{\keyword}[1]{\texttt{#1}}
\newcommand{\sizeof}[1]{\texttt{sizeof(#1)}}
%

% array_ptr type macros
%
\newcommand{\arrayptr}{\texttt{array\_ptr}}
\newcommand{\arrayptrinst}[1]{\texttt{array\_ptr<}#1\texttt{>}}
\newcommand{\arrayptrT}{\arrayptrinst{\var{T}}}
\newcommand{\arrayptrchar}{\arrayptrinst{\texttt{char}}}
\newcommand{\arrayptrint}{\arrayptrinst{\texttt{int}}}
\newcommand{\arrayptrvoid}{\arrayptrinst{\texttt{void}}}

\newcommand{\arrayview}{\texttt{array\_view}}
\newcommand{\arrayviewinst}[1]{\texttt{array\_view<}#1\texttt{>}}
\newcommand{\arrayviewT}{\arrayviewinst{\var{T}}}
\newcommand{\arrayviewchar}{\arrayviewinst{\texttt{char}}}
\newcommand{\arrayviewint}{\arrayviewinst{\texttt{int}}}
\newcommand{\arrayviewvoid}{\arrayviewinst{\texttt{void}}}

\newcommand{\ptr}{\texttt{ptr}}
\newcommand{\ptrinst}[1]{\texttt{ptr<}#1\texttt{>}}
\newcommand{\ptrT}{\ptrinst{\var{T}}}
\newcommand{\ptrchar}{\ptrinst{\texttt{char}}}
\newcommand{\ptrint}{\ptrinst{\texttt{int}}}
\newcommand{\ptrvoid}{\ptrinst{\texttt{void}}}

%
% bounds expression macros
%
\newcommand{\relalign}[1]{\texttt{rel\_align(}#1\texttt{)}}
\newcommand{\relalignval}[1]{\texttt{rel\_align\_value(}#1\texttt{)}}
\newcommand{\bounds}[2]{\texttt{bounds(}#1\texttt{,}#2\texttt{)}}
\newcommand{\boundsrel}[3]{\texttt{bounds(}#1\texttt{,}#2\texttt{)}
                           \relalign{#3}}
\newcommand{\boundsrelval}[3]{\texttt{bounds(}#1\texttt{,}#2\texttt{)}
                               \relalignval{#3}}
\newcommand{\boundsany}{\texttt{bounds(any)}}
\newcommand{\boundsnone}{\texttt{bounds(none)}}
\newcommand{\boundscount}[1]{\texttt{count(}#1\texttt{)}}
\newcommand{\boundsbytecount}[1]{\texttt{byte\_count(}#1\texttt{)}}

%
% bounds declaration macros
%
\newcommand{\boundsdecl}[2]{#1 \texttt{:} #2}
%
% computed bounds for expressions
%
\newcommand{\boundsinfer}[2]{#1 \texttt{:-} #2}

\date{}

\title{Checked C Extensions to C for Pointer Safety}

\begin{document}

\maketitle

\begin{abstract}
Systems programmers need a systems programming language that
detects or prevents common programming errors involving pointers. This
would improve the reliability and security of systems software, as well
the productivity of systems programmers. This design note describes
Checked C, an extended version of C that provides bounds-checking for
pointers and arrays.

Checked C relies on static and dynamic checking to enforce bounds
safety. It adds new pointer types and array types that are
bounds-checked, yet layout-compatible with existing pointer and array
types. Programmers control the placement of bounds information in data
structures and the flow of bounds information through programs. Static
checking enforces the integrity of the bounds information and allows the
eliding of some dynamic checking. Dynamic checking enforces the
integrity of memory accesses at runtime when static checking cannot.
Checked C is a backwards-compatible extension: existing C programs work
``as is''. Programmers incrementally opt-in to bounds checking, while
maintaining binary compatibility. Checked C builds on extensions to C
proposed by the CCured and Deputy projects.
\end{abstract}

\tableofcontents

\chapter{Introduction}\label{introduction}

The C programming language allows programmers to use pointers directly.
A pointer is an address of a location in memory. Programs may do
arithmetic on pointers, dereference them to read memory, or assign
through them to modify memory. The ability to use pointers directly
makes C well-suited for low-level systems programming that is ``close to
the hardware'' and allows programmers to write efficient programs. C
also unifies pointer types and array types. They can usually be used
interchangeably and array subscripting is a synonym for equivalent
pointer operations.

Pointers and the unification of arrays and pointers are one of the
strengths of the C programming language, allowing programmers to write
concise, efficient programs. At the same time, they are one of the main
sources of reliability and security problems in modern software. This is
because pointers and array indices are not bounds checked in C and
related languages such as C++. Bounds checking checks that a pointer or
array index is in bounds before it is used to read or write memory. A
pointer to an array object is in bounds if it points to an element of
the array object. An array index is in bounds if the index is greater
than or equal to zero and less than the size of the array.

Between 2010 and 2015, buffer overflows accounted for between 10-16\% of
publicly reported security vulnerabilities in the U.S. National
Vulnerability Database each year . The vulnerabilities have affected
software implemented in C and C++ that is widely used, including the
Windows and Linux operating systems, the Internet Explorer, Chrome, and
Safari web browsers, the Apache web server, the OpenSSL security
library, scripting language implementations for Bash, Ruby, and PHP, and
media playback software such as QuickTime.

Because pointers and array indices are not bounds checked in C, a
programming error involving them may corrupt memory locations used by
the program. The memory locations may hold data that is important to the
computations being done by the program or data that is essential to the
control-flow of the program, such as return address locations and
function pointers. Memory corruption can lead to a program producing
incorrect results or, in the hands of a malicious adversary, the
complete malfunctioning of the program and the takeover of a running
process by the adversary.

This design note describes Checked C, an extension to C that provides
bounds checking for pointers and arrays. There are two obstacles to
adding bounds checking to C. First, it is not clear where to put the
bounds information at runtime. Second, it is not clear how to make the
bounds checking efficient for programs where performance matters. The
solution of changing the representation of all C pointer types and
arrays to carry bounds information is not sufficient in practice. C may
be used at the base of systems where hardware or standards dictate data
layout and data layout cannot be changed. C programs must also
interoperate with existing operating systems and software that require
specific data layouts.

Checked C addresses the bounds checking problem for C by:

\begin{itemize}
\item
  Introducing different pointer types to capture the different ways in
  which pointers are used. The unsafe C pointer type \texttt{*} is kept
  and three new pointer types are added: one for pointers that are never
  used in pointer arithmetic (\ptr), one for \emph{array pointer
  types} (\arrayptr) that are involved in pointer arithmetic,
  and one for pointer types that carry their dynamic bounds with them
  (\arrayview ).
\item
  For array pointer types (\arrayptr), bounds checking is
  placed under programmer control. This differs from languages like
  Java, where bounds checking is completely automatic. A programmer
  declares \emph{bounds}, where the bounds for an \arrayptr\
  variable are given by non-modifying C expressions. These are a subset
  of C expressions that do not modify variables or memory. They include
  local variables, parameters, constant expressions, casts, and
  operators such as addition, subtraction, and address-of (\texttt{\&})
  operators. Static checking ensures that programs declare and maintain
  bounds information properly. The bounds are used at runtime to enforce
  bounds safety, if necessary.
\item
  Introducing different array types to distinguish between arrays whose
  accesses are bounds-checked and existing C arrays whose accesses are
  not bounds-checked. A programmer places the modifier \keyword{checked}
  before the declaration of the bound(s) of the array: \texttt{int x
  checked[5][5]} declares a 2-dimensional array for which all
  accesses will be bounds-checked.
\item
  For structure types with \arrayptr -typed members, a
  programmer declares \emph{member bounds} for those members. A member
  bounds declares the bounds for a member in terms of members in the
  structure type. Member bounds can be suspended temporarily for
  specific variables and objects. Static checking ensures that updates
  to members maintain the member bounds of the members.
\item
  Introducing bounds-safe interfaces to address the problem of
  interoperation between safe code and unsafe code. A bounds-safe
  interface describes the safe interface to unsafe code by declaring
  bounds for unsafe pointers in function signatures and data structures.
  Because it describes a boundary, it has to be ``safe'' and ``unsafe''
  at the same time, depending on what kind of code is using it. The
  interface is trusted in safe code (code that uses safe pointer types).
  Proper usage is enforced via checking at compile time and runtime. For
  unsafe code, the interface is merely descriptive and not enforced by
  language checking. This provides a way to upgrade existing code to
  provide a safe interface without breaking existing users of the code.
\item
  Introducing checked program scopes, where bounds checking is the
  default behavior. In a checked program scope, definitions of variables
  and functions can use safe pointer types and cannot use unsafe pointer
  types. Declarations involving unsafe pointer types must provide
  bounds-safe interfaces. Checked program scopes avoid problems with
  subtle misuse of bounds-safe interfaces.
\item
  Reasoning about the correctness of programs with declared bounds
  sometimes requires reasoning about simple aspects of program behavior.
  To support this, lightweight invariants are added to C. A lightweight
  invariant declares a relation between a variable and a simple
  expression using a relational operator. An example would be the
  statement \texttt{x < y + 5}. Lightweight invariants can be
  declared at variable declarations, at assignment statements, for
  parameters, and for return values. C is extended with rules for
  checking these lightweight invariants. Just as type checking rules are
  defined by the programming language, so are rules for checking
  lightweight invariants. The checking of the correctness of
  programmer-declared bounds is integrated with the checking of
  invariants.
\item
  For the cases where static checking reaches it limits, a programmer
  can introduce dynamic checks that are runtime errors if they fail.
  Dynamic checks use the syntax \keyword{check} \var{e}, where \var{e} is an
  integer-valued expression. A check is similar to an assert, except
  that it is never removed from the program (unless the compiler proves
  it is redundant). It cannot be removed because the integrity of the
  program depends upon it.
\end{itemize}

For an existing C program to be correct, there has to be an
understanding on the part of the programmer as to why pointers and array
indices stay in range. The goals of the design are to let the programmer
write this knowledge down, to formalize existing practices, such as
array pointer parameters being paired with length parameters, and to
check this information.

To simplify bounds and reasoning about bounds, for \arrayview\
and \arrayptr\ types, pointer arithmetic overflow for these
types is considered a runtime error. Pointer arithmetic involving a null
pointer for these types is also a runtime error.

Efficiency is addressed by extending the static checking so that it can
guarantee that specific bounds checks will always succeed at runtime for
\arrayptr\ and \arrayview\ types. The static checking
supports the scenario of simple control-flow enclosing the bounds check
guaranteeing that the bounds check will succeed. For example, a for-loop
may iterate only over values within the declared bounds for an
\arrayptr\ pointer variable.

A problem with incorporating static checking into a programming language
is that static checking needs to be something that compilers can do
quickly and deterministically. Static checking can become very expensive
to do, depending on the language of invariants and the inference that
the compiler is expected to do. For example, Presburger arithmetic is
integer arithmetic restricted only to addition and less than or equal
operations. It is NP-complete to determine whether a formula in the
first-order logic for quantifier-free Presburger arithmetic is
satisfiable (true or false). Even statically checking properties of
simple fragments of real programs can be computationally intractable.

We address this problem two ways. First, the language of invariants is
restricted. The language of invariants does not allow disjunctive
invariants (invariants involving \verb+||+. For example, one
cannot write an invariant that says that variable x has a pointer to a 5
or 7 element array, depending on the value of some Boolean variable b.
The combination of disjunction with conjunction leads to an exponential
size increase when invariants are put into a normal form to check that
two invariants are the same, so it is avoided.

Second, the inference that compilers are expected to do is limited also.
A compiler acts as a \emph{checker} for invariants. It checks that
declared invariants follow from other \emph{declared} invariants, the
program control-flow, intervening assignments, and simple axioms about
invariants, such as transitivity of relational operators. The compiler
does not try to devise invariants or prove the correctness of
invariants; it applies simple local reasoning to check them. The
programmer has to call out the relevant facts. If a programmer declares
an invariant \texttt{x == y} but neglects to declare the invariant
\texttt{y == z}, the checker may not be able to reason several
statements later that \texttt{x == z}, even though it may be true at
that point in the program. This is taking advantage of the fact that
checking a proof is usually much easier than creating the proof.

One question for the design is how usable it is with these restrictions.
We plan to evaluate the limitation on the language of invariants
empirically by examining code and looking for code that requires
disjunctive invariants about bounds. We will also see how many
invariants need to be explicitly declared for the compiler.

Another problem with static checking is that static checking has
theoretical and practical limits. A program logic may be incomplete: a
fact that is true about a program may not be provable in the logic. Even
when a program logic can prove a fact, the proof may require deep
knowledge of an area or the properties of the program. A programmer may
not have the time or expertise to construct the proof that the fact is
true. For example, code may be relying on properties of modular
arithmetic for correctness. For these situations, programs can
dynamically check facts that are believed to be true, but not provable
via the static checking in the language.

Establishing the safety of pointer operations is just the first step in
establishing type safety for C programs. There are other ways which C
programs may fail. C programs may incorrectly deallocate memory that is
still in use, do incorrect unsafe pointer casts, or have concurrency
races that tear data structures. Addressing these problems is beyond the
scope of this design document. For now, we assume that programs are
correct in these other aspects.

The rest of this document is organized as follows. Section 2 describes
the principles that will be applied to extending C. Section 3 describes
the new pointer types and the new array types, including syntax,
semantics, and error conditions. It also covers other extensions to C
semantics. One extension is the introduction of safe program scopes to
prevent inadvertent use of unsafe types. Another extension is a
refinement of C's notion of undefined behavior. We wish to maintain
bounds safety even in the face of integer overflow, which is a
widespread possibility in C programs. This requires a more nuanced
requirement on the result of overflow than ``the result is undefined.''

Sections 4 through 9 present the extensions to C for declaring bounds
for \arrayptr\ values stored in variables and structures and
checking the consistency of those declared bounds. The extensions are
organized by C language feature, moving from simple language features to
more complicated language features. This allows a reader to understand
concepts one at time.

Section 4 describes how programmers declare the bounds for
\arrayptr\ variables and the meaning of bounds declarations.
Bounds can be declared at variable declarations. They can also be
declared for automatic (local) variables at assignments. If the only
bounds declaration for a variable is at the declaration of the variable,
the bounds declaration is an invariant bounds declaration. An invariant
bounds declaration must be true for the lifetime of the variable. If
there are bounds declarations for the variable at assignments or other
declarations, all bounds declarations for the variable are
dataflow-sensitive. Dataflow-sensitive bounds declarations extend via
dataflow to uses of the variable.

Invariant bounds declarations must usually be valid after every
statement and declaration in the scope of a variable. Sometime multiple
statements are needed to update the set of a variables used in an
invariant bounds declaration. To support this, expression statements and
declarations can be \emph{bundled}, in which case bounds declarations
must be valid only at the end of the bundle. Within the bundled block,
the variables may be inconsistent with respect to bounds declarations
that use them. The variable can be updated so that consistency is
re-established at the end of the bundled block.

Section 5 describes rules that the compiler uses to check the validity
of bounds declarations. It covers inferring bounds for expressions.
Because expression may have assignments embedded within them, it also
covers inferring effects of an expression on the bounds of variables.
This inferred information is then used to validate that declarations and
statements correctly declare bounds and maintain the bounds information.

Section 6 covers interoperation between safe and unsafe code. It covers
conversions between safe and unsafe pointers, as well as the new kinds
of pointers. It pins down the notion of safe code and unsafe code.
Finally, it covers bounds-safe interfaces in depth.

Section 7 extends these ideas from variables to data structures by
introducing member bounds, which are type-level invariants about members
of structure types. For now, it assumes that the programmer has done
concurrency control around shared data properly and ignores the fact
that data structures may be modified in racy ways such that invariants
are violated.

Section 9 extends these ideas to pointers to structures.

Section 10 extends the checking of bounds to incorporate simple
reasoning about bounds and program behavior. It includes a set of rules
for deducing facts that are true about a program at a specific point in
the program (for example, given an assignment \texttt{x = y;} the fact
that x == y is true after the assignment). Facts can also be deduced
from program control-flow. There are additional rules for reasoning
about whether one fact is true given a set of other facts (for example,
given x == y and the statement \texttt{z = y;} z == x is true after that
statement). These rules and facts can be used to deduce the correctness
of bounds declarations that differ from those inferred directly by the
checking described in Sections 0 through 9. For example, a programmer
may wish to narrow the memory that is accessible via an
\arrayptr\ variable by declaring bounds that are a subrange of
the bounds inferred by the checking. A programmer may wish to update the
bounds for an \arrayptr\ variable after an assignment \texttt{x
= y}, substituting x for y.

The same static checking that is used for bounds can be used to reason
about the ranges of variables at specific points in a program. From
there, it is a short step to deducing at compile-time that bounds are
always satisfied at a particular memory access in a program. For
example, a fact can be that the range of an integer variable \texttt{i}
is always between 0 and 10. This can be used to deduce that an array
access in a crucial inner loop is always in bounds.

Section 11 addresses pointers to \arrayptr\ variables and
address-taken variables.

Section 12 describes prior work on extending C for safety and some
lessons that we drew from that work. We are heavily influenced by the
CCured and Deputy systems.

Section 13 evaluates the design by describing our experience modifying
an existing C open-source code base by hand to use the Checked C
extensions. We chose to modify OpenSSL, an important widely-used
open-source code base. The static and dynamic checking is not
implemented in a compiler yet, so we cannot be sure of the correctness
of the modifications or understand the practical benefits of checking.
Still, this gives some idea about the usefulness and applicability of
the design.

Section 14 summarizes the open problems uncovered by Section 13 or
unaddressed by the design. It also describes next steps for implementing
this in a C compiler.

\chapter{Principles for language extensions}\label{principles-for-language-extensions}

Here are the principles that are applied to extending C:

\begin{enumerate}
\item
  Preserve the efficiency and control of C. C is designed to be
  low-level and work with the same types that computer processors work
  with. This makes C ``close to the hardware'', allowing programmers to
  write efficient programs and control what programs do precisely at the
  machine level. These features are one reason why C is valued as a
  system programming language. Extensions will be ``pay-as-you-go'' and
  continue to provide precise control to programmers at the machine
  level. Hidden costs will be avoided.
\item
  Be Minimal. This means adding the minimal set of extensions needed to
  accomplish the goals. It is easier to learn extensions if there are as
  few of them as possible. It also lets us stay true to the design goals
  of C.
\item
  Aim for clarity and succinctness. Clarity means that code is easy to
  understand and extensions are straightforward to understand.
  Succinctness means the programmers have less to read or type.
  Programmers value clarity and succinctness because it makes them more
  productive at their jobs. Sometimes clarity and succinctness are in
  tension and sometimes they are not. When they are in conflict, clarity
  will be prioritized above succinctness, primarily because source code
  is read many more times than it is written.
\item
  Enable incremental use. Real systems are large and complicated, with
  hundreds of thousands and millions of lines of code. The teams that
  work on those systems will adopt safe pointer operations over time,
  not all at once, so incremental use of safe pointer operations will be
  supported. Teams will prefer incremental conversion paths because of
  practical matters such as reducing risk, fixing existing bugs
  identified by introducing bounds checking, maintaining system
  stability, and understanding performance effects. Even though
  incremental use will be supported, it is not the end goal. We believe
  that benefits of using safe pointer operations will be modest until
  almost an entire system is converted. At that point, we expect a
  qualitative increase in system reliability and programmer
  productivity.
\end{enumerate}

Two specific design principles are adopted based on these principles:

\begin{enumerate}
\item
  Do not change the meaning of existing C code. Methods that do not use
  extensions will continue to compile, link, and run ``as is''. If the
  meaning of existing C code is changed, it will violate the principles
  of clarity and enabling incremental adoption.
\item
  Adopt existing notations from C++ when it meets our needs, instead of
  inventing new notations. Many systems are hybrid C/C++ systems, so
  this approach fits with the principle of clarity. It also enables
  incremental adoption. One of the design goals of C++ has been that C
  is a subset of C++. That will continue to be true even for our
  extended C.
\end{enumerate}


\chapter{New types and other extensions to C semantics}
\label{new-types-and-other-extensions-to-c-semantics}

\section{New kinds of pointer types}
\label{new-kinds-of-pointer-types}
Three new safe pointer types are added to C. Each pointer type can be
used in place of `*'

\begin{enumerate}
\item
  \ptrT: this points to
  a value of type \textit{T}. Pointer arithmetic is not allowed on these
  kinds of pointers. The expectation is that that many pointers are not
  involved in pointer arithmetic and will be given this type. When
  values of this pointer type are used to read or write memory, they
  must be non-null. The non-nullness is checked at runtime if necessary.
\item
  \arrayptrT: this is
  a pointer to an element of an array of type \var{T} values. A
  variable of type \arrayptr\ that is used to access memory
  must have an associated declaration of the valid bounds for the
  variable. When values of this pointer type are used to read or write
  memory, they must be non-null and in bounds. The non-nullness and
  bounds are checked at runtime if necessary. Pointer arithmetic can be
  done on these pointer types. The resulting pointers do not need to be
  in bounds.
\item
  \arrayviewT: this
  is a pointer that dynamically carries its bounds information with it.
  These pointers follow the same rules as
  \arrayptrT .
\end{enumerate}

Unsafe C pointer types that use \texttt{*} and are unchecked in their
ranges continue to exist. Pointer arithmetic is not forbidden on unsafe
pointer types because it would break existing C code. C compilers will
have an error or warning mode that flags unexpected uses of `*'.

The name \ptr\ is chosen for pointers that can only be read or
written because those are expected to be the most common type of pointer
in C code. It is a short succinct name.

The same syntax as C++ template instantiations is used for building
instances of these types because this syntax is well-known and
understood. The parameter to these type constructors must be a type.

\begin{quote}
\emph{Note that using C++ template instantiation syntax interacts poorly
with mixed C declarators. In the syntax of C declarators, `*' is used as
a prefix to an identifier to modify the type of an identifier. A mixed
declarator is a declarator where different identifiers have different
types because of different modifiers. An example of a mixed declarator
is the declaration int i, *pi; The C++ template instantiation produces a
type, so ``mixed'' declarators} \emph{must be broken across multiple
lines instead. The resulting declarations would be} int i;
\ptrint\ pi;\emph{. On the other hand, non-mixed
declarators are fine: int *pj, *pi; is given the syntax
\ptrint\ pi, pj.}

\emph{Instead of using the C template instantiation syntax, we
considered allowing the new pointer names to be used in place of *, for
example,} int i, ptr pi;\emph{. However, in our opinion, that made code
less readable. The use of a symbol can be recognized visually more
quickly than the use of an identifier. This is apparent for type names
that consist of several words:} const unsigned int ptr g \emph{is more
difficult to parse quickly than} \ptrinst{\texttt{const unsigned
int}} g\emph{.}
\end{quote}

\section{New kinds of array types}\label{new-kinds-of-array-types}

A new safe array type is added to C. Just as there are safe pointer
types, there are safe array types. They are declared by placing the
modifier \keyword{checked} before the declaration of the bound of the
array\footnote{We can just as easily adopt the syntax that the checked
annotation is postfix and propagates from the inner most array to the
 outermost array. We have chosen the prefix syntax because the notation
 can be read easily from left to right ``this is a checked array of
 10x10 elements''.}:
\begin{verbatim}
int a checked[10];
\end{verbatim}

All array references to checked array types are bounds checked. C has
the rule that an ``array of \var{T}'' is converted implicitly to a
``pointer to \var{T}'' in a number of situations. This rule is extended
to convert a ``checked array of \var{T}'' to an ``\arrayptr\ 
to \var{T}''.

In C, array types may be complete or incomplete. A complete array type
specifies the bound of each dimension of the array using constant
expressions. An incomplete array type does not specify the bound of the
first dimension of the array. Examples of complete array types are
\texttt{int[10]} and \texttt{int[10][10]}. Examples of
incomplete array types are \texttt{int[]} and \texttt{int[][10]}.

If a checked array type is incomplete, there must be an associated
declaration of the valid bounds for the first dimension of the array.
For a complete array type, the bounds declared by the type are used to
bounds check array references. For example, given a declaration
\texttt{int a[10]} and a use \texttt{a[i]}, the bounds check is
that \texttt{i >= 0} and \texttt{i < 10}.

Array references to multi-dimensional arrays must be uniformly bounds
checked or not bounds checked. If any dimension is bounds checked, all
dimensions must be checked. A programmer can simply declare the
\emph{``checked''}-ness for the outer dimension. It will be propagated
to the inner dimensions:

\begin{verbatim}
int b checked[10][10];
\end{verbatim}

More specifically, in C, multidimensional arrays are arrays of arrays,
where the nested array types have known dimensions at compile-time. A
2-dimensional array is an array of array of T, a 3-dimensional array is
an array of array of array of T. The checked-ness is propagated from the
outer array to the nested array types.

The propagation works as follows. In C, a declaration of a variable has
the form T D, where T is a type and D is a declarator. The declarator
can be as simple as an identifier \texttt{x}:
\begin{verbatim}
int x;
\end{verbatim}

It can be a more complex form that declares an identifier and modifies T
to produce a new type for the identifier. An example is \texttt{x[5]}:

\begin{verbatim}
int x[5];
\end{verbatim}

Given a C declaration \var{T} \var{D}, if \var{D} is an array
declarator, it will have the form
\texttt{\var{D1}[\var{constant-expression\textsubscript{opt}}]},
where \var{D1} is another declarator. The type of the identifier in the
declaration \var{T D1} will be determined first. The type can be some
constructed type of the form \var{type-modifier} of \var{T}, where
\var{type-modifier} is a sequence of array, checked array, or pointer
type modifiers. If the first element in the \var{type-modifier}
sequence is an array or pointer, the type of the identifier will be
\var{type-modifier} array of T. If the first element in the
\var{type-modifier} sequence is checked array, the type of the
identifier will be \var{type-modifier} checked array of T.

For example, in parsing the declaration of \texttt{b} above, \var{D1}
will be \texttt{int b checked[10]}. The type of \texttt{b} in
\var{D1} is ``checked array of int''. The type of \texttt{b} in
\texttt{int b checked[10][10]} will be ``checked array of
checked array of int''.

\subsection{An example}
\label{an-example}

It is easy to convert a function that operates only on complete array
types to one where array accesses are bounds checked: just add the
checked keyword to the declarations of the variables with complete array
types. Consider a method that adds 2x2 integer arrays \texttt{a} and
\texttt{b} so that \texttt{a} = \texttt{a} + \texttt{b}:

\begin{verbatim}
void add(int a checked[2][2], int b checked[2][2])
{
    for (int i = 0; i < 2; i++) {
        for (int j = 0; j < 2; j++) {
            a[i][j] += b[i][j];
        }
    }
}
\end{verbatim}

\section{Operations involving pointer types}\label{operations-involving-pointer-types}

The following operations involving pointer-typed values are allowed:

\begin{itemize}
\item
  Indirection: the \texttt{*} operator can be applied to a value of type
  \var{T} \texttt{*},
  \ptrT,
  \arrayptrT, or
  \arrayviewT. It
  produces a value of type \var{T}.
\item
  Array reference: the \texttt{[]} operator can be applied to a
  value of type \var{T} \texttt{*}, \arrayptrT, or \arrayviewT. It
  cannot be applied to a value of type \ptrT.
  \texttt{\var{e1}[\var{e2}]} is equivalent to
  \texttt{*(\var{e1} + \var{e2})}
\item
  Assignment: two pointers of the same type can be assigned.
\item
  Adding or subtracting a pointer type and an integer. This is allowed
  for \var{T} \texttt{*}, \arrayptrT, and \arrayviewT types.
\item
  Pointers to objects of the same type can be compared for equality or
  inequality. The pointers do not have to be the same kind of pointer.
  To support reasoning about program behavior, the result of comparing
  pointers to different objects must be defined.
\item
  Pointers to objects of the same type can be compared relationally,
  except for \ptr\ types. Relational comparisons are the
  \verb|<|, \verb|<=|, \verb|>|, \verb|>=| operators. The pointers do not have to be
  the same kind of pointer. Given a type \var{T}, a \var{T}
  \texttt{*}, \arrayptrT\ or   \arrayviewT, can be compared to a \var{T} \texttt{*},
  \arrayptrT , or \arrayviewT. For example, an \arrayviewT can be compared with an
  \arrayptrT . To support bounds checking and reasoning about program behavior, the
  result of comparing pointers to different objects must be defined.
  Section 3.7 describes this requirement in detail.
\item
  Pointers to objects of the same type can be subtracted, except for
  \ptr\ types. The pointers do not have to be the same kind of
  pointer. The result of subtracting pointers to different objects of
  the same type must be defined. Section 3.7 describes this requirement
  in detail.
\end{itemize}

A value of one pointer type may be converted to a value of another
pointer type. For casts to or from safe pointer types where
bounds-safety can be checked at compile-time, a cast operator can be
used. If bounds safety cannot be checked at compile-time, bounds cast
operators must be used. There are two kinds of bounds cast operators:
\keyword{dynamic\_bounds\_cast}, which does runtime checks of any
conditions required to enforce bounds safety and
\texttt{unchecked\_bounds\_cast}, which does no runtime checking and
trusts the programmer. The rules for pointer casting and the bounds cast
operators are described in in Section 6.

\subsection{Rules for the address-of operator}\label{rules-for-the-address-of-operator}

If an address-of operator (\texttt{\&}) applied to an lvalue expression
of type \var{T}, the following rules apply:

\begin{itemize}
\item
  If the operator occurs in a checked block, the address-of operator
  produces a value of type
  \ptrT
\item
  Otherwise, the address-of operator produces a value of type \var{T}
  \texttt{*}.
\end{itemize}

If the \& operator is applied to an lvalue expression that is a
dereference of a pointer or an array that has bounds checking, the
bounds check will be done when the address is taken. This guarantees
that it is valid to dereference the pointer that results from the
address-of operator. For example, in the following code, bounds checks
will be done at \texttt{\&a[i]} and \texttt{\&b[0]}.

\begin{verbatim}
int a checked[10];
array_ptr<int> b;
int i;
...
ptr<int> y = &a[i];
ptr<int> z = &b[0];
\end{verbatim}

\subsection{Rules for conversion of checked array types to pointer types}\label{rules-for-conversion-of-checked-array-types-to-pointer-types}

If the type of an expression or a subexpression is ``checked array of
\var{T}'', the type of the expression is altered to be
\arrayptrT .

Following existing C language rules, this alteration does not happen if
the expression is an operand of an address-of operator, \texttt{++},
\texttt{--}, \texttt{sizeof}, or the left operand of an assignment
operator or the `\texttt{.}' operator. The prohibition against this
conversion occurring for operands of the address-of operator gives the
results of the operator a more precise type. For sizeof, it also results
in a more precise answer. The prohibitions against it for ++, and --
operands and the left operand of an assignment operato keeps array
variables from being modifiable.

\subsection{\texttt{Array\_view<}\textit{T}\texttt{>} specific operations}\label{arrayux5fviewt-specific-operations}

An \arrayviewT
pointer carries three values with it: the memory location that will be
accessed by dereferencing the
\arrayviewT, a lower
bound on the memory that can be accessed via the current pointer value,
and an upper bound on accessible memory. Those values can be accessed
using the \texttt{.} operator combined with the special field names
\texttt{current}, \texttt{lower\_bound}, and \texttt{upper\_bound}. The
resulting values have the type
\arrayptrT . The
special field names can only be read and cannot be modified by
assignments.

\begin{verbatim}
array_view<int> p = …
array_ptr<int> low = p.lower_bound;
array_ptr<int> high = p.upper_bound;
array_ptr<int> current = p.current;
\end{verbatim}

An \arrayviewT value
is created by casting a value of another pointer type to the
\arrayviewT type. A
value of another pointer type may be converted to an
\arrayviewT in
situations where an
\arrayviewT value is
expected, the referent type of the other pointer type is \var{T}, and
the bounds of the value can be determined automatically.

For example, a variable of array type can be converted automatically to
an \arrayview\ . First, the array type will be converted to a
pointer type of either \var{T} \texttt{*} or
\arrayptrT , depending
on whether the array type is checked or unchecked. This pointer type
will then be converted to an
\arrayviewT. The
bounds of a variable of array type are easily determined at compile
time, so the pointer type will then be converted to an
\arrayviewT:

\begin{verbatim}
int x[10]
array_view<int> p = x; 
// p.current = x; p.lower_bound = x; p.upper_bound = x + 10;

\end{verbatim}

Similarly, an \arrayptr\ value with declared bounds can be
converted to an \arrayview\ value:

\begin{verbatim}
array_ptr<int> src = …
array_view<int> p = src;
\end{verbatim}

The full rules for casting to an \arrayview\ type are covered
in Section 6.1.

\section{Pointer arithmetic error conditions}\label{pointer-arithmetic-error-conditions}

For existing unsafe C pointers, the definition of pointer arithmetic is
described in terms of addresses of elements of an array object. The C
Standard states, that given a pointer p that points to some element i of
an array object, p + j points to the (i+j)th element of that object.
Pointer arithmetic is defined only for pointers to elements of the array
object or one past the last element of the array object.

We take an alternative approach to defining the meaning of pointer
arithmetic and the error conditions for pointer arithmetic. Pointer
arithmetic is allowed to go out-of-bounds and has a well-defined
semantics. Section 3.4.1 defines the semantics of the new pointer types
directly in terms of byte addresses, instead of with respect to
addresses of elements of an array. Pointer arithmetic that overflows or
involves a null pointer is defined to produce a runtime error.

The new pointer types allow pointer arithmetic that produces
out-of-bounds values. The C definition leaves pointer arithmetic that
produces out-of-bounds values undefined because it is not clear what the
meaning of should be when the pointers are dereferenced. The new pointer
types prevent out-of-bounds pointers from being dereferenced, and solve
this problem another way. In addition, in practice C implementations
often allow pointer arithmetic to produce out-of-bounds values and C
programs end up relying on this implementation-specific behavior. There
is no reason to cause existing code that computes out-of-bounds pointers
but does not dereference them to break when it is converted to use the
new pointer types.

When pointer arithmetic overflows or involves a null pointer, the
resulting value of the expression cannot be used and program execution
stops. If a system provides for error handling, an error handling
mechanism may be invoked to redirect program execution to a new point of
execution that does not use the value of the expression.

Defining pointer arithmetic this way simplifies reasoning about the new
pointer types. Expected Identities such as \texttt{p + 1 \textgreater{}
p} now hold because, if \texttt{p + 1} overflows, the value cannot be
used. This allows programmers to narrow the bounds for
\arrayptr\ values by incrementing the lower bound or
decrementing the upper bound, even in situations where the bounds are at
the ends of the address space. Later sections describe places where
allowing an undefined value to be used would complicate reasoning about
programs.

If a compiler cannot prove that a new pointer type value is non-null
before a pointer arithmetic operation, it must insert a check.
Similarly, if a compiler cannot prove that a pointer arithmetic
expression for a new pointer type cannot overflow, it must insert a
check. This may slow a typical program down by a slight amount.

\subsection{Semantics of pointer arithmetic for new pointer types}\label{semantics-of-pointer-arithmetic-for-new-pointer-types}

This section defines the semantics of pointer arithmetic and explains
when overflow occurs in pointer arithmetic. It is assumed that memory is
addressable at the byte level. The order of bits within a byte is not
specified. The order of bytes within built-in types larger than a byte,
such as integers and floating-point numbers, is also not specified.
Pointers shall be treated as addresses of locations of bytes in memory.
The addresses shall be unsigned integers with a defined range of 0 to
\texttt{UINTPTR\_MAX}. The maximum value of a signed integer that can be
added to an address shall be given by \texttt{INTPTR\_MAX} and the
minimum value of a signed integer that can be added to an address shall
be given by \texttt{INTPTR\_MIN}.

For the new
\arrayptrT\ pointer
types, there are distinct operations for addition and subtraction of
pointers by signed and unsigned integers. The operations behave
similarly, but have different overflow conditions for scaling because
the ranges of signed integers and unsigned integers are different.

\begin{itemize}
\item
  First scaling an integer by \sizeof{\var{T}} is
  defined. To scale an integer \var{i}, \var{i} shall be multiplied by
  \sizeof{\var{T}}, producing an integer \var{j}. If
  \var{i} is a signed integer, the scaled result shall be treated as a
  signed integer. If \var{i} is an unsigned integer, the scaled result
  shall be treated as an unsigned integer. For a signed integer, the
  minimum and maximum range for j shall be \texttt{INTPTR\_MIN} and
  \texttt{INTPTR\_MAX} For an unsigned integer, the minimum and maximum
  range for j shall be 0 and UINTPTR\texttt{\_MAX}. If \var{j} is
  outside its valid range, the operation doing the scaling operation
  shall produce a runtime error.
\item
  \var{p} \texttt{+} \var{i}, where p is an
  \arrayptrT\ pointer
  and \var{i} is an integer. The integer \var{i} shall be scaled by
  \sizeof{\var{T}}, producing an integer \var{j}. The
  pointer p will be interpreted as an unsigned integer. The mathematical
  value \var{p} + \var{j} shall be the result of the operation. If
  \var{p} + \var{j} is out of range for a pointer, the operation shall
  produce a runtime error.
\item
  \var{i} \texttt{+} \var{p}, where \var{p} is an
  \arrayptrT\ pointer
  and \var{i} is an integer, shall be defined as \var{p} \texttt{+}
  \var{i}.
\item
  \var{p} \texttt{--} \var{i}, where \var{p} is an
  \arrayptrT\ pointer
  and \var{i} is an integer. The integer \var{i} shall be scaled by
  \sizeof{\var{T}}, producing an integer \var{j}. The
  pointer \var{p} will be interpreted as an unsigned integer. The
  mathematical value \var{p} - \var{j} shall be the result of the
  operation. If \var{p -} \var{j} is out of range for a pointer, the
  operation shall produce a runtime error.
\item
  \var{p} \texttt{--} \var{q}, where \var{p} and \var{q} are
  \arrayptrT
  pointers. The two pointers will be interpreted as unsigned integers
  and the mathematical value \var{p} -- \var{q} shall be computed,
  producing an integer \var{j}. If \var{j} is out of range for signed
  integer that can be added to an address, the operation shall produce a
  runtime error. If \var{j} is a multiple of
  \sizeof{\var{T}}, the result shall be
  \var{j}/\sizeof{\var{T}}. If \var{j} is not a
  multiple of \sizeof{\var{T}}, then the value shall
  be determined as follows:

  \begin{itemize}
  \item
    If \var{j} is non-negative,
    \var{j}/\sizeof{\var{T}} shall round toward 0.
  \item
    If \var{j} is negative, it shall be implementation-defined whether
    \var{j}/\sizeof{\var{T}} rounds toward 0 or away
    from 0.
  \end{itemize}
\end{itemize}

An important implication of these definitions is that they put a maximum
limit on the number of elements in an array of type \var{T}. It is
\texttt{UINTPTR\_MAX}/\sizeof{\var{T}}. They also put
maximum limits on the number of elements that can be accessed in an
array by a signed integer or an unsigned integer. That leads to limits
on the size of arrays that can be described by some bounds. A signed
integer that must be non-negative can describe an array of
\texttt{INTPTR\_MAX/\sizeof{\var{T}}} elements.

\subsection{Expressing pointer arithmetic as integer arithmetic}\label{expressing-pointer-arithmetic-as-integer-arithmetic}

During static checking, pointer arithmetic operations will be converted
to use integer arithmetic. This is necessary in C because at times
programmers do explicit size computations that follow the same rules as
pointer arithmetic.

To support this expansion, integer arithmetic operators are extended
with the operators \texttt{+\textsubscript{ovf}},
\texttt{-\textsubscript{ovf}} , and\texttt{*\textsubscript{ovf}}. The
operators interpet pointers as unsigned integers in some range 0 to
\texttt{UINTPTR\_MAX}. An operator produces a runtime error if the value
of its result cannot be represented by the result type:

\begin{itemize}
\item
  \texttt{+\textsubscript{ovf}} takes an unsigned integer i and an
  integer j and produces an unsigned integer in the range 0 to
  \texttt{UINTPTR\_MAX}. Its result is the mathemetical value i + j.
\item
  For subtraction, there are two forms:

  \begin{itemize}
  \item
    \texttt{-\textsubscript{ovf}} takes an unsigned integer i and an
    integer j as an argument and computes i - j, producing an unsigned
    integer in the range 0 to \texttt{UINTPTR\_MAX}. Its result is the
    mathematical value i - j.
  \item
    \texttt{-\textsubscript{ovf\_diff }}takes two unsigned integers i
    and j and computes i - j, producing a signed integer of type
    \texttt{ptrdiff\_t}. Its result is the mathemetical value i - j.
  \end{itemize}
\item
  \texttt{*\textsubscript{ovf }}takes two integers i and j (both either
  signed or unsigned) as arguments. It produces an integer whose type is
  the same as the input argument types. Its result is the mathematical
  value i * j.
\end{itemize}

Given an expression \texttt{e1} with a pointer type and an expression
\texttt{e2} with an integer type, the expansion of \texttt{e1 + e2} from
pointer arithmetic to integer arithmetic depends on the type of
\texttt{e2}. The number of bytes to added must be the same kind of
signed or unsigned integer as \texttt{e2}.

\begin{itemize}
\item
  If \texttt{e2} is an unsigned integer, \texttt{e1 + e2} expands to
  \texttt{e1 +\textsubscript{ovf} \sizeof{\var{T}} *\textsubscript{ovf} e2}
\item
  If \texttt{e2} is a signed integer, the expansion of \texttt{e1 + e2}
  must cast \sizeof{\var{T}} to a signed integer. We introduce a
  signed integer type \texttt{signed\_size\_t} that is large enough for
  this cast. \texttt{e1 + e2} expands to \texttt{e1 +\textsubscript{ovf}
  ((signed\_size\_t) \sizeof{\var{T}} *\textsubscript{ovf} e2}. This cast is
  necessary because in C, multiplying a signed integer by an unsigned
  integer implicitly converts the signed integer to be an unsigned
  integer.
\end{itemize}

\subsection{Runtime performance implications}\label{runtime-performance-implications}

There will be concerns about the effect of overflow checks on the speed
of pointer arithmetic using the new pointer types. These concerns are an
empirical question to be settled after implementing and using the new
pointer types. It is unclear what the actual cost will be. First, there
will be sometimes be additional conditions on expressions used in
pointer arithmetic that prevent overflow from occurring. Second,
compiler optimizations often can remove the checks. Third, programmers
can use lightweight invariants to show statically that checks are not
necessary.

In our experience working on an operating system written in managed code
that required these checks, the slowdown was a few percent, even when
\emph{all} arithmetic instructions were checked for overflow too. The
cost of checks was low because it is often the case that checks are
redundant or can be combined into adjacent machine instructions. For
example, in the code \texttt{t = *p; p += 1;} the first dereference of
\texttt{p} implies that \texttt{p} is non-null before the increment.
Otherwise, in a typical C environment, the program would fault at
\texttt{*p}. In the code \texttt{if (p \textless{} hi) \{ p += 1; \}}
the check \texttt{p \textless{} hi} implies that the increment cannot
overflow. The checks are also inexpensive on superscalar processors:
they can be placed so that they are statically predicted by the
processor to never fail.

\section{Relative alignment of \arrayptr\ and \arrayview\ values}\label{relative-alignment-of-arrayux5fptr-and-arrayux5fview-values}

\arrayptrT\ and \arrayviewT pointers provide safe
pointer arithmetic on arrays. The bounds for these pointers usually
describe a range of memory that is exactly the size of some array of T.
The pointers point to an element of the array. In other words, the lower
bound, the upper bound, and pointer are relatively aligned to the type
\var{T}. Given a lower bound \var{lb}, an upper bound \var{ub}, and a
pointer \var{p}, there should exist some integer \var{count} such that
\var{ub} = \var{lb} + \var{count}. In addition, there is either some
integer \var{index} such that \var{p} = \var{lb} + \var{index},
where addition is C pointer arithmetic, or p is null.

The type to which a pointer and its bounds are relatively aligned is
called the relative alignment type. By default, the relative alignment
type for a pointer and its bounds is the referent type. However, the
relative alignment type can be overridden by specifying it explicitly as
part of the bounds. This is useful when describing bounds for the
results of pointers casts. It is necessary when describing bounds for
\arrayptrvoid\ and \arrayviewvoid pointers. The type
\texttt{void} has no defined size, so the default relative alignment is
undefined for \texttt{void}.

When pointers and their bounds are not relatively aligned to the
referent type, the cost of bounds checking increases. We considered
removing the entire concept of relative alignment from the design. We
decided against that because it increases the cost of bounds checking.
Section 15.1 describes proposals that were considered but not chosen.

\section{Program scopes for safe pointer types}\label{program-scopes-for-safe-pointer-types}

To improve program reliability and to simplify understanding programs,
it is desirable to limit code to using only safe pointers. To support
this, we introduce ``checked'' program scopes. The ``checked'' keyword
can be attached to blocks and function definitions. In checked program
scopes, definitions can use only safe pointer types and checked array
types; they cannot use unsafe pointer types and unsafe arrays. On the
other hand, declarations can use unsafe pointer types and unsafe arrays,
provided that the declarations provide a bounds-safe interface.

A new pragma directive BOUNDS\_CHECKED is introduced to control whether
the top-level scope is a checked scope:
\begin{alltt}
#pragma BOUNDS_CHECKED \textit{on-off-switch}
\end{alltt}

Where \texttt{\textit{on-off-switch}} is one of \verb|ON OFF DEFAULT|

By default, function definitions are not checked. A block inherits the
checking properties of its parent. This preserves the meaning of
existing C code.

A checked block is introduced by placing the checked keyword before a
compound block:
\begin{verbatim}
checked 
{
    int a = 5;
    ptr<int> pa = &a;

    int b checked[5][5];
    for (int i = 0; i < 5; i++) {
        for (int j = 0; j < 5; j++) {
            // all references are bounds checked
            b[i][j] = -1;
        }
    }
}
\end{verbatim}

It is rarer for a programmer to need to introduce an unchecked scope. It
is usually needed to allow the use of unsafe pointers within a checked
block. The ``unchecked'' keyword can be used in all the places where the
checked keyword can be used. This example shows the use of an unchecked
block:

\begin{verbatim}
checked 
{
    int a = 5;
    unchecked 
    {
        int *upa = &a;	
        int b[5][5];
        for (int i = 0; i < 5; i++) {
            for (int j = 0; j < 5; j++) {
                // not bounds checked
                b[i][j] = -1;
            }
        }     
    }
 ...
}
\end{verbatim}

In a checked function definition, the body of the function is a checked
block. A checked function definition is declared by placing the checked
keyword before the definition. Here are examples of checked and
unchecked function definitions:

\begin{verbatim}
// checked at the function level: no unsafe pointers can appear in argument
// types, the return type, or the body of the function.
checked int f(ptr<int> p) 
{
    int a = 5;
    ptr<int> pa = &a;
…
}

// unchecked at the function level: Safe and unsafe pointer types can occur 
// in argument types, the return type, or the body of the function
unchecked int f(int *p, ptr<int> r)
{
    int a = 5;
    int *pa = &a;
    ...
}

// f is unchecked by default
int f(int *p, ptr<int> r)
{
    int a = 5;
    int *pa = &a;
    ...
}
\end{verbatim}

When a function call occurs in a checked block, the function being
called does not have to be declared as checked. The notion of whether a
scope is checked or not checked is lexical and the function definition
is a separate lexical scope.

As we add different notions of checking to C programs, we will use the
checked and unchecked keywords for all the different notions of
checking. We may introduce additional keywords to control specific kinds
of checking.

\section{Programmer-inserted dynamic checks}\label{programmer-inserted-dynamic-checks}

A bounds check generates a runtime error if it fails. The ability to
generate a runtime error is not limited to the C implementation. A
programmer can check a Boolean condition and generate a runtime error
using the expression \texttt{dynamic\_check(}\var{e1}\texttt{)}, where
\var{e1} is an integral valued expression. At runtime, \var{e1} is
evaluated. If the result is \texttt{0} (false), a runtime error occurs.
If the result is non-zero (true), no runtime error occurs. Just as with
a bounds check, if a runtime error occurs and a C implementation
provides an error-handling facility, the error-handling facility may be
invoked.

The \texttt{dynamic\_check} expression is similar to an assertion, but
unlike an assertion, it is expected to be used in production or release
versions of software. The \texttt{dynamic\_check} expression is useful
for these reasons:

\begin{itemize}
\item
  It provides an escape hatch for limits of static checking. If a
  programmer knows a condition is true at runtime, yet the static
  checking cannot prove the fact, the programmer can use
  \texttt{dynamic\_check} to show that the condition is true.
\item
  It maintains programmer control: programmers can use unsafe ponters
  and \texttt{dynamic\_check} to write the same code that the compiler
  would generate for safe pointers.
\item
  It gives programmers more control over bounds checks. A programmer can
  place a pre-condition before a loop that ensures that the loop is free
  from dynamic bounds checks, without having to restructure the
  control-flow of the program.
\end{itemize}

The following example illustrates why having an escape hatch from static
checking is useful. Suppose a decoder from a compressed representation
to an uncompressed representation is being converted to use safe
pointers. This example is based on code patterns seen in the Abstract
Syntax Notation (ASN1) parsing code of OpenSSL .

\begin{verbatim}
void decode(char *output_buffer, char *input_buffer, size_t input_len)
{
    char *src = input_buffer;
    char *src_bound = src + input_len;
    char *dst = out_buffer;

    while (src < bound) {
        switch (*current++) {
            case UNCOMPRESSED_BYTES: { 
                // just copy bytes; compression wasn’t useful here.
                size_t len = src[0] + src[1]*256;
                src += 2;
                memcpy(dst, src, len);
                src += len;
                dst += len;
                break;
            }
            case COMPRESSED_INT64: {
                ...
                break;
            }
        ...
    }
}
\end{verbatim}

The caller knows that the destination buffer will be large enough and
that the contents of the source buffer are well-formed. However, these
invariants cannot be expressed using lightweight invariants. These are
complicated high-level invariants that require the use of techniques for
proving functional correctness.

To use safe pointers, the size of the destination buffer must be passed
in and there must be a check before the memcpy that the destination
buffer and source buffer have enough room. We ignore the details of how
the bounds are described for now.

\begin{verbatim}
void decode(array_ptr<char> output_buffer, array_ptr<char> input_buffer, 
            size_t input_len, size_t output_len)
{
    array_ptr<char> src = input_buffer;
    array_ptr<char> src_bound = src + input_len;
    array_ptr<char> dst = out_buffer;
    array_ptr<char> dst_bound = out_buffer + output_len;


    while (src < bound) {
        switch (*current++) {
            case UNCOMPRESSED_BYTES: { 
                size_t len = src[0] + src[1]*256;
                src += 2;
                // need check that dst and src have at least len bytes of
                // space
                memcpy(dst, src, len);
                src += len;
                dst += len;                
                break;
            }
            case COMPRESSED_INT64: {
                ...
                break;
            }
        ...
    }
}
\end{verbatim}

How should that check be written? One approach is to change the
control-flow by inserting if-statements into the program. Something must
be done if the check fails, though. One possibility is to just ignore a
failure. This is bad programming practice because now the program might
fail silently:

\begin{verbatim}
void decode(array_ptr<char> output_buffer, array_ptr<char> input_buffer, 
            size_t input_len, size_t output_len)
{
      ...
            case UNCOMPRESSED_BYTES: { 
                size_t len = src[0] + src[1]*256;
                src += 2;
                // check that dst and src have at least len bytes of
                // space
                if (dst + len >= dst_bound || src + len >= src_bound) {
                    goto failure;
                }
                memcpy(dst, src, len);
                src += len;
                dst += len;                
                break;
            }
   ...
   failure: 
      return;
}
\end{verbatim}

This could be fixed by having \texttt{decode} return a status code
indicating success or failure. That just pushes the problem upward to
the caller and leaves a testing problem. The program should never fail,
so there is no way to test the path.

\begin{verbatim}
int decode(array_ptr<char> output_buffer, array_ptr<char> input_buffer, 
            size_t input_len, size_t output_len)
{
   ...
   failure: 
      return 1;
}
\end{verbatim}

The problems with requiring functions that validate buffer lengths to
return status codes for errors are analyzed by . Annex K of the C
Standard introduced a new set of standard library functions to replace
functions that provide no way to validate their arguments. These
functions return status codes to indicate success or failure A classic
example of a function prone to misuse is \texttt{strcpy(char *dst, const
char *src)}. It copies all bytes in \texttt{src} to \texttt{dst} until
it hits a null byte. If \texttt{src} is missing the null byte or
\texttt{dst} is too small, this causes a buffer overrunn. The new
function \texttt{strcpy\_s} takes an additional size parameter for
\texttt{dst} and has the signature \texttt{errno\_t strcpy\_s(char *dst,
size\_t dest\_len, const char *src)}. O'Donell and Sebor explain how
using these functions is awkward, leading to more complicated and less
efficient code.

In contrast, \texttt{dynamic\_check} allows the checking to be localized
and not propagate upward in the call chain. If the programmer is
correct, the check never fails. If the programmer is incorrect, the
check might fail and invoke error-handling code:

\begin{verbatim}
void decode(array_ptr<char> output_buffer, array_ptr<char> input_buffer, 
            size_t input_len, size_t output_len)
{
      ...
            case UNCOMPRESSED_BYTES: { 
                size_t len = src[0] + src[1]*256;
                src += 2;
                dynamic_check(dst + len < dst_bound && src + len < src_bound);
                memcpy(dst, src, len);
                src += len;
                dst += len;                
                break;
            }
   ...
}
\end{verbatim}

One can argue that it is a problem to have a dynamic point of failure
that leads to error-handling code being invoked. This is the same way
systems treat null pointer dereferences, though, which are a possibility
throughout C code. The alternative of having a program with undefined
behavior is worse.

The following example uses \texttt{dynamic\_check} to eliminate bounds
checks in a loop. It is based on experience hand-optimizing C\# and Java
programs. This kind of example is typically found during a performance
tuning phase of program development. In the example, 
the \verb|: count(|\var{exp}\verb|)| notation indicates that \var{exp} is the
length of the buffer.

\begin{verbatim}
void append(array_ptr<char> dst : count(dst_count),
            array_ptr<char> src : count(src_count), 
            size_t dst_count, size_t src_count)
{ 
    for (size_t i = 0; i < src_count; i++) {
        if (src[i] == marker) {
           break;
        }
        dst[i] = src[i];
    }
}
\end{verbatim}

The highlighted expressions are bounds checked:
\begin{verbatim}
void append(array_ptr<char> dst: count(dest_count), 
            array_ptr<char> src : count(src_count), 
            size_t dst_count, size_t src_count)
{ 
    for (size_t i = 0; i < src_count; i++) {
        if (src[i] == marker) {
           break;
        }
        dst[i] = src[i];
    }
}
\end{verbatim}

It is clear that the accesses to \texttt{src} are in-bounds based on
just information from the for-loop, so a compiler will eliminate those
bounds checks. It is not clear that assignments through \texttt{dst} are
always in bounds, so the check there must remain. It can be eliminated
by adding a \texttt{dynamic\_check}:

\begin{verbatim}
void append(array_ptr<char> dst: count(dest_count), 
            array_ptr<char> src : count(src_count), 
            size_t dst_count, size_t src_count)
{ 
    dynamic_check(src_count <= dst_count);
    for (size_t i = 0; i < src_count; i++) {
        if (src[i] == marker) {
            break;
        }
        dst[i] = src[i];
    }
}
\end{verbatim}

The compiler now knows that \texttt{i \textless{} src\_count
\textless{}= dst\_count}, so it can eliminate the check.

A compiler would not introduce this dynamic\_check because it would
alter the behavior of \texttt{append}. The bounds check on \texttt{dst}
in the original code is done only if a marker is not found in
\texttt{src} and \texttt{src\_count \textgreater{} 0}. A compiler could
try to deduce a precondition for the bounds check failing, but this is
not possible because the precondition depends on the contents of
\texttt{src}. A compiler would have to clone code to maintain the same
behavior. This increase code size, so production compilers do not this
sort of transformation or do it sparingly. Programmer control produces
better results.

\begin{verbatim}
void append(array_ptr<char> dst: count(dest_count), 
            array_ptr<char> src : count(src_count), 
            size_t dst_count, size_t src_count)
{ 
    if (src_count <= dst_count) {
        for (size_t i = 0; i < src_count; i++) {
            if (src[i] == marker) {
                break;
            }
            dst[i] = src[i];  // no bounds check needed
        }   
    else {
        for (size_t i = 0; i < src_count; i++) {
            if (src[i] == marker) {
                break;
            }
            dst[i] = src[i];  // bounds check needed
        }   

    }
}
\end{verbatim}

\section{Changes to undefined behavior}\label{changes-to-undefined-behavior}

C has situations where an expression has undefined behavior or the
meaning of an expression is undefined:

\begin{enumerate}
\item
  Unsafe pointer arithmetic only has defined behavior when the resulting
  pointer points to the same object as the original pointer, or one
  element past the object.
\item
  Unsafe pointer comparison only has defined behavior when comparing
  pointers to the same object (where one or both pointers may point one
  element past the same object).
\item
  Unsafe pointer subtraction only has defined behavior when subtracting
  pointers to the same object (where one or both pointers may point one
  element past the object).
\item
  Arithmetic expression behavior is undefined on signed integer overflow
  and integer division by 0.
\item
  Expressions may have nested assignments within them. The evaluation
  order of side-effects in subexpressions is defined only in specific
  circumstances; otherwise it is undefined. This leads to expressions
  with undefined meaning. There can be multiple assignments to the same
  variable that have no defined evaluation order with respect to each
  other or an assignment and a use of a variable that have no defined
  evaluation order.
\item
  Initializers may have nested assignments within them. These can have
  undefined meanings as well for the same reasons as expressions.
\end{enumerate}

Undefined behavior is different from unspecified behavior, where one of
a number of choices may be made. Unspecified behavior in C includes:

\begin{itemize}
\item
  The order of evaluation of side-effects in expressions (so long as the
  expression does not have undefined behavior).
\item
  The order of evaluation of side-effects in initializers.
\end{itemize}

C also has implementation-defined behavior, which includes:

\begin{itemize}
\item
  The ranges of values for integer, floating-point, and pointer types.
\item
  Data layout, including the sizes of types, padding, and alignment of
  data.
\item
  Some aspects of pointer conversion.
\end{itemize}

It is difficult to reason about the correctness of programs that have
expressions with undefined behavior. One has to make sure that a program
never arrives at a point where behavior is undefined. In practice, this
would mean proving that signed integer overflow can never occur, for
example. For unspecified behavior, one has to reason about all possible
behaviors, such as all possible orders of evaluation. For
implementation-defined behavior, one has to reason about the
implementation-specific behavior or have reasoning that is independent
of the details.

A careful reading of the rules for unsafe pointer comparison implies
that it is impossible to detect an out-of-bounds unsafe pointer in C,
for example. If an unsafe pointer p is not in the valid range for an
object, the pointer comparison is undefined.

To provide for pointer bounds safety, we require that C implementations
provide defined behaviors for unsafe pointer arithmetic operations and
signed integer overflow:

\begin{itemize}
\item
  Unsafe pointers shall be treated as addresses of locations in memory,
  just as safe pointers are treated as addressses. The addresses shall
  be unsigned integers with a defined range of 0 to
  \texttt{UINTPTR\_MAX}:

  \begin{itemize}
  \item
    Comparison of pointers for all different kinds of pointers shall be
    defined as the corresponding integer comparison.
  \item
    Subtraction p - r of two pointers p and r of type T where one
    pointer is a safe pointer and the other is an unsafe pointer shall
    be done following the rules for subtraction of safe pointers,
    treating the unsafe pointer as a safe pointer in those rules.
  \end{itemize}
\end{itemize}

\begin{itemize}
\item
  To be able to maintain pointer bounds safety, it is important that
  signed integer overflow produce a defined value. When a signed integer
  expression produces an out-of-range value, either (1) the operation
  must convert that value to an in-range integer value or (2) the
  expression shall produce a runtime error. The conversion must be a
  function of only the input values of the expression.
\item
  Integer division by 0 shall also produce a runtime error or produce a
  defined value.
\end{itemize}

In the case of a runtime error, program execution cannot continue in a
way the uses the value of the expression that produced the error.

For programs with expressions and initializers with undefined meanings,
those programs must be rejected at translation-time. Section 5.11
describes this in detail.

Of course, there are other ways in which C expressions may have
undefined behavior:

\begin{enumerate}
\item
  By reading or writing memory through an out-of-bounds pointer.
\item
  By storing a value of one type and accessing the value as a different
  type later, when the value is not valid for the different type. A
  program might write bit patterns that do not correspond to valid
  values for a type or write an integer and use it as a pointer later,
  even though the pointer is not within the range of memory for a valid
  object.
\item
  By accessing memory that has been deallocated.
\item
  By using variables or functions with inconsistent declarations across
  different translation units. This can cause the type of a variable or
  a function to be different at the definition and the use. This can be
  addressed with suitable link-time checking.
\end{enumerate}

The aim is to be able to show partial correctness of programs for the
1\textsuperscript{st} item (avoiding out-of-bounds pointer accesses). A
partial correctness guarantee has the form ``assuming X holds, then Y is
true''. Informally, one might say ``assuming that memory allocation and
type casts are correct and that unsafe code never reads or write though
out-of-bounds pointers, then safe code never reads or writes through
out-of-bounds pointers.'' These assumptions can be turned into formal
statements about program behavior at runtime. Given those assumptions,
we might then prove that at runtime safe code never reads or writes
through out-of-bounds pointers.

\chapter{Tracking bounds for variables with \arrayptr\ or incomplete checked array types}\label{tracking-bounds-for-variables-with-arrayux5fptr-or-incomplete-checked-array-types}

A variable whose type is \arrayptr\ that is used to access
memory must have bounds declared for it. In addition, a variable with an
incomplete checked array type also must have bounds declared for it.

For an \arrayptr\ variable, the bounds will be used to check
memory accesses at runtime involving the pointers stored in the variable
or pointers produced by pointer arithmetic that uses those pointers.
Runtime checks can be omitted if a compiler proves that they are
redundant. In addition, for performance-critical code, checks will be
omitted when programmers demonstrate at compile-time that the checks are
redundant (see Section 10.2.6 for details).

\section{Bounds declarations}\label{bounds-declarations}

Bounds are declared using bounds declarations. Bounds declarations have
the form:

\begin{quote}
\var{x} \texttt{:} \var{bounds-exp}
\end{quote}

\var{bounds-exp:}

\begin{quote}
\texttt{count(}\var{non-modifying-exp}\texttt{)}

\bounds{\var{non-modifying-exp}}{\var{non-modifying-exp}}

\boundsnone

\boundsany
\end{quote}

where \var{x} is a variable. There are additional forms for handling
casts and void pointers that are described in Sections 4.5 and 4.6.

A bounds expression describes the memory that can be accessed using the
value of \var{x}, provided that x is not null. Bounds expressions
include counts, pairs that specify an upper bound and lower bound,
\boundsnone, and \boundsany:

\begin{itemize}
\item
  \boundsdecl{\var{x}}{\boundscount{e1}} describes the number of
  elements that are accessible beginning at \var{x}. Only memory that
  is at or above x and below \var{x} \texttt{+} \var{e1} can be
  accessed through \var{x}, where \var{x} \texttt{+} \var{e1} is
  interpreted using \arrayptr\ pointer arithmetic.
\item
  \boundsdecl{\var{x}}{\bounds{\var{e1}}{\var{e2}}}
  describes the range of memory that can be accessed through \var{x}.
  Only memory that is at or above the location specified by \var{e1}
  and below \var{e2} can be accessed through \var{x}.
\item
  \boundsdecl{\var{x}}{\boundsnone} declares that \var{x} has no bounds.
  It is an error at compile-time to attempt to access memory using a
  variable of type \arrayptr\ with no bounds.
\item
  \boundsdecl{\var{x}}{\boundsany} is a special form that readers can
  ignore for now. It is used for null pointers (0 cast to a pointer
  type) and means that \var{x} can have any bounds. Because null
  pointers cannot be used to access memory, they can have any bounds.
\end{itemize}

Bounds expression use ``non-modifying'' expressions. These are a subset
of C expressions that do not modify variables or memory. They include
local variables, parameters, constant expressions, casts, and operators
such as addition, subtraction, and address-of. Section 4.3 describes
non-modifying expressions in detail.

In a bounds declaration of the form \boundsdecl{\var{x}}{\var{bounds-exp}},
\var{x} must have an \arrayptr\ or a checked array type. 
For the form  \boundsdecl{\var{x}}{\boundscount{\var{e1}}},  the type of 
\var{x} cannot be \arrayptrvoid\ and the type of \var{e1} must be an integral type. 
For \boundsdecl{\var{x}}{\bounds{\var{e1}}{\var{e2}}}, \var{e1} and
\var{e2} must have the same \arrayptr\ type. The type of x is
typically the same type as \var{e1} and \var{e2}, but it can be a
different \arrayptr\ or checked array type. Allowing the types
to different is useful for describing the results of pointer casts and
bounds for \arrayptrvoid\ pointers.

For any variable with a bounds declaration, the variable must be
non-null when memory is accessed There is no requirement that an
\arrayptr\ variable stay within its bounds. The requirement is
that the \arrayptr\ variable can only be dereferenced if it is
in bounds. This avoids bound checks on pointer arithmetic.

Count expressions have limits on their ranges to prevent signed integer
overflow and unsigned integer wraparound from affecting size
computations. Section 4.11 explains these limits in detail. The limits
depend on the element type of the \arrayptr\ and the type of the count
expression. For \boundsdecl{\var{x}}{\boundscount{\var{e1}}}, where x
has type \arrayptrT ,
\var{e1} must be greater than or equal to 0. \var{e1} must be less
than the maximum number of an
\arrayptrT\ elements
that can be indexed by an integer whose type matches that of \var{e1}.
If \var{e1} has an unsigned integer type, \var{e1} must be less than
or equal to \texttt{UINTPTR\_MAX/\sizeof{\var{T}}}. If e1 has a
signed integer type, \var{e1} must be \textgreater{}= 0 and less than
or equal to \texttt{INTPTR\_MAX/\sizeof{\var{T}}}.

A bounds declaration \boundsdecl{\var{x}}{\boundscount{\var{e1}}} is an
abbreviation for \boundsdecl{\var{x}}{\bounds{\var{x}}{\var{x} \texttt{+} \var{e1}}} with additional conditions that \var{e1}
\texttt{>= 0 \&\& \var{e1} <= (char *)}
\var{ub}\texttt{.} \var{ub} is either
\texttt{UINTPTR\_MAX/\sizeof{\var{T}}} or
\texttt{INTPTR\_MAX/\sizeof{\var{T}}}. The conditions may
require programmers to add additional checks at memory allocations to
show that \var{e1} is in range. The conditions have advantages. At
object uses, they provide scaffolding to show that expressions based on
element counts do not overflow or wraparound.

\emph{For now, no easy way is provided to specify conditional bounds.
This could be provided by adding a clause to bounds-exp that uses the
same syntax as C conditional expressions: }

\var{bounds-exp: }

\begin{quote}
\var{non-modifying-exp ? bounds-exp : bounds-exp}
\end{quote}

\emph{This makes describing the system and checking properties more
complex, so it is a feature that we will consider later.}

The meaning and correctness of bounds are based on the C semantics for
pointers and pointer arithmetic. At runtime, any non-null pointer in C
has an object associated with it. The association starts when a pointer
is created by a memory allocation operation, address-of expression, or
conversion of an array variable to a pointer-typed expression. It flows
through to pointers that result from pointer arithmetic. At runtime, the
bounds for a pointer must be the bounds of the object associated with
the pointer or a subrange of those bounds. The correctness of declared
bounds information at compile-time is ensured by making allocation sites
and address-of expressions be creators of bounds information and by
propagating bounds with the pointers with which they are associated.
Bounds can be narrowed during propagation, but they cannot be widened.

The meaning of a bounds expression can be defined more precisely. At
runtime, given an expression \var{e} with a bounds expression
\bounds{\var{lb}}{\var{ub}}, let the runtime
values of \var{e}, \var{lb}, and \var{ub} be \var{ev}, \var{lbv},
and \var{ubv}, respectively. The value ev will be \texttt{0} (null) or
have been derived via a sequence of operations from a pointer to some
object \var{obj} with \bounds{\var{low}}{\var{high}}.
The following statement will be true at runtime:
\var{ev} \texttt{== 0 \textbar{}\textbar{} (}\var{low}
\texttt{<=} \var{lbv} \texttt{\&\&} ubv \texttt{<=}
\var{high}\texttt{)}. In other words, if \var{ev} is null, the bounds
may or may not be valid. If \var{ev} is non-null, the bounds must be
valid. This implies that any access to memory where \var{ev} \texttt{!=
0 \&\&} lbv \texttt{<=} \var{ev} \texttt{\&\&} \var{ev}
\texttt{<} \var{ubv} will be within the bounds of \var{obj}.

In this section, to simplify the description, it is assumed that none of
the \arrayptr\ variables that have bounds declarations have
their addresses taken. It is also assumed that the values of variables
whose addresses are taken are not used in bounds declarations. It is
acceptable to use the address of an address-taken variable in a bounds
declaration. This is provided that the resulting address is not used to
access memory in the bounds declaration (that is, indirectly access the
value of a variable). For example, given the declaration \texttt{int x},
the expression \texttt{\&x} may appear in a bounds expression. Section
11 handles pointers to \arrayptr\ types and bounds expressions
that dereference address-taken variables.

\subsection{Using bounds declarations}\label{using-bounds-declarations}

Bounds declarations may be added to declarations and statements using
\keyword{where} clauses. They also may be placed inline at a declaration
by following the declarator with \texttt{:} \var{bounds-exp}. In that
case, the bounds expression applies to the variable that is the subject
of the declarator. By making the bounds be part of the program, this
preserves the control and efficiency of C. The bounds declarations will
be checked statically for correctness using rules described in Section
0.

\subsection{Bounds declarations at variable declarations}\label{bounds-declarations-at-variable-declarations}

Here are some examples of bounds declarations as part of variable
declarations. The first function sums the integers stored in memory
between \texttt{start} and \texttt{end}, where the integer stored at
\texttt{end} is not included.

\begin{verbatim}
int sum(array_ptr<int> start : bounds(start, end), array_ptr<int> end)
{ 
    int result = 0;
    array_ptr<int> current : bounds(start, end) = start;
    while (current < end) {
       result += *current++; // *current is bounds-checked.  The checking ensures 
                             // that current is within the bounds of (start, end) 
                             // at the memory access.                           
    }
    return result;
}
\end{verbatim}

This can be written using \keyword{where} clauses as well, at the
inconvenience of typing variable names twice in declarations:

\begin{verbatim}
int sum(array_ptr<int> start where start : bounds(start, end), array_ptr<int> end)
{ 
    int result = 0;
    array_ptr<int> current where current : bounds(start, end) = start;
    while (current < end) {
       result += *current++;                          
    }
    return result;
}
\end{verbatim}

This function searches for an integer in an array. If it finds the
integer, it returns the index in the array where the integer occurs.
Otherwise, it returns -1.

\begin{verbatim}
int find(int key, array_ptr<int> a : count(len), int len)
{
    for (int i = 0; i < len; i++) {
         if (a[i] == key) { // a[i] is bounds checked.  The checking
                            // ensures that i is between 0 and len.
             return i;
         }
    }
    return -1;
}
\end{verbatim}

If the code was written assuming that it would always find the integer,
bounds-checking would detect the buffer overrun in the case the integer
was not present:

\begin{verbatim}
int bad_find(int key, array_ptr<int> a : count(len), int len)
{
    int i = 0;
    while (1) {
        if (a[i] == key) { // The bounds check will fail when i == len
            return i;
        }
        i++;
    }
    return -1;
}

\end{verbatim}

This function adds two arrays of 2x2 arrays.

\begin{verbatim}
int add(int a checked[][2][2] : count(len), int b checked[][2][2] : count(len), 
        int len) 
{
    for (int i = 0; i < len; i++) {
        // All array accesses are bounds checked
        a[i][0][0] += b[i][0][0]; 
        a[i][0][1] += b[i][0][1];
        a[i][1][0] += b[i][1][0];
        a[i][1][1] += b[i][1][1];
    }
}
\end{verbatim}

Externally-scoped variables can have bounds as well:

\begin{verbatim}
// external-scoped variables that hold a buffer and its length
int buflen = 0;
array_ptr<int> buf : count(buflen) = NULL;

int sum()
{
    int result = 0;
    for (int i = 0; i < buflen; i++) {
        result += buf[i]; // bounds checked
    }
    return result;
}
\end{verbatim}

This is a declaration of a function that copies bytes provided that the
pointers and lengths are aligned:
\begin{verbatim}
int aligned_memcpy(array<char> dest where dest : count(len) && aligned(dest, 4),
                   array<char> src where src : count(len) && aligned(src, 4),
                   int len where len % 4 == 0);
\end{verbatim}

The declaration can be shortened using in-line bounds declarations to:

\begin{verbatim}
int aligned_memcpy(array<char> dest : count(len) where aligned(dest, 4),
                   array<char> src : count(len) where aligned(src, 4),
                   int len where len % 4 == 0);
\end{verbatim}

This example is adapted from the OpenSSL library. The signature of a
method has been modified to have bounds declaration. The size of input
and output buffers must be multiples of 16 because the function operates
on 16-byte chunks of data.

\begin{verbatim}
void AES_cbc_encrypt(array_ptr<const unsigned char> in : count(len),
                     array_ptr<unsigned char> out : count(len),
                     size_t len where len % 16 == 0,
                     ptr<const AES_KEY> key,
                     array_ptr<unsigned char> ivec : count(16),
                     const int enc);
\end{verbatim}

\subsection{Bounds declarations at expression statements}\label{bounds-declarations-at-expression-statements}

Programmers may wish to delay initializing variables or may wish to
change the bounds of a variable in the middle of a function. This can be
done using bounds declarations attached to expression statements. In C,
an expression is converted to a statement by placing a semi-colon after
the expression. This creates an expression statement. A \keyword{where}
clause may be added before the terminating semi-colon of an expression
statement.

Any variable that has bounds declared at an expression statement has
dataflow-sensitive bounds throughout the body of the function. Only
automatic variables can have bounds declared for them at expression
statements. It does not make sense to have dataflow-sensitive bounds for
externally-scoped variables and variables with static or thread storage.
The bounds extend to the next assignment to any variable in the bounds
declaration, with some exceptions for pointer incrementing or
decrementing. Section 4.5 describes the extent of flow-sensitive bounds
in more detail.

Here is a simple example that illustrates bounds declarations at
statements. The variable \texttt{tmp} first points to an array with 5
elements and then points to an array with 10 elements; the bounds are
adjusted accordingly.

\begin{verbatim}
void f() 
{
   int x[5];
   int y[10];
   array_ptr<int> tmp;
   tmp = x where tmp : count(5);
   ...
   tmp = y where tmp : count(10);
}
\end{verbatim}

In the second example, an \arrayptr\ c and its length are initialized
lazily to either a or b, depending on the another parameter.

\begin{verbatim}
/* use either a or b depending on val */
int choose(int val, array_ptr<int> a : count(alen), int alen,
                    array_ptr<int> b : count(blen), int blen) 
{
    array_ptr<int> c ;
    int clen;
    if (val) {
        clen = alen;
        c = a
        where c : count(clen);
    }
    else {
        clen = blen;
        c = b
        where c : count(clen);
    }    
    … 
}
\end{verbatim}

Declaring bounds at assignments supports updating of variables that are
used in the bounds for an existing \arrayptr\ variable. New
bounds for the \arrayptr\ variable can be declared to reflect
the update. Consider the following example:

\begin{verbatim}
/* sum integers stored between start and end, where end is not included */
int sum(array_ptr<int> start : bounds(start, end), array_ptr<int> end)
{ 
    ...
    // Adjusting end. Can declare new bounds for start at the assignment
    end = end – 1 where start : bounds(start, end + 1);
}
\end{verbatim}

\subsubsection{Bounds declarations for return values}\label{bounds-declarations-for-return-values}

Bounds may be declared for the value returned by a function. The
parameter list can be followed by either \texttt{:} \var{bounds-exp} or
a \keyword{where} clause. The special variable \keyword{return\_value} can
be used to refer to the return value. The parameters are considered in
scope for the bounds declaration or where clause. Any parameters
occurring in the return bounds declaration or \keyword{where} clause may
not be modified by the body of the function.

The following example show the find function from Section 4.1.2 modified
to return a pointer to the element instead of the index:

\begin{verbatim}
array_ptr<int> find(int key, array_ptr<int> a : count(len), int len)
 : bounds(a, a + len)
{
    for (int i = 0; i < len; i++) {
         if (a[i] == key) { // a[i] is bounds checked.  The checking
                            // ensures that i is between 0 and len.
             return &a[i];
         }
    }
    return NULL;
}
\end{verbatim}

This also can be written as:

\begin{verbatim}
array_ptr<int> find(int key, array_ptr<int> a : count(len), int len)
  where return_value : bounds(a, a + len)
{
   ...
}
Here is the declaration of a function that allocates memory:

\begin{verbatim}
array_ptr<char> alloc(size_t size) : count(size);
\end{verbatim}

\subsection{Invariant bounds declarations}\label{invariant-bounds-declarations}

Variables that only have bounds declared for them at their definition
have bounds that are invariants. Any assignments to the variable
\emph{or} variables in the bounds expression must maintain the
invariant. The invariant can be suspended temporarily during updates.

Because externally-scoped \arrayptr variables can have bounds declared
for them only at their definitions, by definition their bounds are
always invariants.

\subsection{Lexical hiding of variables}\label{lexical-hiding-of-variables}

A nested lexical scope is not allowed to hide a variable used in a
bounds declaration within the extent of the bounds declaration. This
prevents programs from accidentally invalidating the bounds declaration:

\begin{verbatim}
/* illegal function */
void bad(int i) 
{
    array_ptr<int> x : count(i) = malloc ((sizeof(int) * i);
    {
        int x = 5;     // hide x
        i = INT_MAX;   // subvert bounds
    }
    x[random()] = 0xbad;
}
\end{verbatim}

\subsection{Storage class-related requirements}\label{storage-class-related-requirements}

Local variables with static storage class or thread storage class can
have only bounds declarations with bounds expressions that use variables
with the same storage class or variables that are declared
\texttt{const}. The memory for static variables and thread variables
persists across exit and reentry from functions and blocks. It follows
that the bounds information must persist also.

Local variables with automatic storage class can have bounds
declarations with bounds expressions that use variables with automatic,
static, or thread storage class. However, the extent of local variable
bounds declarations that use variables with external linkage ends at
function calls, unless the variables with external linkage are declared
\texttt{const}. This is because the function calls may modify the
variables with external linkage.

\section{Variables at external scope}\label{variables-at-external-scope}

If there are multiple declarations of a variable with external scope in
a translation unit, the bounds declaration and/or where clauses for the
variable must be identical at all the declarations. This prevents the
specification of different bounds for global variables in the same
compilation unit. Any variables with external scope that have bounds
declarations and/or where clauses must have the same bounds declaration
and where clauses in all translation units.

All places in a program that may write to a variable with external scope
also must have the same view of the bounds declarations involving that
variable. This allows static checking to ensure that bounds declarations
remain valid.

To see what can go wrong without this requirement, consider the
following example:

\begin{verbatim}
extern int num;

void update_num(int i)
{
    num = i;
}

extern array_ptr<int> ap : count(num);

void go()
{
    update_num(INT_MAX);
    ap[100] = 0xbad;
}

// define count and ap
int num = 10;
int arr[10];
array_ptr<int> ap = arr : count(num);
\end{verbatim}

The checking of bounds declarations does not know at
\texttt{update\_num} that \texttt{ap} needs to have at least \texttt{i}
elements when count is updated, allowing a programmer to accidentally
invalidate bounds declarations.

A simple rule enforces this restriction. Given the initial declaration
in a translation unit of a variable with external scope that has a
\keyword{where} clause, there cannot be any function definitions between
the declaration and the initial declarations of other variables used in
the \keyword{where} clause. It is possible for the initial declaration of
a variable with external scope to occur within the body of a function.
In that case, there cannot be any statements or declarations of
non-external variables with initializers between the initial declaration
and the initial declarations of other variables used in the
\keyword{where} clause.

\section{Syntax changes}\label{syntax-changes}

The grammar from the ``C Programming Language'' is extended to include
in-line bounds declarations and \keyword{where} clauses for declarations:

\var{init-declarator} :

\begin{quote}
\var{declarator inline-bounds-specifier\textsubscript{opt}
where-clause\textsubscript{opt}}

\var{declarator inline-bounds-specifier\textsubscript{opt}
where-clause\textsubscript{opt}} \texttt{=} \var{initializer
where-clause\textsubscript{opt}}

\ldots{}
\end{quote}

\var{parameter-declaration} :

\begin{quote}
\var{declaration-specifiers declarator}
\var{inline-bounds-specifier\textsubscript{opt}
where-clause\textsubscript{opt}}
\end{quote}

\var{inline-bounds-specifier:}

\begin{quote}
\texttt{:} \var{bounds-exp}
\end{quote}

\var{where-clause}:

\begin{quote}
\keyword{where} \var{facts}
\end{quote}

\var{facts}:

\begin{quote}
\var{fact}
\end{quote}

\var{fact} \texttt{\&\&} \var{facts}

\var{fact: }

\var{variable inline-bounds-specifier}

\begin{quote}
\var{variable relop non-modifying-exp}

\var{non-modifying-exp relop variable}
\end{quote}

where \var{relop} is one of \verb|<|, \verb|<=|, \verb|==|,
\verb|!=|, \verb|>=|, \verb|>|.,

In addition, the grammar is updated to allow where clauses at expression
statements:

\var{expression-statement}:

\begin{quote}
\var{expression\textsubscript{opt}
where-clause\textsubscript{opt}}\texttt{;}
\end{quote}

\section{Operations allowed in non-modifying expressions}\label{operations-allowed-in-non-modifying-expressions}

As mentioned earlier, non-modifying expressions are a subset of C
expressions that do not modify variables or memory. The subexpressions
of a non-modifying expression must themselves be non-modifying
expressions. Non-modifying expressions include the following kinds of
expressions:

\begin{itemize}
\item
  Local variables and parameter variables
\item
  Constant expressions
\item
  Cast expressions
\item
  Address-of expressions
\item
  Unary plus/minus expressions
\item
  One's complement expressions
\item
  Logical negation expressions
\item
  Sizeof expressions
\item
  Multiplicative expressions (*, /, \%)
\item
  Additive expressions (+, -))
\item
  Shift expressions (\textgreater{}\textgreater{},
  \textless{}\textless{})
\item
  Relational and equality expressions (\textless{}, \textgreater{},
  \textless{}=, \textgreater{}=, ==, !=)
\item
  Bitwise expressions: and, or, exclusive-or
\item
  Logical AND (\&\&) and logical OR (\textbar{}\textbar{}) expressions
\item
  Conditional expressions
\item
  Access to special members of \arrayview\ types
  (\texttt{current}, \texttt{lower\_bound}, and \texttt{upper\_bound})
\end{itemize}

They also include expressions that access members of types or memory:

\begin{itemize}
\item
  Member references (to members of structures or unions) (the `.'
  operator)
\item
  Indirect member dereferences (-\textgreater{})
\end{itemize}

\begin{itemize}
\item
  Pointer dereferences
\end{itemize}

The static checking of the validity of bounds declarations restricts the
usage of non-modifying expressions that read memory when memory is being
modified.

Non-modifying expressions do not include:

\begin{itemize}
\item
  Assignment expressions (for the reason that evaluating them repeatedly
  at bounds checks would produce unexpected results)
\item
  Pre-increment/decrement and post-increment/decrement expressions
  (these are forms of assignments)
\item
  Volatile variables
\item
  Function calls (because these may contain assignments that modify
  variables or memory)
\item
  Comma expressions (because bounds expressions do not allow side
  effects, these can always be simplified to the second expression)
\end{itemize}

Programmers are advised to use simple non-modifying expressions because
they may be fully re-evaluated at every bounds check involving the
bounds expression. More complicated bounds expressions are allowed
because programmers might find them useful.

\section{Bounds declarations for results of casts between \arrayptr\ types}\label{bounds-declarations-for-results-of-casts-between-arrayux5fptr-types}

Typically \arrayptr\ pointers and their bounds are relatively
aligned. Together, they represent a view of an array of \var{T}, where
the pointer has type
\arrayptrT. The
bounds specify a range of memory that is exactly the size of some array
of T and the pointer points exactly at an element of that array. For
example, support short ints are 2 bytes in size and 
{\texttt{\boundsdecl{x}{\bounds{y}{z}}}}, where the types of \texttt{x},
\texttt{y}, \texttt{z} are \arrayptrinst{\texttt{short int}} .

This illustration shows 12 consecutive bytes in memory beginning at
address a\textsubscript{0}, where \texttt{y} and \texttt{z} bound a
3-element array and \texttt{z} points to the middle of the array. The
memory occuped by the 3-element array is shaded in light purple, and the
element pointed to by x is also cross-hatched. The distances in bytes
between \texttt{x}, \texttt{y}, and \texttt{z} are all multiples of 2,
the size of \texttt{short int}.

This simplifies bounds checking because there is no concern during a
bounds check that a pointer will access memory at the end or beginning
of the array that partially overlaps with the bounds. Suppose, for
example, that \texttt{x} was not relatively aligned to \texttt{y} and
\texttt{z} and points at a\textsubscript{7}. The object pointed to by
\texttt{x} now straddles the array bounds. This illustration shows this:

When \texttt{x} is not relatively aligned, the bounds check for x
becomes more expensive. With relative alignment, the bounds check is
\texttt{y <= x} and \texttt{x < z}. Without relative
alignment, the check for the upper bound needs to compute the highest
address that will be accessed using x. For this example, the highest
address accessed will be
\texttt{(\arrayptrchar) x + \sizeof{short int} - 1}, so the check becomes 
\texttt{y <= x} and \texttt{x + 1 < z}.

A pointer cast can create a pointer that is not relatively aligned to
the referent type of the pointer type. This can happen when:

\begin{enumerate}
\item
  A pointer is cast to be a pointer to a larger type. For example, if an
  \arrayptrinst{\texttt{short int}}\ is cast to be an
  \arrayptrint , the resulting pointer
  may not be relatively aligned to its bounds for \texttt{int}. In the
  first illustration where \texttt{x} points to a4,
  \arrayptrint\ \texttt{x} is not relatively
  aligned to \texttt{y} for \texttt{int}.
\item
  A pointer is cast to be a pointer to a smaller type, and the size of
  the original referent type is not a multiple of the size of the
  smaller type. For example, a pointer to a 12-byte struct may not be
  relatively aligned to its bounds when it is cast to a pointer to an
  8-byte struct.
\end{enumerate}

The use of struct types to illustrate the second case is intentional.
For most C implementations, the second case never happens for casts
involving scalar types. Scalar types are powers of 2 in size (1, 2, 4,
and 8 bytes). This means that for a cast from a larger scalar type to a
smaller scalar type, the larger scalar type will always be a multiple of
the smaller scalar type.

In general, an
\arrayptrT\ that is
relatively aligned for \var{T} is guaranteed to be relatively aligned
for \arrayptrinst{\textit{S}} only
when \sizeof{\var{S}} is a common factor of
\sizeof{\var{T}}. In other cases, programmers need to
supply additional information using program invariants to show that an
\arrayptr\ pointer is relatively aligned to its bounds. Of
course, programmers who are doing casts to use operations on larger
types instead of operations on smaller types (for example, \texttt{int}
instead of \texttt{char}) usually already are doing these checks.

\subsection{Representing relative alignment in bounds declarations}\label{representing-relative-alignment-in-bounds-declarations}

To be able to reason about situations where an
\arrayptrT\ is not
relatively aligned to its bounds for \var{T}, there needs to be a way
to represent this in the program. Bounds expressions are extended with
an optional relative alignment clause:

\var{bounds-exp:}

\var{\ldots{}}

\begin{quote}
\bounds{\var{non-modifying-exp}}{\var{non-modifying-exp}}
        \var{relative-alignment-clause\textsubscript{opt}}
\end{quote}

\var{relative-alignment-clause:}

\begin{quote}
\relalign{\var{type}}

\relalignval{\var{constant-exp}}
\end{quote}

This clause is only added to bounds pairs because (by definition) count
expressions always describe pointers that are relatively aligned to
their bounds. The optional relative alignment clause specifies a
relative alignment type \var{T} or the required relative alignment of
the pointer and its bounds and in bytes. Given 
\boundsdecl{\var{x}}{\boundsrel{\var{e1}}{\var{e2}}{\var{T}}},
\texttt{(((\arrayptrchar) \var{x}) - ((\arrayptrchar) \var{e1})) \%
        \sizeof{\var{T}} == 0} and
(((\arrayptrchar) \var{e2}\texttt{) --
(\arrayptrchar\ } \var{x}\texttt{)) \%
sizeof(}\var{T}\texttt{) == 0} must be true. If the number of bytes is
specified, \sizeof{\var{T}} is replaced by the
constant expression.

The relative alignment clause \relalign{\var{type}}
is just short-hand for \relalignval{\texttt{sizeof(\var{type})}}.

\subsection{Examples of uses of bounds declarations that specify relative alignment}\label{examples-of-uses-of-bounds-declarations-that-specify-relative-alignment}

Here are examples of the use of relative alignment clauses in
conjunction with pointer casts. In the first example, there is an
\arrayptr\ to raw data consisting of characters. The pointer is
cast to be an \arrayptrint . However,
the relative alignment remains \texttt{char}:

\begin{verbatim}
// cast data to be an array_ptr<int> instead
array_ptr<char> raw_data : bounds(lower, upper) = ...
array_ptr<int> data : bounds(lower, upper) rel_align(char) = (array_ptr<int>) data;
\end{verbatim}

In the second example, the code starts with an
\arrayptrint. The pointer is cast to
be an \arrayptrchar. That
\arrayptr\ is then cast back to be an
\arrayptrint . In the second cast, the
\texttt{rel\_align} clause is omitted because the default relative
alignment for an \arrayptrint\ is
\texttt{int}.

\begin{verbatim}
array_ptr<int> data : bounds(lower, upper) = ...
array_ptr<char> byte_data : bounds(lower, upper) rel_align(int) = (array_ptr<char>) data;
array_ptr<int> finish : bounds(lower, upper) = (array_ptr(int>) byte_data;
\end{verbatim}

The third example illustrates a subtlety when an
\arrayptrT\ has a
relative alignment that is larger than the actual size of \var{T}. The
use of pointer arithmetic may require that relative alignment be
lowered. Suppose that the size of \texttt{short int} is 2 bytes and the
size of an \texttt{int} is 4 bytes:

\begin{verbatim}
array_ptr<int> d : bounds(lower, upper) = ...
array_ptr<short int> e : bounds(lower, upper) rel_align(int) = (array_ptr<short int>) d;
array_ptr<short int> f : bounds(lower, upper) rel_align(short int) = e + 1;
\end{verbatim}

While \texttt{e} can have relative alignment of \texttt{int}, \texttt{f}
cannot because pointer arithmetic is done at the granularity of
\texttt{short int}.

The final example illustrates the use of a dynamic check to allow an
\arrayptrchar\ to be cast to a larger
type with a larger relative alignment. It assumes that
\texttt{sizeof(int)} is 4 and that the memory pointed to by
\texttt{dest} and \texttt{src} does not overlap. The code for a function
that does a memory copy and uses an optimized aligned copy if possible
could be written as:

\begin{verbatim}
void copy(array_ptr<char> dest : bounds(dest, dest + num),
          array_ptr<char> src : bounds(src, src + num), 
          size_t num)
{
  if (num % 4 == 0) {
    array_ptr<int> aligned_dest : bounds(dest, dest + num) rel_align(char) =
        (array_ptr<int>) dest;
    array_ptr<int> aligned_src : bounds(src, src + num) rel_align(char) =
        (array_ptr<int>) src;
    int n = num / 4;
    for (int i = 0; i<n; i++) {
       aligned_dest[i] = aligned_src[i];
    }
 }
 else {
    for (int i = 0; i<n; i++) {
       dest[i] = src[i];
    }
}
\end{verbatim}

However, \texttt{num \% 4 == 0} implies that \texttt{aligned\_dest} and
\texttt{align\_src} are relatively aligned to their bounds, so the
relative alignment can be changed:

\begin{verbatim}
void copy(array_ptr<char> dest : bounds(dest, dest + num),
          array_ptr<char> src : bounds(src, src + num), 
          size_t num)
{
  if (num % 4 == 0) {
    // num % 4 == 0 implies that aligned_dest and aligned_src are relatively
    // aligned to their bounds.
    array_ptr<int> aligned_dest : bounds(dest, dest + num) rel_align(int) =
        (array_ptr<int>) dest;
    array_ptr<int> aligned_src : bounds(src, src + num) rel_align(int) =
        (array_ptr<int>) src;
    int n = num / 4;
    for (int i = 0; i<n; i++) {
       aligned_dest[i] = aligned_src[i];
    }
 }
 else  
   ...
}
\end{verbatim}

Of course, the \texttt{rel\_align(int)} is redundant and can be omitted.

\subsection{Relative alignment and constant counts}\label{relative-alignment-and-constant-counts}

When an \arrayptr\ with a constant count is cast to another
\arrayptr\ type, all the facts about relative alignment are
easily checkable at compile time. This means that a pointer to data can
easily be cast to be a pointer to a larger type. Suppose in the
following example that the size of integers is 4 bytes. A pointer to 8
bytes of characters can be converted easily a pointer to 2 integers:

\begin{verbatim}
char a[] = "0123456";
array_ptr<char> p : count(8) = a;
array_ptr<int> r : count(2) = (array_ptr<int>) p;
\end{verbatim}

\section{Pointers to void}\label{pointers-to-void}

The definition of count expressions poses a problem for
\arrayptrvoid. \texttt{Void} is an
incomplete type and has no defined size, which means that count
expressions are ill-defined for
\arrayptrvoid. To address this, a
variant of count expressions where counts are given in terms of bytes is
added:

\var{bounds-exp:}

\begin{quote}
\ldots{}

\boundsbytecount{\var{non-modifying-exp}}
\end{quote}

The bounds declaration \boundsdecl{\var{x}, \boundsbytecount{\var{e1}}}
describes the number of bytes that are accessible beginning at \var{x}. 
Only memory that is at or above \var{x} and below \texttt{(\arrayptrchar)}
\var{x} \texttt{+} \var{e1} can be accessed through \var{x}. The type
of \var{e1} must be an integral type. This bounds declaration is a synonym for 
\boundsdecl{\var{x}}
           {\boundsrel{(\arrayptrchar) \var{x}}
                      {(\arrayptrchar) (\var{x} \texttt{+} \var{e1})}
                      {\texttt{char}}}

The standard C library functions for malloc, memcmp, and memcpy will be
given bounds-safe interfaces to avoid breaking existing code as
described in Section 6.3. However, if they were to return safe pointer
types, their bounds declarations would be:

\begin{verbatim}
array_ptr<void> malloc(size_t num) : byte_count(num);

int memcmp(array_ptr<const void> dest : byte_count(num),
           array_ptr<const void> src : byte_count(num), size_t num);

array_ptr<void> memcpy(array_ptr<void> dest : byte_count(num),
                       array_ptr<const void> src : byte_count(num), size_t num) :
    byte_count(num);
\end{verbatim}

The return value of \texttt{memcpy} is \texttt{dest} . The bounds for
this return value could be more precisely described by:

\begin{verbatim}
array_ptr<void> memcpy(array_ptr<void> dest : byte_count(num),
                       array_ptr<void> src : byte_count(num), size_t num) :
  bounds((<array_ptr<char>) dest, (array_ptr<char>) dest + num) rel_align(char)
\end{verbatim}

\section{Extent of dataflow-sensitive bounds declarations}\label{extent-of-dataflow-sensitive-bounds-declarations}

Variables that have bounds declared for them at expression statements
have dataflow-sensitive bounds declarations. There are two aspects two
dataflow-sensitive bounds: extent and consistency. The extent of a
bounds declaration is the part of the program to which a bounds
declaration applies. Within the extent of a bounds declaration, the
bounds for the variable for memory dereferences are given by the bounds
declaration. Consistency is that all the bounds declarations flowing to
a statement agree with each other.

As mentioned in Section 4.1.3, a dataflow-sensitive bounds declaration
extends to the next assignment to any variable occurring in the bounds
declaration. There are exceptions for pointer increment and decrement.
If an assignment

\begin{itemize}
\item
  increments or decrements a pointer variable (\texttt{++},
  \texttt{-\/-}, \texttt{+=}, \texttt{-=}), and
\item
  the bounds expression for the pointer variable has the form
  \bounds{\var{e1}}{\var{e2}}, and
\item
  the pointer variable does not occur in \var{e1} or \var{e2},
\end{itemize}

then no bounds declaration is needed at the statement containing the
assignment.

The reason for this exception is that there is obviously a connection
between the old and the new value of the pointer in the case of a
pointer increment or decrement. These kinds of assignment statements
move a pointer within an area of memory and it is reasonable to assume
that bounds remain the same. However, with other kinds of assignments,
the before and after values may be unrelated, so re-using bounds could
lead to unexpected bounds checks failures.

\subsection{Definition of extent for statements}\label{definition-of-extent-for-statements}

We first define the set of bounds declarations that apply to a function
component, where a function component is an expression statement,
variable declaration, or part of a compound statement.

For any bounds declaration for a variable \var{v}, if

\begin{enumerate}
\item
  There is some path from the bounds declaration to the function
  component, and
\item
  \var{v} occurs in the function component, and
\item
  There is no other bounds decla;ration for \var{v} along the path
\end{enumerate}

then

\begin{enumerate}
\item
  If one of the variables in the bounds expression is out-of-scope at
  the component, the declaration \boundsdecl{\var{v}}{\boundsnone}
  applies, otherwise
\item
  If one of the expressions or statements on the path modifies a
  variable occurring in the bounds declaration, and

  \begin{enumerate}
  \item
    The expression or statement is not a pointer increment or decrement
    of the variable \var{v}, or
  \item
    v occurs in the bounds expression, or
  \item
    the bounds expression has the form \texttt{count},
    \boundsnone, or \boundsany
  \end{enumerate}
then the declaration \boundsdecl{\var{v}}{boundsnone} applies.
Otherwise,
\item
  The bounds declaration applies.
\end{enumerate}

 \subsection{Consistency}\label{consistency}

These conditions ensure the consistency of bounds declarations:

\begin{enumerate}
\item
  \emph{Agreement of bounds declarations}: If a variable occurring in a
  function component has more than one bounds declaration that applies
  to it at the component, then all the bounds declarations applying to
  it at the component must be syntactically identical. This avoids
  ambiguity about which bounds declaration applies to an occurrence of a
  variable. It an error for the bounds declarations to disagree.
\item
  \emph{No missing bounds declarations}: If a bounds declaration for a
  variable applies to a function component, then all paths from the
  beginning of the function to the function component must have a bounds
  declaration for the variable along each path.
\end{enumerate}

\subsection{Examples}\label{examples:consistency}

In the following example, a function modifies a variable \texttt{end}
used in the bounds expression for the variable \texttt{start} and then
uses the variable \texttt{start} after that. This function will be
rejected by the compiler.

\begin{verbatim}
/* buggy function */
/* sum integers stored between start and end, where end is not included */
int sum(array_ptr<int> start : bounds(start, end), array_ptr<int> end)
{ 
    end = end + 1; // Bounds of start becomes none because a variable in the bounds
                   // expression is modified
    start[5]  = 0; // Program is rejected
   ...
}
\end{verbatim}

A correct function declares new bounds for \texttt{start}:

\begin{verbatim}
/* sum integers stored between start and end, where end is not included */
int sum(array_ptr<int> start : bounds(start, end), array_ptr<int> end)
{ 
    end = end + 1
    where start : bounds(start, end – 1);
    start[5] = 0; // program accepted by compiler; may fail bounds check at 
                  // run time
    ...
}
\end{verbatim}

There are two bounds declaration for \texttt{start} here: one at the
parameter declaration and one at the first assignment in the function.
The bounds declaration at the parameter and its extent is highlighted in
light blue. The bounds declaration at the assignment and its extent is
highlighted in yellow:

\begin{verbatim}
/* sum integers stored between start and end, where end is not included */
int sum(array_ptr<int> start : bounds(start, end), array_ptr<int> end)
{ 
    start[5] = 0; // bounds checked using (start, end)
    end = end + 1
    where start : bounds(start, end - 1);
    start[5] = 0; // bounds checked using (start, end -1)
}
\end{verbatim}

The following example expands on the choose function earlier. There are
4 explicit bounds declarations for \texttt{c}. The bounds declarations
and their extents have been color-coded. Three bounds declarations for c
have the form \texttt{c : count(clen)}. They must be syntactically
identical because there are statements that they cover in common. Their
extents are highlighted in light blue. There is one case where
\texttt{c} is being incremented and the length is being decremented.
This temporarily violates the bounds declaration \texttt{c :
count(clen)}, so a new bounds declaration is declared while this is the
case. This extent is highlighted in green.

\begin{verbatim}
/* use either a or b depending on val */
int choose(int val, array_ptr<int> a : count(alen), int alen,
                    array_ptr<int> b : count(blen), int blen) 
{
    array_ptr<int> c;
    int clen;
    int result = 0;

    if (val) {
        clen = alen;
        c = a
        where c : count(clen);
    }
    else {
        clen = blen;
        c = b
        where c : count(clen);
    }
    if (clen > 1) {
        result = c[0];
    }

    if (cond  && clen > 1) {
        c++
        where c : count(clen – 1);
        clen = clen – 1;
        where c : count(clen);
        result += c[0];
    }
    
    ...
    return result;
}
\end{verbatim}

\subsection{Computing the extent of flow-sensitive bounds declarations}\label{computing-the-extent-of-flow-sensitive-bounds-declarations}

This section is primarily for compiler implementers. Those readers
primarily interested in the language may skip it safely. It describes
how a compiler can determine efficiently which bounds declaration
applies to uses of variables that have flow-sensitive bounds
declaration.

The inference process can be done for all \arrayptr\ variables
in a function with dataflow-sensitive bounds using a forward dataflow
analysis . The bounds declarations for all occurrences of
\arrayptr\ variables in a function can be computed in
worst-case O(N\^{}2 * M) time. N is the number of statements in a
function and M is the number of \arrayptr\ variables in the
function. In functions that do not have loops in their control-flow, the
dataflow analysis can be done in O(N*M) time.

The dataflow analysis uses a lattice of values, assigning one lattice
value to each variable at each program point in the function. The
lattice of values includes singleton values consisting of the bounds
expressions in the flow-sensitive bounds declaration for variables in
the function, \boundsnone (indicating absence of bounds
information), and \texttt{Top} (indicating contradiction or error):

For an assignment to an \arrayptr\ variable, the existing
lattice value for the \arrayptr\ variable is killed. A new
lattice value is generated for the \arrayptr\ variable. If the
assignment declares bounds for the \arrayptr\ variable, the new
lattice value is the bounds expression in the bounds declaration.
Otherwise, it is the value \boundsnone.

A declaration of a variable is handled similarly to an assignment,
except that there will not be any lattice value to kill. Lexical hiding
of variables involved in bounds declarations is not permitted. If the
declaration declares bounds for the \arrayptr\ variable, the
new lattice value is the bounds expression in the bounds declaration.
Otherwise, it is the value \boundsnone.

A variable going out of scope kills any existing lattice values in which
that variable occurs.

At control-flow split points, the lattice values for the
\arrayptr\ variables flow to all branches of the split. The
propagation is dataflow-sensitive but not control-flow sensitive. At
control-flow join points, the lattice values are unioned (moving upward
in the lattice). If the lattice values for an \arrayptr\
variable are not the same, the resulting value is \texttt{Top}.

\section{Bounds declarations and loops}\label{bounds-declarations-and-loops}

Loops often operate on variables declared outside of loops. They may
read the variables and then update the variables. When these variables
are \arrayptr\ variables they must have bounds and the bound
must be loop invariants.

The common case is that the bounds expression is invariant across all
iterations of the loop. The earlier \texttt{sum} example illustrates
this. The variable \texttt{current} is declared with bounds before a
loop. The loop modifies \texttt{current}, but the bounds for
\texttt{current} do not change:

\begin{verbatim}
/* sum integers stored between start and end, where end is not included */
int sum(array_ptr<int> start where start : bounds(start, end), array_ptr<int> end)
{ 
    int sum = 0;
    array_ptr<int> current : (start, end) = start;

    while (current < end) {
       sum = *current;
       current += 1; // bounds do not need to be redeclared here.
    }
}
\end{verbatim}

A programmer can declare bounds expressions that change on each
iteration of the loop. This may be necessary if an \arrayptr\
variable is modified to point to different memory during a loop
iteration. It also may be desirable for performance reasons. In either
case, there needs to be a loop-invariant bounds declaration.

The following example illustrates this. It is an implementation of
lexicographic comparisons of two arrays, using one pointer to scan each
array. The bounds at the variable declarations serve as loop invariant
bounds. The lower bounds for a variable are declared using the variable
itself, to reduce register pressure in the loop. This can enable
compilers to generate better code. Note that an optimizing compiler will
eliminate the runtime bounds checks easily.

\begin{verbatim}
/* lexicographic comparison of two arrays of integers */
int compare(array_ptr<int> x : bounds(x, x_end), 
            array_ptr<int> y : bounds(y, y_end)
            array_ptr<int> x_end,
            array_ptr<int> y_end)
{ 
    while (x < x_end && y < y_end) {
        if (*x == *y) {  // bounds check: x >= x && x < x_end; easily optimizable
                         // bounds check: y >= y && y < y_end; easily optimizable
            x++;
            y++;
        }
        else if (*x < *y) {  // bounds checks here are easily optimizable as well
            return -1;
        }
        else {
            return 1;
        }
    }
    if (x == x_end && y == y_end) {
        return 0;
    }
    else if (x != x_end) {
        return 1;
    }
    else {
        return -1; 
    }
}
\end{verbatim}

\section{Bundling statements and declarations}\label{bundling-statements-and-declarations}

Invariant bounds declarations must be valid at the end of every
statement. The effect of the statement must preserve the validity of the
bounds declarations. This is too restrictive when multiple statements
are used to update variables involved in a bounds declaration.

For example, suppose a function was added to the earlier sum example
that allowed for the buffer to be reallocated:
\begin{verbatim}
// external-scoped variables that hold a buffer and its length
int buflen = 0;
array_ptr<int> buf : count(buflen) = NULL;

int sum()
{
   int result = 0;
   for (int i = 0; i < buflen; i++) {
       result += buf[i]; // bounds checked
   }
   return result;
}

/* buggy resize function */
void resize(int len) 
{
    array_ptr<int> tmp = malloc(sizeof(int) * len);
    copy(tmp, buf, buflen);
    buflen = len;  // fails at compile-time because the bounds are not true
    buf = tmp;
}
\end{verbatim}
In this example, the update to \texttt{buflen} fails compile-time
checking because the bounds declaration is not true after the
assignment. If the two updates are combined into one statement, though,
the checking would succeed.

\begin{verbatim}
void resize(int len) 
{
    array_ptr<int> tmp = malloc(sizeof(int) * len);
    copy(tmp, buf, buflen);
    buflen = len, buf = tmp; // succeeds, surprisingly
}
\end{verbatim}

This is an interesting difference between regular C, where

\begin{verbatim}
expr1, expr2;
\end{verbatim}

is always the same as:

\begin{verbatim}
expr1;
expr2;
\end{verbatim}

To allow invariant bounds to be checked after several statements or
initializing declarations, we introduce the notion of a bundled block.
Assignment statements and declarations can be grouped together using a
bundled block. Bounds declarations must be valid only at the end of the
block:

\begin{verbatim}
if (cond  && clen > 1) {
    bundle {
        c++;
        clen = clen - 1;
    }
}
\end{verbatim}

There is some subtlety with bundled blocks and function calls. The
bounds declarations for any static variables must be valid before any
function call in a bundle. This is because the called function may make
use of the static variables. It will assume that the bounds declaration
holds when it uses the static variables. In general, programmers may
deal with this requirement by using the idiom of storing function call
results in temporary variables and updating static variables \textit{en
masse} after the required function calls have been made.

The C syntax for is extended with:

\var{statement:}

\begin{quote}
\var{bundled-statement;}
\end{quote}

\var{bundled-statement:}

\begin{quote}
bundled \var{\{ bundled-item-list\textsubscript{opt}} \}
\end{quote}

\var{bundled-item-list:}

\begin{quote}
\var{bundled-item}

\var{bundled-item-list bundled-item}
\end{quote}

\var{bundled-item:}

\begin{quote}
\var{declaration}

\var{expression-statement}
\end{quote}

\section{Bounds checks at pointer dereferences}\label{bounds-checks-at-pointer-dereferences}

Given *\var{e1}, where \var{e1} is an expression of type
\arrayptr, the compiler determines the bounds for \var{e1}
following the rules in Section 5.1. Special rules are followed in
\texttt{bundled} blocks to determine the bounds for \var{e1}. The
compiler inserts checks before the memory pointed to by \var{e1} is
read or written that \var{e1} is non-null and that the value of
\var{e1} is in bounds.

If \boundsdecl{\var{e1}}{\bounds{\var{e2}}{\var{e3}}},
the compiler inserts a runtime check that \texttt{\var{e2} <= \var{e1} \&\&
\var{e1} < \var{e3}}. If the runtime check fails, the program
will be terminated by the runtime system or in, systems that support it,
a runtime exception will be raised.

If the default relative alignment has been overridden and
\boundsdecl{\var{e1}}{\boundsrel{\var{e2}}{\var{e3}}{\var{T}}}, the compiler checks whether
\texttt{sizeof(referent-type(\var{e1})) <= sizeof(\var{T})}. If it is, it inserts the same
runtime check as before. Otherwise, it inserts a runtime check that
\texttt{\var{e2} <= \var{e1} \&\& \var{e1} + sizeof(\var{T}) - 1 < \var{e3}}

Consider as an example, \verb|z = *x;| where 
\verb+x : bounds(x, x + c)|. The compiler will produce code of the form

\begin{quote}
\begin{verbatim}
dynamic_check(x != null);
dynamic_check(x <= x && x < x + c);
z = *t1;
\end{verbatim}
\end{quote}

Suppose \boundsdecl{x}{\boundscount{\texttt{c}}} instead. The bounds declaration 
\boundsdecl{\var{e1}}{\boundscount{\var{e2}}} is a synonym for 
\boundsdecl{\var{e1}}{\bounds{\var{e1}}{\var{e1} \texttt{+} \var{e2}}}.
The runtime check becomes \texttt{e1 \textless{}= e1 \textless{} e1 + e2}.
In this example, the check becomes \texttt{x \textless{}= x \textless{}
x + c}. The condition \texttt{x \textless{}= x} is trivially true. The
condition \texttt{x \textless{} x + c} simplifies to \texttt{0
\textless{} c}, that is \texttt{c \textgreater{} 0}, which is what one
would expect.

Now suppose pointer arithmetic is involved and \texttt{z = *(x+5)}. The
bounds of \texttt{x + 5} will be the same as the bounds of \texttt{x}.
The expression \texttt{x + 5} must point into the same object as
\texttt{x} for this to be a valid memory access. This means that
\boundsdecl{\texttt{x + 5}}{\bounds{\texttt{x}}{texttt{x+c}}}.
The compiler will produce code of the form:

\begin{quote}
\begin{verbatim}
dynamic_check(x != null);
t1 = x + 5;
dynamic_check(t1 != null && x <= t1 && t1 < x + c);
z = *t1;
\end{verbatim}
\end{quote}

If \verb|x : count(c)|, the compiler will expand this to
\verb|bounds(x, x + c)| before computing the bounds of \verb|x + 5|
and proceed as before.

Array subscripting works as expected. For \texttt{e1[e2]}, the
compiler computes the bounds of \texttt{e1}. The compiler inserts
runtime checks that \texttt{e1 + e2} is within this bounds. For example,
given \verb|x[5]| where \verb|x : bounds(x, x + c)|, the
compiler inserts runtime checks that \verb|x <= x + 5 < x + c|. 
The runtime checks simplify to \verb|5 < c|.

\subsection{Evaluation of bounds at bounds checks}\label{evaluation-of-bounds-at-bounds-checks}

The preceding example raises a subtle point, which is when bounds
expressions are evaluated. Consider the following code:

\begin{verbatim}
array_ptr<int> x;
x = malloc ((sizeof(int) * 5)
where x : bounds(x, x + 5);
\end{verbatim}

When should \texttt{x + 5} be evaluated? If it is evaluated eagerly,
then \texttt{malloc} returning null on a failure to allocate will cause
a null pointer arithmetic failure immediately. To avoid this problem,
the evaluation of a bounds expression in a bounds declaration is
deferred until a bounds check uses the bounds expression.

\section{Size computations for memory allocation and integer overflow or wraparound}\label{size-computations-for-memory-allocation-and-integer-overflow-or-wraparound}

When objects are allocated dynamically in C, programmers have to compute
the amount of memory to allocate for the objects. It is well-known that
integer overflow or wraparound in these computations can lead to buffer
overruns . In Checked C, the explicit size computations are not enough
to imply that the bounds for a newly-allocated object are valid.
Additional side conditions that deal with integer overflow or wraparound
are needed.

This section informally examines why and the additional conditions that
are needed. We start by looking at an allocation using malloc with an
old-style \texttt{char *} return type and a bounds declaration:

\begin{verbatim}
extern char *malloc(size_t s) : count(s);
\end{verbatim}

An array of type T is allocated with:

\begin{verbatim}
array_ptr<T> p : count(e1) = (T) malloc(sizeof(T) * e1);
\end{verbatim}

The size computation in the count expression differs subtly from the
explicit computation on the right-hand side. In the count expression,
arithmetic with overflow checking is used, while the explicit
computation does not have overflow checking. Intuitively, this leads to
a mismatch when overflow or wraparound can happen, which causes static
checking to fail.

We expand the count expression to integer arithmetic to make its size
computation clear. \texttt{count(e1)} expands to \bounds{p}{p + e1}. 
ollowing the rules in Section 3.4.2, the expansion of \texttt{p +
e1} from pointer arithmetic to integer arithmetic depends on the type of
\texttt{e1}.

\begin{itemize}
\item
  If \texttt{e1} is an unsigned integer, \texttt{p + e1} expands to
  \texttt{p +\textsubscript{ovf} sizeof(T) *\textsubscript{ovf} e1}
\item
  If \texttt{e1} is a signed integer, \texttt{p + e1} expands to
  \texttt{p +\textsubscript{ovf} ((signed\_size\_t) sizeof(T))
  *\textsubscript{ovf} e1}.
\end{itemize}

The number of bytes added to \texttt{p} is the size computation of the
count expression. We can compare the size computations and see when the
values differ. We add casts for any implicit conversions that would
occur in the \texttt{malloc} size computation also:

\begin{longtable}[c]{@{}llll@{}}
\toprule
Type of e1 & Count size computation & \texttt{malloc} size computation &
Values differ?\tabularnewline
\midrule
\endhead
Unsigned integer & \texttt{sizeof(T) *\textsubscript{ovf} e1} &
\texttt{sizeof(T) * e1} & On overflow\tabularnewline
Signed integer & \texttt{((signed\_size\_t) sizeof(T))
*\textsubscript{ovf} e1} & \texttt{sizeof(T) * (size\_t) e1} & On
overflow or when e1 \textless{} 0.\tabularnewline
\bottomrule
\end{longtable}

For correctness, we want the count size computation and the
\texttt{malloc} size computations to produce identical values. This
implies that malloc did allocate the number of bytes expected by the
count size computation. We add conditions on \texttt{e1} to do this:

\begin{longtable}[c]{@{}ll@{}}
\toprule
Type of e1 & Restrictions\tabularnewline
\midrule
\endhead
Unsigned integer & \texttt{e1 \textless{}=
UINT\_MAX/sizeof(T)}\tabularnewline
Signed integer & \texttt{e1 \textgreater{}= 0 and e1 \textless{}=
INT\_MAX/sizeof(T)}\tabularnewline
\bottomrule
\end{longtable}

This has an interesting implication for any function that allocates an
array of \var{T}. If the count of elements is constant, of course these
conditions are trivial. If the constant is non-constant, the function
must do the following checks:

\begin{itemize}
\item
  If the count is a signed integer, the function must check that the
  count \textgreater{}= 0 before trying to allocate the array.
\item
  If \var{T} is larger than 1 byte, the function must check that the
  count is less than the upper bound as well.
\end{itemize}

When retrofitting existing code to use safe pointers, the code may be
unprepared for overflow or wraparound to happen during allocation. This
suggests that uses of \texttt{malloc} should be replaced by slightly
higher-level functions that takes the element count and the size of
elements and handle overflow. C already has a function that is suitable
for unsigned integer counts:

\begin{verbatim}
void *calloc(size_t nobj, size_t size);
\end{verbatim}

A signed version is needed too:

\begin{verbatim}
void *signed_calloc(signed_size_t nobj, size_t size);
\end{verbatim}

\chapter{Checking validity of bounds declarations for variables}\label{checking-validity-of-bounds-declarations-for-variables}

This section describes basic rules for determining the validity of
bounds declarations in a C translation unit. In general, these rules do
not include any inference steps. Inference steps for reasoning about
bounds are described in Section 10.

Section 5.1 describes how to determine the bounds for an expression of
type \arrayptr\ that does not have any assignments within it.
We start with a set of bounds that are true about variables before the
evaluation of the expression, called the context, and describe the
bounds for the value of the expression.

Section 5.3 then describes handling assignment expressions, assuming
that no assignments are nested within the expression. For an assignment
expression, we must determine the updated context in addition to the
value of the expression. The updated context contains new bounds for any
variables assigned to by the expression.

Section 5.4 combines the concepts and describes handling expressions
with nested assignments expressions.

Section 5.5 describes how to validate expression statements. Section 5.8
describes validating function call arguments.

Because this section covers bounds for \arrayptr\ variables,
not data structures with \arrayptr\ data, certain expressions
are not covered here. This includes member references and expressions
that load or store \arrayptr\ values through pointers. These
expressions are covered in Sections 7, 9, and
11.  Section 4.10 does discuss how to insert bounds checking at uses of the
indirection operator (\texttt{*}). This is different than discussing the
bounds of the values \emph{returned} or \emph{stored} through the
indirection operator.

\section{Reducing the number of syntactic cases}\label{reducing-the-number-of-syntactic-cases}

To simplify checking, in-line return bounds expressions are replaced
with the form that uses a name for the return value. The form
f(\ldots{})\texttt{:} \var{e1} is changed to f(\ldots{}) \keyword{where}
\texttt{return\_value :} \var{e1}. The \texttt{count} and
\texttt{byte\_count} bounds expressions are also replaced with their
equivalent \texttt{bounds} forms. The form \var{x} :
\texttt{count(}\var{e1}\texttt{)} is replaced with \var{x} \texttt{:}
\bounds{\var{x}}{\var{x} \texttt{+} \var{e1}} and \var{x} :
\texttt{byte\_count(}\var{e1}\texttt{)} is replaced with \var{x}
\texttt{:} \arrayptrchar\
\var{x}\texttt{,} \texttt{(\arrayptrchar )}
\var{x} \texttt{+} \var{e1}\texttt{)}. For now, we ignore the
additional side conditions on count expressions. Checking of these
conditions will be addressed in Section 10.

Finally, relative alignment is made explicit for all bounds
declarations: \boundsdecl{\var{x}}{\bounds{\var{e2}}{\var{e3}}} is expanded to
\boundsdecl{\var{x}}{\boundsrelval{\var{e2}}{\var{e3}}{\texttt{sizeof(typeof(\var{x}))}}}.
For code without explicit or implicit casts of \arrayptr s, relative
alignment can be ignored.

In the rules below, we sometimes use shorter syntactic forms for
brevity. The shorter forms should be replaced to the full forms before
using the rules.

\section{Inferring valid bounds for expressions without nested assignment expressions}\label{inferring-valid-bounds-for-expressions-without-nested-assignment-expressions}

We first discuss determining valid bounds for expressions that do not
have assignment expressions nested within them. The bounds for an
expression is always determined with respect to a context (bounds for
variables read by the expression). We will use \texttt{:-} to denote the
valid bounds for an expression. The notation \boundsinfer{\var{e}}{\var{bounds-exp}}
means that expression \var{e} has valid bounds \var{bounds-exp}.

At times, we need to discuss bounds that are given in terms of the value
of the current expression. For example, a function call expression may
return an \arrayptr\ pointer to an array of constant size
\var{n}. The bounds for that pointer value would be (the
\arrayptr\ pointer, the \arrayptr\ pointer +
\var{n}). We use the special variable \texttt{current\_expr\_value} to
denote the ``current value of the expression.''\footnote{We are open to
  suggestions on the name for this special symbol. We considered the
  term `self', but chose not to use because it is anthromorphic and not
  particularly descriptive. We also considered the term `this', but that
  has specific meaning to programmers who also use object-oriented
  languages, so it is likely to cause confusion.} The bounds for an
expression may involve using the bounds for a subexpression where the
special variable \texttt{current\_expr\_value} occurs. If the ``current
value'' of the expression changes, the uses of
\texttt{current\_expr\_value} from subexpressions must be adjusted to
counter the change. Bookkeeping rules for making this adjustment will be
described in sections that treat expressions with subexpressions.

\subsection{Null pointers}
\label{null-pointers}

The bounds for 0 is the \texttt{any} bounds:

\boundsinfer{0}{\boundsany}

\subsection{Variables}
\label{variables}

Suppose there is a use of some variable \var{x}.

\begin{itemize}
\item
  If \var{x} has type \arrayptr, the bounds are the result of
  the analysis in Section 4.7.4 for this occurrence of \var{x}.
\item
  If \var{x} has type \ptrT, 
  \boundsinfer{\var{x}}{\boundsrel{\var{x}}{\var{x} \texttt{+ 1}}{\var{T}}}.
   On the right-hand side, \var{x} is reinterpreted as having \arrayptr\ type.
\item
  If \var{x} has type
  \arrayviewT, 
  \boundsinfer{\var{x}}{\boundsrel{\var{x}\texttt{.lower\_bound},
                                   \var{x}\texttt{.upper\_bound},
                                   \var{T}}}
\item
  If \var{x} has an array type with a known number of elements \var{n}
  such that the variable is being converted implicitly to a pointer
  type, the bounds are  \boundsinfer{\var{x}}{\boundscount{\var{n}}}.
\item
  Otherwise \var{x} has \boundsnone.
\end{itemize}


\subsection{Addresses of variables}\label{addresses-of-variables}

A variable with type \var{T} whose address is taken is considered to be
an array of one element:

\boundsinfer{\texttt{\&var{x}}} 
            {\boundsrel{\texttt{\&\var{x}}}{\texttt{\& \var{x} + 1}}{\var{T}}}.

\subsection{Function calls}\label{function-calls}

Let \var{f} be the name of a function that returns an
\arrayptr\ value (pointers to functions will be handled later).
Suppose there is a function call expression of the form
\var{f}\texttt{(}\var{e1 \ldots{} en}\texttt{)}:

\begin{enumerate}
\item
  If \var{f} has a bounds declaration for the return value of the form
  \texttt{return\_value :} \var{exp1}, then

  \begin{itemize}
  \item
    Any arguments that correspond to formal parameters occurring in
    \var{exp1} must be valid non-modifying expressions. If they are
    not, \boundsinfer{\var{f}\texttt{(\var{e1} \ldots{} \var{en})}}{\boundsnone}.
  \item
    Otherwise, substitute \texttt{\var{e1} \ldots{} \var{en}} for the formal
    parameters of \var{f} occurring in \var{exp1}. Also substitute the
    special symbol \texttt{expr\_current\_value} for
    \texttt{return\_value}. These substitutions produce \var{exp2}.
    \boundsinfer{\var{f}\texttt{(\var{e1} \ldots{} \var{en})}}{\var{exp2}}.
  \end{itemize}
\item
  If \var{f} does not have a bounds declaration for its return value,
  then \boundsinfer{\var{f}\texttt{(\var{e1} \ldots{} \var{en})}}{\boundsnone}.
\end{enumerate}

The special variable \texttt{return\_value} may appear \var{exp1}. It
is the value of the function call expression, so it is replaced with the
special variable \texttt{expr\_current\_value}.

There needs to be validation that the bounds for argument expressions
match the required bounds for formal parameters. This is described in
Section 5.8.

The following code provides examples of function call expressions where
bounds need to be computed. In the code, the programmer wraps a call to
\texttt{malloc} in an allocation helper, \texttt{alloc\_helper}. The
function \texttt{alloc\_helper} returns an \arrayptr\ value
that is passed an argument to \texttt{init}, which initializes the array
and returns the \arrayptr\ value.
\begin{verbatim}
array_ptr<int> alloc_helper(int n) : count(n)
{
       array_ptr<int> result : count(n) = malloc((sizeof(int) * n);
       return result;
}

array_ptr<int> init(array_ptr<int> target : count(s), 
                    int s) : count(s)
{
    for (int i = 0; i < count; i++) {
         target[i] = i;
    }

    return target;
}

void go(int size) 
{
    array_ptr<int> x : count(size) = init(alloc_helper(size), size);
    ...
}
\end{verbatim}

First, syntactic forms for bounds expressions are expanded to eliminate
count epxressions and in-line return expressions, as well as make
relative alignment explicit.

\begin{verbatim}
array_ptr<int> alloc_helper(int n)
where return_value : bounds(return_value, return_value + n) rel_align(int)
{
       array_ptr<int> result : bounds(result, result + n) rel_align(int) =
         malloc((sizeof(int) * n);
       return result;
}

array_ptr<int> init(array_ptr<int> target :bounds(target, target + s) rel_align(int), 
                    int s) 
where return_value : bounds(return_value, return_value + s) rel_align(int)
{
    for (int i = 0; i < count; i++) {
         target[i] = i;
    }

    return target;
}

void go(int size) 
{
    array_ptr<int> x : bounds(x, x + size) rel_align(int) = 
      init(alloc_helper(size), size);
    ...
}
\end{verbatim}

The valid bounds for the call to \texttt{init(alloc\_helper(size),
size)} in \texttt{go} are computed using the return bounds for
\texttt{init}:

\begin{verbatim}
    return_value : bounds(return_value, return_value + s) rel_align(int)
\end{verbatim}

First, there is a check that all the actual arguments corresponding to
the formal parameters used by the return bounds expression are valid
non-modifying bounds expressions. This check succeeds even though the
first actual argument \texttt{alloc\_helper(size)} is not a valid bounds
expression. The formal parameter \texttt{target} is not used by the
return bounds expression.

Next, the actual arguments are substituted for the formal parameters and
\texttt{current\_expr\_value} is substituted for \texttt{return\_value}.
The argument \texttt{size} is substituted for \texttt{s}, producing
\begin{verbatim}
    init(alloc_helper(size), size) :- bounds(current_expr_value, current_expr_value + size) rel_align(int)
\end{verbatim}

It would not be possible to represent the bounds if \texttt{size} were a
function call too:
\begin{verbatim}
    array_ptr<int> x = init(alloc_helper(getsize()), getsize());
\end{verbatim}

Function calls are not valid in bounds expressions:

\begin{verbatim}
    bounds(current_expr_value, current_expr_value + getsize())  // illegal
\end{verbatim}

The solution would be to assign the result of \texttt{getsize(}) to a
variable:
\begin{verbatim}
   int tmp = getsize();
   array_ptr<int> x = init(alloc_helper(tmp), tmp);
\end{verbatim}

The parameters to the call to init will need to be validated also. This
will require determining the valid bounds for \texttt{alloc\_helper(size)}. The
return bounds for \texttt{alloc\_helper} are used:
\begin{verbatim}
   return_value : bounds(return_value, return_value + n) rel_align(int)
\end{verbatim}

First, there is a check that the actual arguments that correspond to
formal parameters used in the return bounds are valid non-modifying
expressions. The only argument is the variable size, so this check
succeeds. Next, size is substituted for n and current\_expr\_value is
substituted for return\_value, producing:
\begin{verbatim}
   alloc_helper(size) :- bounds(current_expr_value, current_expr_value + size) 
                         rel_align(int)
\end{verbatim}

\subsection{Pointer arithmetic}\label{pointer-arithmetic}

The range of memory accessible through pointer arithmetic expressions
remains unchanged from the underlying pointer. In other words, for
\boundsinfer{\var{x}}{\var{bounds-exp}}, the bounds expression for any
pointer arithmetic involving \var{x} is the same as the one for
\var{x}. This is because that C semantics for pointer arithmetic is
that if \var{x} points to an object at runtime, any pointer arithmetic
involving \var{x} must produce a pointer to the same object. The bounds
of the object in memory are not changed by the pointer arithmetic.

We first cover the typical situation where the relative alignment type
for a pointer in a pointer operation matches the referent type of the
pointer. Given a pointer operation of the form \var{x op e1}, where x
has an \arrayptr\ type, \var{e1} has an integral type, and
\var{op} is addition or subtraction, the memory that can be accessed
through \var{x op e1} is the same memory that can be accessed through
\var{x}:

\begin{itemize}
\item
  If \var{x} is a pointer to \var{T} and 
  \boundsinfer{\var{x}}{\boundsrel{\var{e2}}{\var{e3}}{\var{T}}},
  then \boundsinfer{\var{x} \var{op} \var{e1}}{\boundsrel{\var{e2}}{\var{e3}}{var{T}}}.
\end{itemize}

This can be extended to pointer operations of the form \var{e4 op e1},
where \var{e4} has type
\arrayptrT\ as
follows:

\begin{itemize}
\item
  If \var{e4} is a pointer to \var{T} and 
  \boundsinfer{\var{e4}}{\boundsrel{\var{e2}}{\var{e3}}{\var{T}}}
  then \boundsinfer{\var{e4 op e1}}{\boundsrel{\var{e2}}{\var{e3}}{\var{T}}}
\end{itemize}

Here are is the full rule that handles the situation where the relative
alignment of the pointer differs from the size of the referent type of
the pointer. GCD computes the greatest common divisor of two integers.
The prior rules are just special cases of this rule:

\begin{quote}
If \var{e4} is a pointer to \var{T} and 
\boundsinfer{\var{e4}}
            {\boundsrel{\var{e2}}
                       {\var{e3}}
                       {\var{c}}}
then \boundsinfer{\var{e4 op e1}}
                 {\boundsrel{\var{e2}}
                            {\var{e3}}
                            {\texttt{GCD(\var{c}, sizeof(\var{T}))}}}.
\end{quote}

\subsubsection{Bounds for unsafe pointer arithmetic}
\label{bounds-for-unsafe-pointer-arithmetic}

Pointer arithmetic involving an \arrayptr\ value checks that
the value is non-null and generates a runtime error if it is. This check
is important because a null pointer may have invalid bounds (this
follows from the definition of the meaning of bounds in Section 4.1). It
prevents a null pointer with invalid bounds from being used to create a
non-null pointer with invalid bounds, which could then be used to access
memory.

Because the meaning of unsafe pointers has not changed, pointer
arithmetic involving a null unsafe pointer may not generate a runtime
error. The rules for array\_ptr pointer arithmetic can be applied to
unsafe pointer arithmetic, however, provided that a side condition that
the pointer expression is non-null is added:

\begin{quote}
If \var{e4} is a pointer to \var{T} and it can be proved that
\var{e4} \texttt{!= 0} and 
\boundsinfer{\var{e4}}{\boundsrel{\var{e2}}{\var{e3}}}{\var{c}}, then
\boundsinfer{\var{e4 op e1}}{\boundsrel{\var{e2}}{\var{e3}}
                                            {\texttt{gcd(\var{c},\sizeof{\var{T}})}}}.
\end{quote}

Section 10 provides a general framework for checking side-conditions as
part of checking bounds declarations.

\subsubsection{Treatment of expr\_current\_value variable in bounds for
pointer arithmetic
expressions}\label{treatment-of-exprux5fcurrentux5fvalue-variable-in-bounds-for-pointer-arithmetic-expressions}

If the special variable \texttt{expr\_current\_value} occurs in
\bounds{\var{e2}}{\var{e3}}, then
\texttt{expr\_current\_value} must be adjusted as follows:

\begin{itemize}
\item
  If op is \texttt{+}, then substitute \texttt{expr\_current\_value -}
  \var{e1} for all occurrences of \texttt{expr\_current\_value} in
  \bounds{\var{e2}}{\var{e3}}
\item
  If op is \texttt{-}, substitute \texttt{expr\_current\_value +}
  \var{e1} for all occurrences of \texttt{expr\_current\_value} in
  \bounds{\var{e2}}{\var{e3}}.
\end{itemize}

The reasoning behind this that the current value of the expression has
changed as the result of \texttt{op} \var{e1}. An adjustment in the
opposite direction of equal magnitude must be made for occurrences of
\texttt{expr\_current\_value}.

The following example illustrates the treatment of
\texttt{expr\_current\_value}. Consider the prior example that had a
function called \texttt{alloc\_helper} that returned some
newly-allocated memory. Suppose there is an expression that offsets a
pointer returned by a call to \texttt{alloc\_helper}.

\begin{verbatim}
   alloc_helper(size) + 2
\end{verbatim}

To compute the bounds for this expression, first the valid bounds for
\texttt{alloc\_helper(size)} are computed:

\begin{verbatim}
   alloc_helper(size) :- bounds(expr_current_value, expr_current_value + size)
\end{verbatim}

Next, \texttt{expr\_current\_value - 2} is substituted for
\texttt{expr\_current\_value}, yielding:

\begin{verbatim}
   alloc_helper(size) + 2 :- (expr_current_value - 2, expr_current_value - 2 + size)
\end{verbatim}

Now, suppose the pointer is being adjusted to insert some blank padding
at the beginning of the newly-allocated object. We can remove the
occurrence of \texttt{expr\_current\_value - 2} in the upper bound by
over-allocating in the expression:

\begin{verbatim}
   alloc_helper(size + 2) + 2
\end{verbatim}

The valid bounds for \texttt{alloc\_helper(size + 2)} are:

\begin{verbatim}
   alloc_helper(size + 2) :- bound(expr_current_value, expr_current_value + size + 2)
\end{verbatim}

The valid bounds for the entire expression are:

\begin{verbatim}
    alloc_helper(size + 2) + 2 :- bounds(expr_current_value - 2,
                                         expr_current_value - 2 + size + 2)
\end{verbatim}

which can be simplified to:

\begin{verbatim}
    alloc_helper(size + 2) + 2 :- bounds(expr_current_value - 2, 
                                         expr_current_value + size)
\end{verbatim}

As we will explain in Section 10, it is fine to narrow a bounds by
adding a positive constant to the lower bounds. This allows us to adjust
the bounds to what would be desired when extra padding is inserted:

\begin{verbatim}
    alloc_helper(size + 2) + 2 :- bounds(expr_current_value, 
                                         expr_current_value + size)
\end{verbatim}

\subsection{Cast expressions}\label{cast-expressions}

Given a cast expression of the form \texttt{(\var{T})} \var{e},
the bounds for \var{e} are determined. The bounds for
\var{e} are used as the bounds for the entire expression.

If the special variable \texttt{expr\_current\_value} appears in the
bounds for \var{e},

\begin{itemize}
\item
  If T is an integral type large enough to hold a pointer or a pointer
  type, let \var{S} be the type of \var{e}. The expression
  \texttt{((\var{S}) expr\_current\_value)} is substituted for
  all occurrences of \texttt{expr\_current\_value}.
\item
  Otherwise, the bounds of \var{e} are  altered to \boundsnone.
\end{itemize}
  
\subsection{Conditional expressions}\label{conditional-expressions}

Given an expression of the form \var{e1} \texttt{?} \var{e2}
\texttt{:} \var{e3}, the bounds for \var{e2} and \var{e3} are
determined. They must be syntactically identical (after putting the
bounds into a normal form). The bounds for \var{e2} are used as the
bounds for the entire expression.

If the special variable \texttt{expr\_current\_value} occurs in the
bounds for \var{e2}, it is left unchanged. The conditional expression
does not change the value returned by one if its branches, so no
adjustment to \texttt{expr\_current\_value} is needed.

\emph{This is an expression where a conditional bounds expression could
be used to represent the resulting range. Another alternative that work
with current syntax would be to create upper/lower-bound expressions
that use e1 such as (e1 ? lower-bound(e2) : lower-bound(e3), e1 ?
upper-bound(e2) : upper-bound(e3). For now, we defer discussion of both
alternatives. }

\subsection{Comma expressions}\label{comma-expressions}

Given an expression of the form \var{e1} \texttt{,} \var{e2}, the
bounds for \var{e2} are determined. The bounds for \var{e2} are used
as the bounds for the entire expression.

If the special variable \texttt{expr\_current\_value} occurs in the
bounds for \var{e2}, it is left unchanged.

\section{Validity of bounds declarations for assignment expressions}\label{validity-of-bounds-declarations-for-assignment-expressions}

For an assignment expression of the form \var{x} \texttt{=} \var{e},
where \var{x} is a variable and \var{e} is an expression, we start
with a context that is true before the evaluation of the assignment
expression. We determine the context that will be true after the
evaluation of the assignment expression and the bounds for the value
returned by the assignment expression.

This seems straightforward at first. If \var{x} has type
\arrayptr, compute the bounds for \var{e} and update the
context so that the bounds for \var{x} is the bounds of \var{e}.
However, there is a problem. The bounds for \var{e} is determined
\var{before} \var{x} changes value. When \var{x} changes value, the bounds
for \var{e} may no longer be true if \var{x} appears in the bounds.
The context could contain uses of \var{x} also in bounds expressions.

A simple solution is to invalidate bounds expressions where x appears in
the bounds. This does not work well when a variable that appears in its
own bounds declaration is incremented or decremented. Consider the
following example:
\begin{verbatim}
array_ptr<int> x : bounds(x, high) = ...
int sum = 0;
while (x < high) {
    sum += *x;
    x++;  // bounds for x would be undefined for the simple solution
}
\end{verbatim}

A possible solution is to require programmers to copy variables in loops
that are modified using only pointer arithmetic to temporary variables
before the loop. The temporary variables could then be used in bounds.
However, this might increase register pressure and worsen performance.

One can do better than that for loop induction variables, which are
variables that are incremented or decremented by a constant in a loop.
Condit \textit{et al.} observe that some assignment expressions are
invertible: the old value of a variable can be calculated from the new
value . One can update the bounds by substituting the inverted
expression in place of the variable. The updated bounds can then be
narrowed to satisfy loop bounds invariants. Invertible expressions
include the addition and subtraction expressions that update loop
induction variables.

The updated context will be determined in three steps. First, if
\var{x} has type \arrayptr, the context is updated for
\var{x} using bounds expressions that use the \emph{old} value of \var{x}:

\begin{enumerate}
\item
  If \var{e} \texttt{:-} \var{exp}, then the context is updated with
  \var{x} \texttt{:} \var{exp}.
\item
  Otherwise, the context is updated with \var{x} \texttt{:
  bounds(none)} to indicate that \var{x} has no valid bounds.
\end{enumerate}

Second, the context is updated to reflect the change in the value of
\var{x}:

\begin{itemize}
\item
  If the expression being assigned is invertible, the right-hand side of
  any bounds expression that uses \var{x} will be updated to use an
  expression that inverts the new value to compute the old value.
\item
  Otherwise, any bounds expression that involves x is invalidated
\end{itemize}

An assignment expression in C has a value. The bounds of the assignment
expression will be the bounds of \var{x} at this point.

Third, the special variable \texttt{expr\_current\_value} is eliminated
from the bounds of \var{x}, if it was introduced because it occurred in
\var{e} \texttt{:-} \var{exp}. Recall that
\texttt{expr\_current\_value} stands for the current value of an
expression whose bounds is being determined. Because the value of
\var{e} has been assigned to \var{x}, \var{x} is substituted for
\texttt{expr\_current\_value} in the bounds for x.

\subsection{Invertibility}\label{invertibility}

The following examples illustrate invertibility and updating bounds. For
the first example, suppose there is a declaration of an
\arrayptr\ variable followed by a decrement of a variable
involved in the bounds:

\begin{verbatim}
array_ptr<int> a : count(len) = ...
len = len - 1
\end{verbatim}

The original value of \texttt{len} can be computed from the new value.
In this case, a valid new bounds after the decrement of \texttt{len} is
\texttt{count(a) == len + 1.} The bounds for \texttt{a} after the
assignment are:
\begin{verbatim}
len = len - 1
where a : count(len + 1);
\end{verbatim}

For the second example, consider an update to a pointer variable that
appears in its own bounds:
\begin{verbatim}
array_ptr<int> p : bounds(p, high) = ...         
while (p < high) {
    ...
          p = p + 1;
}
\end{verbatim}

First, the new bounds expression for the expression \verb|p + 1| is
computed. It is the same as the original bounds expression
\verb|bounds(p, high)|. Because p is modified by the assignment, the
inverted expression for \verb|p + 1| is substituted into 
\verb|(p, high)|. The inverted expression for \verb|p + 1| is \verb|p - 1|.
Substituting \verb|p-1| for \verb|p| leads to bounds of the form
\verb|bounds(p - 1, high)|:

\begin{verbatim}
while (p < high) {
    ...
          p = p + 1 where p : bounds(p - 1, high);
}
\end{verbatim}

Bounds safety is preserved when the range of a bounds expression is
narrowed. \texttt{(p -- 1, high)} implies that \texttt{(p, high)} is a
valid bounds expression. This reestablishes the loop bounds invariant
for \texttt{p} of \texttt{(p, high)}.

\begin{verbatim}
while (p < high) {
    ...
          p = p + 1 where p : bounds(p, high);
}
\end{verbatim}

The correctness of narrowing depends on safe pointer arithmetic overflow
being a runtime error. For a lower bound \var{e1} in a bounds
expression, we can only substitute \var{e2} for \var{e1} as the lower
bound if \var{e2} \textgreater{}= \var{e1}. The identity \texttt{p
\textgreater{} p -- 1} holds only if overflow is a runtime error.

\subsection{Invertible expressions}\label{invertible-expressions}

An expression is invertible with respect to a variable x if:

\begin{enumerate}
\item
  The expression is x
\item
  or

  \begin{enumerate}
  \item
    The operator in the expression is an addition, subtraction, one's
    complement, unary minus, unary plus, exclusive-or, a bit-preserving
    cast operator, or a widening cast operator, and
  \item
    The variable x occurs only in one argument of the operation and that
    argument is an invertible expression with respect to \var{x}
  \item
    Any other argument of the operation is a non-modifying expression,
    excluding non-modifying expressions that are or include member
    references, indirect member references, or pointer dereferences.
  \end{enumerate}
\end{enumerate}

The addition and subtraction operations must be for safe pointer
arithmetic or unsigned integer arithmetic. An implementation may allow
integral addition and subtraction operations to be invertible if
integral addition and subtraction are defined as two's complement
arithmetic where extra bits are discarded on overflow. However, this
introduces the possibility of non-portable code.

Given the expression \texttt{x =} \var{e}, where \texttt{x} occurs once
in \var{e}, mathematical rules are applied to solve for \texttt{x} in
\var{e}. We generalize the left-hand side from x to an expression
\var{f} and define \texttt{inverse(}\var{f}\texttt{,}
\var{e}\texttt{)} as follows:

\begin{longtable}[c]{@{}ll@{}}
\toprule
\texttt{Given inverse(}\var{f}\texttt{,} \var{e}\texttt{), where} &
\texttt{the result is:}\tabularnewline
\midrule
\endhead
\var{e} = \texttt{x} & \var{f}\tabularnewline
\var{e} = \texttt{\textasciitilde{}}\var{e1} &
\texttt{inverse(\textasciitilde{}}\var{f},
\var{e1}\texttt{)}\tabularnewline
e = \texttt{-}\var{e1} & \texttt{inverse(-}\var{f},
\var{e1}\texttt{)}\tabularnewline
\var{e} = \texttt{+}\var{e1} & \texttt{inverse(+}\var{f},
\var{e1}\texttt{)}\tabularnewline
\var{e} = \texttt{(}\var{t1}\texttt{)} \var{e1}, where \var{e1} has
type \var{t2} & \texttt{inverse((}\var{t2}\texttt{)} \var{f},
\var{e1}\texttt{)}\tabularnewline
\var{e} = \var{e1} \texttt{+} \var{e2}, where \texttt{x} occurs in
\var{e1} & \texttt{inverse(}\var{f} \texttt{-} \var{e2},
e1)\tabularnewline
\var{e} = \var{e1} \texttt{+} \var{e2}, where \texttt{x} occurs in
\var{e2} & \texttt{inverse(}\var{f} \texttt{-} \var{e1},
\var{e2})\tabularnewline
\var{e} = \var{e1} \texttt{-} \var{e2}, where \texttt{x} occurs in
\var{e1} & \texttt{inverse(}\var{f} \texttt{+} \var{e2},
\var{e1})\tabularnewline
\var{e} = \var{e1} \texttt{-} \var{e2}, where \texttt{x} occurs in
\var{e2} & \texttt{inverse(}\var{e1} \texttt{-} \var{f},
\var{e2})\tabularnewline
&\tabularnewline
\var{e} = \var{e1} \texttt{\^{}} \var{e2}, where \texttt{x} occurs in
\var{e1} & \texttt{inverse(}\var{f} \texttt{\^{}} \var{e2},
\var{e1})\tabularnewline
\var{e} = \var{e1} \texttt{\^{}} \var{e2}, where \texttt{x} occurs in
\var{e2} & \texttt{inverse(}\var{f} \texttt{\^{}} \var{e1},
\var{e2})\tabularnewline
\bottomrule
\end{longtable}

Given \texttt{inverse(x}, \var{e}), the rules are applied repeatedly
until the original value of x in e has been computed. Here is an example
of computing the inverse of \texttt{x = (x + 4) + 5}:
\begin{verbatim}
   inverse(x, (x + 4) + 5) =
       inverse(x - 5, x + 4) =
          inverse((x - 5) - 4, x) =
              (x - 5) - 4
\end{verbatim}

\section{Bounds for expressions with nested assignment expressions}\label{bounds-for-expressions-with-nested-assignment-expressions}

C allows assignment expressions to be nested within other expressions.
This means that the approach of Section 5.3 has to be extended to walk
expressions recursively and update the context during the walk.

Given some expression e that has subexpressions e\textsubscript{1}
\ldots{}. e\textsubscript{n}, start with the context for e. Compute a
new context and the bounds expression for e as follows:

\begin{itemize}
\item
  Traverse e\textsubscript{1} \ldots{} e\textsubscript{n} in an order
  that respect the sequence points of . For each subexpression, take the
  context and compute the updated context and the bound expression (if
  any) for the subexpression.
\item
  If e is an assignment expression, apply the rules in Section 5.3 to
  compute an updated context and a bounds expression for e
\item
  Otherwise, apply the rules in Section 5.1 to compute an updated bounds
  expression for e.
\end{itemize}

 \section{Checking expression statements}\label{checking-expression-statements}

Expression statements need to be checked for consistency with their
expected bounds declarations. If an expression statement is within a
bundled block, the checking is deferred to the end of the bundled block.

To check an expression statement, the analysis of Section 4.7.4 is used
to determine the context for the expression in the statement (the bounds
for variables before the statement is evaluated). The rules in Section
5.4 are then used to determine the updated context.

The updated context is then checked against the bounds declarations that
must be true after the expression statement. For each
\arrayptr\ variable \var{x} in scope, the expected bounds is
computed:

\begin{itemize}
\item
  If the expression statement has a bounds declaration for \var{x}, the
  bounds expression in that bounds declaration is used.
\item
  Otherwise, the analysis of Section 4.7.4 is used to determine the
  expected bounds expression for x.
\end{itemize}

The bounds expression in the context for \var{x} must imply that the
expected bounds expression holds. Implication is checked in this section
using by placing non-modifying expressions into a canonical form and
checking for syntactic equality. If two expressions have the same
canonical form, any values that they have at runtime will always be
identical. Section 10 describes more general techniques for checking
that context bounds imply the expected bounds.

The context bounds expression implies that the expected bounds
expression holds if:

\begin{itemize}
\item
  The expected bounds expression is \boundsnone, or
\item
  The context bounds expression is \boundsany, or
\item
  The context bounds expression and the expected bounds expression are
  equal syntactically after placing the expressions into canonical
  forms,
\item
  The canonicalized context bounds expression and the expected bounds
  expression differ syntactically only in their relative alignment, and
  the context bounds implies the expected relative alignment \var{c}.
  This is true if:

  \begin{itemize}
  \item
    The context relative alignment is an integer multiple of the
    expected relative alignment,
  \item
    or given a context bounds expression of the form
    \boundsrel{\var{e1}}{\var{e2}}{\var{d}},
    \texttt{(((\arrayptrchar)}
    \var{x}\texttt{)} \texttt{-}
    \texttt{((\arrayptrchar)}
    \var{e1}\texttt{))} \texttt{\%} \var{c} canonicalizes to
    \texttt{0}, as does
    \texttt{(((\arrayptrchar)}
    \var{e2}\texttt{)} \texttt{-}
    \texttt{((\arrayptrchar)}
    \var{x}\texttt{))} \texttt{\%} \var{c}.
  \end{itemize}
\end{itemize}

 \subsection{Canonicalization of expressions in bounds expressions}\label{canonicalization-of-expressions-in-bounds-expressions}


Most readers can skip this section safely and come back to it as
necessary. This section is for compiler implementers and for programmers
who want to understand when expressions are regarded as identical by
canonicalization.

Canonicalization guarantees the following: if two non-modifying
expressions have the same canonical form and if they produce values when
evaluated at runtime, the two values will be equal. There are two
important things to understand about this definition. First, two C
expressions may have different canonicalized forms and still always
produce the same value at runtime (in the terminology of logic,
canonicalization is incomplete). Second, canonicalization does not
guarantee that an expression will actually produce a value at runtime.
It may still have a runtime fault. The runtime correctness of bounds
expressions is implied by transitivity: a bounds expression must be
implied by another bounds expression, and so on, until a bounds
expression is implied by an allocation. The allocation must have
involved an expression that actually produced a value.

This has a surprising consequence: integer arithmetic operations that
check for overflow can be regarded as following mathematical rules
during canonicalization. A compiler could not reassociate \texttt{((a
+\textsubscript{ovf} b) +\textsubscript{ovf} c)} to \texttt{(a
+\textsubscript{ovf} (b +\textsubscript{ovf} c)} and replace the first
expression with the second one because it could cause an overflow where
none occurred before. For canonicalization, though, reassociation is
fine.

Signed integer operations do not follow certain mathematical identities.
This is because according to the rules in Section 3.8, they may produce
a value on overflow, but the properties of the value are not specified.
Signed addition is not associative: \texttt{(a + b) + c} is not
guaranteed to produce the same result as \texttt{a + (b + c)} in the
presence of overflow. The expression \texttt{a + b} may overflow, while
\texttt{b + c} may not overflow or the reverse may occur. In addition,
for signed integers, it is not guaranteed that \texttt{a - b} =
\texttt{a + (-b)} or that \texttt{-(-(a))} = \texttt{a}.

The canonicalization rules need to disambiguate between signed and
unsigned operators for integers, as well as operators that check for
overflow. All integer operators will be subscripted by whether they
apply to signed or unsigned integers, or whether they overflow-checking
operators, using the subscripts \texttt{signed}, \texttt{unsigned}, and
\texttt{ovf}. For example, the expression \texttt{(a + b) + c} involving
signed integers will be written as \texttt{(a
+}\emph{\textsubscript{signed}} \texttt{b)
+}\emph{\textsubscript{signed}} \texttt{c}.

The overflow checking operators introduced in Section 3.4.2 only include
operators that can occur in practice. For canonicalization, it is useful
to have a complete set of operators, including
\texttt{+\textsubscript{ovf}} and \texttt{\textsubscript{-ovf}} that
take two integers (both signed or unsigned) and produce an integer that
has the same type as the arguments, as well as unary negation that takes
a signed or unsigned integer and produces a signed integer.

In the rules for canoncialization, when a subscript on an integer
operator is omitted, the rule applies to all forms of the operator.
Sometimes the subscript \var{kind} will be used on operators. Either
u\texttt{nsigned} or \texttt{ovf} should be substituted for \var{kind}
in the rule.

The first step in canonicalization is to convert non-modifying
expressions to an initial representation:

\begin{enumerate}
\item
  All expressions involving operators are fully parenthesized and
  unnecessary parenthesis on variables and constants are removed. For
  example, \var{e1} \var{op1} \var{e2} \var{op2} \var{e3}, is
  replaced by \texttt{((}\var{e1} \var{op1} \var{e2}\texttt{)}
  \var{op2} \var{e3}\texttt{)} or \texttt{(}\var{e1} \var{op1}
  \texttt{(}\var{e2} \var{op2} \var{e3}\texttt{))}, depending on the
  precedence of \var{op1} and \var{op2}.
\item
  Implicit cast operations are made explicit.
\item
  The pointer dereference (*) and pointer indirection operators
  (-\textgreater{}) are implicitly annotated with their pointer types.
  This is necessary because converting pointer arithmetic to integer
  arithmetic will erase the type information needed by these operators.
\item
  Unary plus operations are removed.
\item
  Array references of the form
  \var{e1}\texttt{[}\var{e2}\texttt{]} are converted to
  *\texttt{((}\var{e1}\texttt{)} \texttt{+}
  \texttt{(}\var{e2}\texttt{))}
\item
  Pointer arithmetic is expanded to integer-based arithmetic.
\item
  Binary subtraction expressions are canonicalized to use unary minus
  when possible: \var{e1} \texttt{-}\emph{\textsubscript{kind}}
  \var{e2} is converted to \var{e1}
  \texttt{+}\emph{\textsubscript{kind}}
  \texttt{-}\emph{\textsubscript{kind} e2}.
\end{enumerate}

For the second step of canonicalization, two sets of binary arithmetic
operators are defined

\begin{itemize}
\item
  The set of of commutative and associative operators (CA operators).
  This includes:

  \begin{itemize}
  \item
    The operators +\texttt{\textsubscript{unsigned}},
    *\texttt{\textsubscript{unsigned}}, +\texttt{\textsubscript{ovf}},
    and *\texttt{\textsubscript{ovf}}
  \item
    The bitwise operators \texttt{\textbar{}}, \texttt{\&}, and
    \texttt{\^{}}
  \item
    The Boolean operators \texttt{\textbar{}\textbar{}} and
    \texttt{\&\&}
  \end{itemize}
\item
  The set of commutative-only operators (CO):
  \texttt{+\textsubscript{signed}} and \texttt{*\textsubscript{signed}}.
\end{itemize}

The following rules are applied until no further changes occur:

\begin{enumerate}
\item
  Removing pointer casts and identity casts on integral types (casts
  from a type to itself). Pointer casts do not change the values of
  pointers.
\item
  Folding constant integral expressions. The following expressions are
  constant-folded:

  \begin{enumerate}
  \item
    Any constant expression that uses only overflow-checking arithmetic
    operators and that mathematically evaluates to an in-range integer
    value. The value is the mathematical result.
  \item
    Any constant expression involving integers that produces a defined
    result according to the C language standard or the C implementation
    rules.
  \end{enumerate}
\item
  Applying algebraic identities to simplify expressions

  \begin{enumerate}
  \item
    Arithmetic identities

    \begin{enumerate}
    \item
      \var{e} \texttt{+} \texttt{0} = \var{e}, \var{e} \texttt{-}
      \texttt{0} = \var{e}, \texttt{0} \texttt{-} \var{e} =
      \texttt{(-}\var{e}\texttt{)}, \texttt{0} \texttt{*} \var{e} =
      \texttt{0}, \texttt{1} \texttt{*} \var{e} = \var{e}, \var{e} /
      \texttt{1} = \var{e}, \var{e}\texttt{/-1} = \texttt{-}\var{e},
      \var{e} \texttt{\%} \texttt{1} = \var{e}
    \item
      For a positive constant \var{c}, (\var{e}
      \texttt{*}\emph{\textsubscript{kind}} \var{c}) \texttt{\%}
      \var{c} = \texttt{0}
    \end{enumerate}
  \item
    Bitwise identities: \var{e} \texttt{\&} \texttt{0} = \texttt{0},
    \var{e} \texttt{\textbar{}} \texttt{0} = \var{e}, \var{e}
    \texttt{\^{}} \texttt{0} = \var{e}, and
    \texttt{\textasciitilde{}(\textasciitilde{}}\var{e}\texttt{))} =
    \var{e}
  \item
    Boolean identities: given a non-zero constant c, \var{e}
    \texttt{\&\&} \var{c} simplifies to \var{e}, \var{e}
    \texttt{\textbar{}\textbar{}} \var{c} simplifies to \texttt{1}, and
    \texttt{!}\var{c} = \emph{0}. When \var{c} = \texttt{0}, \var{e}
    \texttt{\&\&} \var{c} simplifies to \texttt{0}, \var{e}
    \texttt{\textbar{}\textbar{}} \var{c} simplifies to \var{e}, and
    \texttt{!}\var{c} = \texttt{1}.
  \item
    Double negation:
    \texttt{-}\emph{\textsubscript{kind}}(\texttt{-}\emph{\textsubscript{kind}}
    \var{e}\texttt{)} = e.
  \item
    Cancelling terms: \var{e} \texttt{-}\textsubscript{signed} \var{e}
    simplifies to \texttt{0} and \var{e} \texttt{+\textsubscript{kind}}
    (\texttt{-\textsubscript{kind}} \var{e}) simplifies to \texttt{0}.
    This is applied more generally to a sequence of addition operations
    of the form \texttt{(}\ldots{} \texttt{(}e1
    \texttt{+}\textsubscript{kind} e2\texttt{)} \ldots{}
    \texttt{+}\textsubscript{kind} \texttt{-}\emph{\textsubscript{kind}}
    e1 \ldots{}\texttt{)}.

    When identities have commutative versions, those are applied as
    well.
  \end{enumerate}
\item
  Applying associativity commutivity, and distributivity rules to put
  expressions in canonical forms:
\end{enumerate}

\begin{enumerate}
\item
  For each operator \var{op} in CA, repeatedly rewriting any expression
  of the from \var{e1} \var{op} \texttt{(}\var{e2} \var{op}
  \var{e3}\texttt{)} to \texttt{(}\var{e1} \var{op}
  \var{e2}\texttt{)} \var{op} \var{e3} until no further rewrites are
  possible.
\item
  For each operator \var{op} in CA, for each sequence of operations
  (\ldots{} ((\var{e1} \var{op} \var{e2}) \var{op} \var{e3})
  \ldots{} \var{op} \var{en}), reordering the operands so that
  \var{e1} \ldots{} \var{en} appear in lexicographic order. Constants
  should appear lower in the lexicographic order than more complex
  expressions.
\item
  For each operator \var{op} in CO, commuting the operands in \var{e1}
  \var{op} \var{e2} so that \var{e1} is lower in the lexicographic
  order.
\item
  Applying the following distributivity rules:

  \begin{enumerate}
  \item
    Rewriting \texttt{-}\emph{\textsubscript{kind}}\texttt{(}\var{e1}
    \texttt{+}\emph{\textsubscript{kind}} \var{e2}\texttt{)} to
    \texttt{(-}\emph{\textsubscript{kind} e1}\texttt{)} \texttt{+}
    \texttt{(-}\emph{\textsubscript{kind} e2}\texttt{)},
  \item
    Rewriting \texttt{(}\var{e1} \texttt{+}\emph{\textsubscript{kind}}
    \var{e2}\texttt{)} \texttt{*}\emph{\textsubscript{kind}} \var{e3}
    to \texttt{(}\var{e1} \texttt{*}\emph{\textsubscript{kind}}
    e3\texttt{)} \texttt{+}\emph{\textsubscript{kind}}
    \texttt{(}\var{e2} \texttt{*}\emph{\textsubscript{kind}}
    \var{e3}\texttt{)}
  \item
    Rewriting \texttt{(}e1 \textbar{} e2\texttt{)} \& e3 as \texttt{(}e1
    \& e3\texttt{)} \textbar{} \texttt{(}e2 \& e3\texttt{)} and
    rewriting e3 \& \texttt{(}e1 \textbar{} e2\texttt{)} as \texttt{(}e3
    \& e1 \textbar{} e3 \& e2\texttt{)}
  \item
    Rewriting !(e1 \textbar{}\textbar{} e2) as ((!e1) \&\& (!e2)) and
    !(e1 \&\& e2) as ((!e1) \textbar{}\textbar{} (!e2))
  \item
    Rewriting (e1 \textbar{}\textbar{} e2) \&\& e3 as (e1 \&\& e3)
    \textbar{}\textbar{} (e2 \&\& e3) and rewriting e3 \&\& (e1
    \textbar{}\textbar{} e2) as (e3 \&\& e1 \textbar{}\textbar{} e3 \&\&
    e2)
  \end{enumerate}
\end{enumerate}

The distributivity rules expand the size of expressions, potentially
increasing size exponentially. Implementations may have a reasonable
limit on the size of canonicalized expressions. A minimum required limit
will be determined based on an empirical evaluation of C programs.

\subsection{An example of canonicalization}\label{an-example-of-canonicalization}

Here is how bounds for following statement will be checked:
\begin{verbatim}
array_ptr<int> x;
x = malloc(sizeof(int)*5) where x : count(5);
\end{verbatim}

The function \verb+malloc+ is assumed to have the bounds declaration:

\begin{verbatim}
array_ptr<void> malloc(size_t num) : byte_count(num);
\end{verbatim}

even though in practice it will have a bounds-safe interface that does
not use a safe pointer type.

First, the implicit casts are made explicit and count is expanded to bounds:

\begin{verbatim}
x = (array_ptr<int>) malloc(sizeof(int)*(size_t) 5) where x : bounds(x, x + 5);
\end{verbatim}

Next, the bounds for the right-hand expression are computed. The bounds
declaration for malloc is expanded to:
\begin{verbatim}
array_ptr<void> malloc(size_t num)  
where return_value : bounds((array_ptr<char>) return_value, 
                            (array_ptr<char>) return_value + num)
\end{verbatim}

The bounds for malloc are used to compute the bounds for the function
call \verb+malloc(sizeof(int)*(size_t) 5)+. The actual argument
\verb+sizeof(int)*(size_t) 5+ is substituted for \verb+num+ in the
bounds expression for the return value of \verb+malloc+:
\begin{verbatim}
return_value : bounds((array_ptr<char>) return_value, 
                       (array_ptr<char>) return_value + sizeof(int)*(size_t) 5)
\end{verbatim}

Next, \verb+expr_current_value+ is substituted for \verb+return_value+ :
\begin{verbatim}
expr_current_value : bounds((array_ptr<char>) expr_current_value, 
                            (array_ptr<char>) expr_current_value + sizeof(int)*(size_t) 5)
\end{verbatim}

Then, the bounds for \verb|(array_ptr<int>) malloc(sizeof(int)*(size_t) 5)|
are computed. The inverse cast \verb|(array_ptr<void> expr_current_value)|
is substituted for \verb|expr_current_value|:

\begin{verbatim}
expr_current_value : bounds((array_ptr<char>) ((array_ptr<void>) expr_current_value), 
                            (array_ptr<char>) ((array_ptr<void>) expr_current_value)
                            + sizeof(int)*(size_t) 5) 
\end{verbatim}

Finally, \verb|x| is substituted for \verb|expr_current_value| :

\begin{verbatim}
x : bounds((array_ptr<char>) ((array_ptr<void>) x), 
           (array_ptr<char>) ((array_ptr<void>) x) + sizeof(int)*(size_t) 5) 
\end{verbatim}

Now, it has be shown that the computed bounds for \verb|x|\ imply the expected
bounds for \verb|x|\ of \verb|bounds(x, x + 5)|. The bounds expressions are both
converted to use integer arithmetic:

\begin{alltt}
// computed bounds
bounds((\arrayptrchar) ((\arrayptrvoid) x),
       (\arrayptrchar) ((\arrayptrvoid) x) +\textsubscript{ovf} sizeof(int)*\textsubscript{unsigned}(size\_t) 5))
// expected bounds
bounds(x, x +\textsubscript{ovf} (5 *\textsubscript{ovf} (signed\_size\_t) sizeof(int)))
\end{alltt}

Next, unnecessary pointer casts are removed:
\begin{alltt}
// computed bounds
bounds(x, x +\textsubscript{ovf} (sizeof(int) *\textsubscript{unsigned} (size\_t) 5))
// expected bounds
bounds(x, x +\textsubscript{ovf} (5 *\textsubscript{ovf} (signed\_size\_t) sizeof(int)))
\end{alltt}

After that, constant folding is done. If \verb+sizeof(int)+ is 4, the result is:
\begin{alltt}
// computed bounds
bounds(x, x +\textsubscript{ovf} 20)
// expected bounds
bounds(x, x +\textsubscript{ovf} 20)
\end{alltt}

We must also show the expected bounds imply that the 
\verb|rel_align(int)| requirement is met. This is straightforward for
a constant-sized array. It involves showing given bounds{\var{e1}}{\var{e2}}
that \verb|(((array_ptr<char>) x) - ((array_ptr<char>)| \var{e1}\verb|)) % 4| canonicalizes to 0, as does
\arrayptrchar \var{e2}\verb|) - (array_ptr<char>) x)) % 4|.

For the first expression, \verb|((array_ptr<char>) - x) % 4|
simplifies to \verb|0 % 4|, which constant-folds to \verb|0|. 
For the second expression, \verb|((array_ptr<char>) (x+5) - ((array_ptr<char>) x)) % 4|
simplifies to \verb|((x |+\textsubscript{ovf}\verb|20)| -\textsubscript{ovf\_diff} \verb|x) % 4|. This
simplifies to \verb|20 % 4|, which constant-folds to \verb|0|.


If we change the example to make the number of elements variable instead
of constant, we can see how canonicalization breaks down in the presence
of integer wraparound. Suppose the number of elements is given by a
variable \verb|k|. We would have:

\begin{alltt}
// computed bounds
bounds(x, x +\textsubscript{ovf} (sizeof(int) *\textsubscript{unsigned} (size\_t) k))
// expected bounds
bounds(x, x +\textsubscript{ovf} (k *\textsubscript{ovf} (signed\_size\_t) sizeof(int)))
\end{alltt}

After converting pointer arithmetic to integer arithmetic, we have:
\begin{alltt}
// computed bounds
bounds(x, x +\textsubscript{ovf} (4 *\textsubscript{unsigned} (size\_t) k))
// expected bounds
bounds(x, x +\textsubscript{ovf} (k *\textsubscript{ovf} 4))
\end{alltt}

Canonicalization of the upper bounds expressions produces:
\begin{alltt}
// computed bounds
x +\textsubscript{ovf} (4 *\textsubscript{unsigned} (size\_t) k))
// expected bounds
x +\textsubscript{ovf} (4 *\textsubscript{ovf} k)
\end{alltt}

The expressions are not identically syntactically, so bounds expression
checking fails. The additional side conditions that \verb|k >= 0 && k <= UINTPTR\_MAX/4|
are needed to show that the computed upper bound implies the expected upper bound. More
general techniques from Section 10 are needed to show that the context
bounds imply the expected bounds.

\subsection{Extending canonicalization to two's complement signed integer arithmetic}
\label{extending-canonicalization-to-twos-complement-signed-integer-arithmetic}

In some widely-used C compilers, however signed arithmetic implemented
as two's complement arithmetic is available under a compiler flag. In
this case, the expected arithmetic properties hold, which enables more
expressions to be canonicalized to the same form.

\section{Checking declarations}\label{checking-declarations}

Declarations also need to be checked for consistency with their bounds
declarations. If the declaration is within a bundled block, the checking
is deferred to the end of the bundled block.

C distinguishes between declarations and definitions of variables. A
declaration declares the type and storage class for a variable. It may
or may not cause storage to be allocated for the variable. A definition
is a declaration of a variable that causes storage to be allocated for
the variable as well. Definitions may have initializers that initialize
the storage for the variable.

We first describe checking definitions, which is similar to checking
assignments. For a declaration, we assume that there is ordered list of
\arrayptr\ variables and their optional initializers, and the
list of bounds declarations in the where clause for the declaration. The
list is ordered by the order of variable declarations.

First, the current context is computed before the declaration. Then, for
each variable \var{v} in the list,

\begin{itemize}
\item
  If \var{v} has an initializer, the current context is updated by
  traversing the assignment expressions in the initializer using the
  analysis from Section 5.4. The bounds for each individual assignment
  expression are recorded as well. Note that if \var{v} is a static
  variable, the assignment expressions must actually be constant
  expressions, so the context will not change.
\item
  If \var{v} has an \arrayptr\ type or an incomplete array
  type, the context is updated to record the new bounds for \var{v}:

  \begin{itemize}
  \item
    If \var{v} has no initializer, then

    \begin{itemize}
    \item
      If \var{v} is a static variable, then \var{v} will be
      initialized to 0. The context is updated to map \var{v} to
      \boundsany.
    \item
      If \var{v} is an automatic variable then \var{v} will have an
      indeterminate value. The context is updated to map v to
      \boundsnone.
    \end{itemize}
  \item
    If \var{v} has an initializer, the initializer must have the form
    \var{e} or \texttt{\{} \var{e} \texttt{\}}. In both cases,

    \begin{itemize}
    \item
      If \texttt{expr\_current\_value} appears in the bounds for
      \var{e}, \var{v} is substituted for it.
    \item
      The context is updated to map v to the updated bounds.
    \end{itemize}
  \end{itemize}
\end{itemize}

The current context is then checked against the bounds declarations that
must be true after the declaration using the analysis in Section 5.5.

Declarations that are not definitions are not checked, other than to
verify that all the declarations of a variable in a translation unit
have the same bounds declaration (or lack of a bounds declarations) for
the variable.

\section{Checking bundled declarations and statements}\label{checking-bundled-declarations-and-statements}

To check bundled declarations and statements, the current context is
determined before the bundled block. The current context is then updated
for each expression statement and declaration following the rules for
updating contexts in Sections 5.5 and 5.6. The analysis of Section 4.7.4
is used to determine the expected bounds expression for each variable at
the end of the bundled block. The current context is checked against the
bounds declarations that must be true at the end of the block using the
analysis in Section 5.5.

When an expression with \arrayptr\ type is dereferenced within
an expression statement in a bundled block, the current context before
the statement is used to determine the bounds for the expression. This
may cause an expression to have a different bounds than it normally
would have based on bounds declarations.

For example, suppose a pointer assignment is introduced into the middle
of the earlier example. The pointer assignment is highlighted in blue.
The bounds for \verb|parr| at that point in the program based on the
current context will be \verb|bounds(parr, parr + size)|.
\begin{verbatim}
int arr[DEFAULT_SIZE];
bundle {
    array_ptr<int> parr : count(len) = arr;
    int plen = DEFAULT_SIZE;
}

f(int size) {
    if (size > DEFAULT_SIZE) {
        bundle {
            parr = malloc(sizeof(int) * size);
            *parr = 314;
            plen = size;
        }
    }
}
\end{verbatim}

If the code were slightly rearranged, there would be a compile-time
error. The assignment to \texttt{plen} invalidates the bounds for
\texttt{parr} in the context at the point of the assignment.
\begin{verbatim}
f(int size) {
    if (size > DEFAULT_SIZE) {
        bundle {
            plen = size;
            *parr = 314; // error: parr has bounds of none.
            parr = malloc(sizeof(int) * size);
        }
    }
}
\end{verbatim}

A function call within a bundled block require special treatment: the
bounds declarations for variables with static storage must be valid
before the call. The called function is assuming that the declared
bounds are valid. This means that the context before the function call
must imply that bounds declarations for variables in scope that have
static storage are valid.

\section{Checking function call arguments}\label{checking-function-call-arguments}

Function call arguments also need to be checked for consistency with
expected bounds declarations. This is similar to checking of expression
statements with where clauses. For each call f(e\textsubscript{1}
\ldots{} e\textsubscript{n}) to a function f(x\textsubscript{1} \ldots{}
x\textsubscript{n}) that has bounds declarations for one or more
parameters,

\begin{itemize}
\item
  A statement of the form

  x\textsubscript{1 =} e\textsubscript{1} \texttt{,} x\textsubscript{2
  =} e\textsubscript{2} \texttt{,} \ldots{}. x\textsubscript{n =}
  e\textsubscript{n} where \var{conditions} \texttt{;}

  is constructed, where \var{conditions} contains all the bounds
  declarations on parameters. Parameters are renamed if necessary so
  that they have different names from variables in scope at the function
  call.
\item
  The context for the function call is constructed. The statement is
  checked in that context using the rules in Section 5.5.
\item
  A subtle point is that the order of evaluation for argument
  expressions in C is not defined (Section 5.11 discusses order of
  evaluation issues in depth). A check is done also that the values of
  argument expressions used in checking the bounds declaration do not
  depend on the order of evaluation of arguments:

  \begin{itemize}
  \item
    The set of parameters that occur in bounds declarations for
    parameters is computed.
  \item
    Any argument expression corresponding to a parameter in this set
    cannot read a variable that is assigned to by another argument
    expression. If one does, the function call is rejected as not
    checking.
  \end{itemize}
\end{itemize}

 \section{Checking return statements}\label{checking-return-statements}

A return statement has the form \texttt{return} \var{e}, where \var{e}
is optional. The bounds for \var{e} are computed. If the special
variable \texttt{expr\_current\_value} occurs in the bounds, the special
variable \keyword{return\_value} is substituted into the bounds in its
place. It is then checked that the updated bounds for \var{e} imply the
return bounds for the function using the rules in Section 5.5.

\section{Checking other statements}\label{checking-other-statements}

There are a variety of other statements in C. These statements are built
from zero or more expressions, statements, and declarations:

\begin{itemize}
\item
  Labeled statements of the form \texttt{case}
  \var{constant-expression} \texttt{:} \var{statement},
  \texttt{default :} \var{statement}, and \var{identifier} :
  \var{statement}.
\item
  Selection statements of the form \texttt{if (}
  \var{expression}\texttt{)} \var{statement} \texttt{else}
  \var{statement} and \texttt{switch (} \var{expression} \texttt{)}
  \var{statement}.
\item
  Iteration statements such as \texttt{while (} \var{expression} )
  \var{statement} and \texttt{for
  (}\var{declaration\textsubscript{opt}}
  \var{expression\textsubscript{opt} ; expression\textsubscript{opt}
  statement}\texttt{)}.
\item
  Jump statements of the from \texttt{goto} \var{identifier},
  \texttt{continue}, and \texttt{break}.
\item
  Compound statements of the form \texttt{\{ ... \}} where \texttt{...}
  are zero or more declarations or statements.
\end{itemize}

The nested statements and declarations can be checked individually.

For the expressions used in the statements, the context is determined
before the evaluation of the expression. No way is provided for a direct
expression occurring in a statement to have new bounds declared for any
bounds in it. This means that the bounds declarations in the context
will be expected to be true after the evaluation of the expression too.

The rules in Section 5.4 are used to determine the updated context after evaluation of the
expression. The rules in Section 5.5 are used to check that the updated
context is valid for the expected bounds declarations.

\section{Avoiding undefined expressions and undefined bounds}\label{avoiding-undefined-expressions-and-undefined-bounds}

The order of evaluation of side-effects in subexpressions of an
expression is defined in C only in certain circumstances (these are
described in Section 6.5 and Annex C of). Otherwise, the order of
evaluation of side-effects is undefined. Although nested assignment
expressions help the brevity of programs, they lead to expressions whose
meaning or bounds are undefined. To avoid compromising the integrity of
bounds information, compilers must produce errors when they encounter
these expressions.

The meaning of an expression is undefined if:

\begin{enumerate}
\item
  There are multiple assignments to the same variable within an
  expression where the order of evaluation of the assignments is
  undefined, or
\item
  There is an assignment to a variable that is also used by the
  expression, where the order of evaluation of the assignment and the
  use is undefined.
\end{enumerate}

The following statements illustrate these problems:

\begin{verbatim}
y = (x = 5) + (x = 6);
i = i++ + 1;
a[i++] = i;
\end{verbatim}

In the first case, the value of the right-hand side expression is 11,
yet at the end of the expression, the value of x could be 5 or 6. In the
second case, there are two assignments to i and the order is undefined.
In the third case, it is not clear when i is read vs. when it is
modified.

Bounds checks can lead to a subtle version of the second problem: an
expression may have an assignment through a pointer that require a
bounds check. The bounds for the pointer expression may include a
variable that is modified in the expression, where the order of
evaluation of the assignment through the pointer and the variable
assignment is undefined. This means that the order of evaluation of the
bounds check and the variable assignment is undefined.

This example illustrates this problem:

\begin{verbatim}
w = ...
where w : bounds(x, x + y);
int t = *w + (y = tmp);
\end{verbatim}

The variable y is an integer variable that is a count of elements. It is
overwritten during the evaluation of an expression that dereferences w,
whose bounds include y.

We define these situations to be compile-time errors. Define an
ambiguous variable in an expression e as:

\begin{itemize}
\item
  A variable that has multiple assignments to it within e such that the
  order of evaluation of those assignments is undefined, or
\item
  A variable that has an assignment to it and a use of the variable such
  that the order of evaluation of the assignment and the use is
  undefined, or
\item
  A variable that has an assignment to it, where there is some
  subexpression *e1 of e where the variable appears in the bounds of e1
  and the order of evaluation of *e1 and the assignment to the variable
  is undefined.
\end{itemize}

It is a compile-time error for an expression to have an ambiguous
variable.

 \chapter{Interoperation between safe and unsafe code}\label{interoperation-between-safe-and-unsafe-code}

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \item ~
    \subsection{\texorpdfstring{\protect\hypertarget{ux5fToc422906963}{}{\protect\hypertarget{ux5fToc424307687}{}{\protect\hypertarget{ux5fToc426641110}{}{\protect\hypertarget{ux5fToc435434969}{}{\protect\hypertarget{ux5fToc437460796}{}{\protect\hypertarget{ux5fRef438042394}{}{\protect\hypertarget{ux5fToc440445477}{}{\protect\hypertarget{ux5fToc440449259}{}{\protect\hypertarget{ux5fToc440551909}{}{}}}}}}}}}Conversions
    between pointers to objects of different
    types}{Conversions between pointers to objects of different types}}\label{conversions-between-pointers-to-objects-of-different-types}
  \end{enumerate}

Conversions from a pointer to one type to a pointer to a different type
introduce two issues. First, there is type safety. Given a pointer to S
that has been converted to be a pointer to T, is it valid to treat the
memory pointed to by the ponter as being an object of type T instead of
type S? Second, there is bounds safety. Given the pointer, what range of
memory can be accessed validly using that pointer? This section focus on
bounds safety.

Type safety is not addressed by this design note. Of course, violating
type safety can lead to violations of bounds safety. This can happen
when there is a conversion between a safe pointer to an object of
structure type that contains a bounds-checked member and a safe pointer
to an object of another type. A programmer can use the pointer to the
other type to modify the bounds-checked member or its bounds in an
inconsistent fashion. For now, it is the programmer's responsibility to
update bounds-checked members and their bounds properly when using a
safe pointer that results from such a conversion. Conversions between
safe pointers to integral types, floating-point types, or structure that
contain only integral types or floating-point types cannot lead to
violations of bounds safety by themselves.

Three new operators are introduced for converting between the different
kinds of pointer types:
\textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}},
\textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}},
and \textbf{assume\_bounds\_cast\textless{}}T\textbf{\textgreater{}}.
The syntax of the operators is similar to the syntax of C++ type
conversion operators. \emph{T} is the destination type to which a source
value is being converted. The new operators take one to three arguments,
where the first argument is the pointer being converted and additional
arguments describe the desired new bounds.

The meanings of the operators when T is a complete type are described
first.

\begin{quote}
\emph{Here are the rules for when a cast operator (T) can be applied to
an expression e with type S:}
\end{quote}

\begin{itemize}
\item
  \emph{T is an array\_ptr: always. The bounds are inferred from the
  expression following the rules in Section . Note that the result may
  be an array\_ptr with bounds(none).}
\item
  \emph{T is a ptr: sometimes. The bounds are inferred as well. The
  resulting bounds must be large enough to hold at least a single
  element of type T. This implies the bounds cannot be bounds(none).}
\item
  \emph{T is an unsafe ptr and S is safe pointer: sometimes. Like ptr, }

  \begin{itemize}
  \item
    \emph{If S is ptr type and size of the of the referent }

    \begin{enumerate}
    \def\labelenumi{\arabic{enumi}.}
    \item ~
      \subsubsection{\texorpdfstring{\protect\hypertarget{ux5fToc437460797}{}{\protect\hypertarget{ux5fToc440445478}{}{\protect\hypertarget{ux5fToc440449260}{}{\protect\hypertarget{ux5fToc440551910}{}{}}}}Dynamic
      checking using
      bounds\_cast\textless{}\emph{T}\textgreater{}}{Dynamic checking using bounds\_cast\textless{}T\textgreater{}}}\label{dynamic-checking-using-boundsux5fcastt}
    \end{enumerate}
  \end{itemize}
\end{itemize}

\textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}} uses
dynamic checks to enforce the preservation of bounds safety. \emph{T}
must be a pointer type and is the desired destination type. The operator
takes 1 to 3 arguments, depending on the kind of conversion being done:

\begin{itemize}
\item
  \textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1},
  \emph{e2}\textbf{)} converts \emph{e1} to an \textbf{array\_ptr} or
  \textbf{array\_view} type with bounds
  \textbf{count(}\emph{e2}\textbf{)}.
\item
  \textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{,}
  \emph{e2}\textbf{,} \emph{e3}\textbf{)} converts \emph{e1} to an
  \textbf{array\_ptr} or \textbf{array\_view} type with bounds
  \textbf{bounds(}\emph{e2}\textbf{,} \emph{e3}\textbf{)}.
\item
  \textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{)}
  converts \emph{e1} to either a \textbf{ptr} or * type.
\end{itemize}

It is a compile-time error if the bounds of e1 are
\textbf{bounds(none)}. No runtime checks are done if the bounds of e1
are \textbf{bounds(any)}. If the bounds of e1 are
\textbf{bounds(}\emph{lb}\textbf{,} \emph{ub}\textbf{)}, the following
runtime checks are done:

\begin{itemize}
\item
  \textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1},
  \emph{e2}\textbf{)}: if \emph{e1} \textbf{!= 0}, check that \emph{lb}
  \textbf{\textless{}=} \emph{e1} \textbf{\&\&} \emph{e1} \textbf{+
  sizeof(referent-type(}\emph{T}\textbf{)) *} e2 \textbf{\textless{}=}
  \emph{ub}.
\item
  \textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{,}
  \emph{e2}\textbf{,} \emph{e3}\textbf{)}: if \emph{e1} \textbf{!= 0},
  check that \emph{lb} \textbf{\textless{}=} \emph{e2} \textbf{\&\&}
  \emph{e3} \textbf{\textless{}=} \emph{ub}. Also check that relative
  alignment constraints for \emph{e1}, \emph{e2}, and \emph{e3} are met.
\item
  \textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{)}:
  check that there is room for least one element of \emph{T}. This is
  the same as doing the check for
  \textbf{bounds\_cast\textless{}}T\textbf{\textgreater{}(}e1,
  1\textbf{)}: if \emph{e1} \textbf{!=} \textbf{0}, check that \emph{lb}
  \textbf{\textless{}=} \emph{e1} \textbf{\&\&} \emph{e1} \textbf{+}
  \textbf{sizeof(referent-type(}\emph{T}\textbf{) \textless{}=}
  \emph{ub}.

  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item ~
    \subsubsection{\texorpdfstring{\protect\hypertarget{ux5fToc437460798}{}{\protect\hypertarget{ux5fToc440445479}{}{\protect\hypertarget{ux5fToc440449261}{}{\protect\hypertarget{ux5fToc440551911}{}{}}}}Correctness
    of bounds\_cast\textless{}\emph{T}\textgreater{}
    conversions}{Correctness of bounds\_cast\textless{}T\textgreater{} conversions}}\label{correctness-of-boundsux5fcastt-conversions}
  \end{enumerate}
\end{itemize}

In this section, the correctness of the bounds\_cast conversions is
discussed. Readers interested in just using the operations may safely
skip this discussion.

We discuss only
\textbf{bounds\_cast\textless{}T\textgreater{}(}\emph{e1}\textbf{,}
\emph{e2}\textbf{,} \emph{e3)} because the other forms are special cases
of this operation. From Section 4, recall the meaning of a bounds
expression \textbf{bounds(}\emph{lb}\textbf{,} \emph{ub}\textbf{)} for
an expression \emph{e1} at runtime. Let the runtime values of \emph{e1},
\emph{lb}, and \emph{ub} be \emph{e1v}, \emph{lbv}, and \emph{ubv},
respectively. The value \emph{e1v} will be \textbf{0} or have been
derived via a sequence of operations from a pointer to some object
\emph{obj} with \textbf{bounds(}\emph{low}\textbf{,}
\emph{high}\textbf{)}. The following statement will be true: \emph{e1v}
\textbf{== 0 \textbar{}\textbar{} (}\emph{low} \textbf{\textless{}=}
\emph{lbv} \textbf{\&\&} ubv \textbf{\textless{}=}
\emph{high}\textbf{)}.

To ensure \textbf{bounds(}\emph{e2}\textbf{,} \emph{e3}\textbf{)} is
valid for \emph{e1}, we need to show the following:

\begin{quote}
Let \emph{e2v} and \emph{e3v} be the runtime values for \emph{e2} and
\emph{e3} respectively. Then \emph{e1v} \textbf{== NULL
\textbar{}\textbar{} (}\emph{low} \textbf{\textless{}=} \emph{e2v}
\textbf{\&\&} e3v \textbf{\textless{}=} \emph{high}\textbf{)}.
\end{quote}

Given \emph{e1v} \textbf{== 0 \textbar{}\textbar{} (}\emph{low}
\textbf{\textless{}=} \emph{lbv} \textbf{\&\&} ubv \textbf{\textless{}=}
\emph{high}\textbf{)}, the runtime check that if \emph{e1v} \textbf{!=}
\emph{0}, \emph{lbv} \textbf{\textless{}=} \emph{e2v} \textbf{\&\&}
e\emph{3v} \textbf{\textless{}=} \emph{ubv} implies \emph{e1v}
\textbf{== 0 \textbar{}\textbar{} (}\emph{low} \textbf{\textless{}=}
\emph{e2v} \textbf{\&\&} e3v \textbf{\textless{}=}
\emph{high}\textbf{).}

\subsubsection{\texorpdfstring{\protect\hypertarget{ux5fToc437460799}{}{\protect\hypertarget{ux5fToc440445480}{}{\protect\hypertarget{ux5fToc440449262}{}{\protect\hypertarget{ux5fToc440551912}{}{}}}}Static
checking use
core\_bounds\_cast\textless{}\emph{T}\textgreater{}}{Static checking use core\_bounds\_cast\textless{}T\textgreater{}}}\label{static-checking-use-coreux5fboundsux5fcastt}

\textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}}
uses static checking to enforce the preservation of bounds safety:

\begin{itemize}
\item
  \textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1},
  \emph{e2}\textbf{)} converts \emph{e1} to an \textbf{array\_ptr} or
  \textbf{array\_view} type with bounds
  \textbf{count(}\emph{e2}\textbf{)}.
\item
  \textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{,}
  \emph{e2}\textbf{,} \emph{e3}\textbf{)} converts \emph{e1} to an
  \textbf{array\_ptr} or \textbf{array\_view} type with bounds
  \textbf{bounds(}\emph{e2}\textbf{,} \emph{e3}\textbf{)}.
\item
  \textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{)}
  converts \emph{e1} to either a \textbf{ptr} or * type.
\end{itemize}

Like \textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}}, it
is a compile-time error if the bounds of e1 are \textbf{bounds(none)}.
There is no static checking if the bounds of e1 are
\textbf{bounds(any)}. If the bounds are \textbf{bounds(}lb\textbf{,}
ub\textbf{)}, the following must be provable via static checking:

\begin{itemize}
\item
  \textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1},
  \emph{e2}\textbf{)}: under the assumption that \emph{e1} != 0, lb
  \textless{}= \emph{e1} \&\& \emph{e1} + sizeof(referent-type(T)) * e2
  \textless{}= ub.
\item
  \textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{,}
  \emph{e2}\textbf{,} \emph{e3}\textbf{)}: under the assumption that
  \emph{e1} \textbf{!= 0}, \emph{lb} \textbf{\textless{}=} \emph{e2}
  \textbf{\&\&} \emph{e3} \textbf{\textless{}=} \emph{ub}. Also show the
  relative alignment constraints for \emph{e1}, \emph{e2}, and \emph{e3}
  are met: \textbf{(}e3 \textbf{--} \emph{e2}\textbf{) \%
  sizeof(referent-type(}\emph{T}\textbf{)) == 0 \&\& (e2 -- e1) \%
  sizeof(referent-type(}\emph{T}\textbf{)}), where arithmetic is done in
  bytes.
\item
  \textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{)}
  converts \emph{e1} to either a \textbf{ptr} or * type. For this, check
  that
  \textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1},
  \emph{1}\textbf{)} holds.
\end{itemize}

\textbf{core\_bounds\_cast} can be used when programmers do not want to
introduce the possibility of dynamic runtime failures due to bounds
casts. It is recommended for conversions between pointers to
constant-length arrays, which succeed at runtime using
\textbf{core\_bounds\_cast} if and only if they succeed at run-time
using \textbf{bounds\_cast}. For example, converting an array\_ptr of 12
characters to an array\_ptr of 4 32-bit integers should always succeed
at compile-time.

\subsubsection{\texorpdfstring{\protect\hypertarget{ux5fToc437460800}{}{\protect\hypertarget{ux5fToc440445481}{}{\protect\hypertarget{ux5fToc440449263}{}{\protect\hypertarget{ux5fToc440551913}{}{}}}}Conversions
without checking using
assume\_bounds\_cast\textless{}\emph{T}\textgreater{}}{Conversions without checking using assume\_bounds\_cast\textless{}T\textgreater{}}}\label{conversions-without-checking-using-assumeux5fboundsux5fcastt}

\textbf{assume\_bounds\_cast\textless{}}T\textbf{\textgreater{}}
converts unsafe pointers to safe pointers. The declared bounds are
trusted without verification, although relative alignment is checked if
necessary. The source expression must have an unsafe pointer type.

\begin{itemize}
\item
  \textbf{assume\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1},
  \emph{e2}\textbf{)} converts \emph{e1} to an \textbf{array\_ptr} or
  \textbf{array\_view} type with count(e2)
\item
  \textbf{assume\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{,}
  \emph{e2}\textbf{,} \emph{e3}\textbf{)} converts \emph{e1} to an
  \textbf{array\_ptr} or \textbf{array\_view} type with bounds(e2, e3).
  There is a runtime check that the relative alignment requirements for
  T are satisfied by \emph{e1,} \emph{e2} and \emph{e3}. \emph{e2} and
  \emph{e3} can have pointer type.
\item
  \textbf{assume\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}(}\emph{e1}\textbf{)}
  converts \emph{e1} to a \textbf{ptr} type or T \textbf{*}.
\end{itemize}

A subtle point about
\textbf{bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}} and
\textbf{core\_bounds\_cast\textless{}}\emph{T}\textbf{\textgreater{}}
are that they allow \emph{\emph{bounds-safe casts}} of an expression
\emph{e} of unsafe pointer type to an \textbf{array\_view} or
\textbf{array\_ptr} type. This is provided that the bounds for \emph{e}
can be determined. Only a few kinds of expressions with unsafe pointer
types have bounds that can be determined: address-of expressions
involving variables and uses of array variables, where the array
variable is converted to a pointer type.

\subsubsection{\texorpdfstring{\protect\hypertarget{ux5fToc437460801}{}{\protect\hypertarget{ux5fToc440445482}{}{\protect\hypertarget{ux5fToc440449264}{}{\protect\hypertarget{ux5fToc440551914}{}{}}}}Summary
of conversion
operators}{Summary of conversion operators}}\label{summary-of-conversion-operators}

The following table summarizes the operations for converting between
pointers to objects of different types, provided that S and T are
complete types:

\begin{longtable}[c]{@{}lllll@{}}
\toprule
To

From & array\_ptr\textless{}T\textgreater{} &
array\_view\textless{}T\textgreater{} & ptr\textless{}T\textgreater{} &
T *\tabularnewline
\midrule
\endhead
array\_ptr\textless{}S\textgreater{} &
bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2)

bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3)

core\_bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2)

core\_bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3) &
bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2)

bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3)

core\_bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2)

core\_bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3) &
bounds\_cast\textless{}ptr\textless{}T\textgreater{}\textgreater{}(e1)

core\_bounds\_cast\textless{}ptr\textless{}T\textgreater{}\textgreater{}(e1)
& bounds\_cast\textless{}T *\textgreater{}(e1)

If S==T, \&e1{[}i{]} can be used too.

assume\_bounds\_cast\textless{}T *\textgreater{}(e1)\tabularnewline
array\_view\textless{}S\textgreater{} & Same as above & Same as above &
Same as above & Same as above.\tabularnewline
ptr\textless{}S\textgreater{} & Same as above & Same as above. & Same as
above.

For bounds\_cast, it is a compile-time error if sizeof(S) \textless{}
sizeof(T). This is guaranteed to fail at runtime. &
bounds\_cast\textless{}T *\textgreater{}(e1)

assume\_bounds\_cast\textless{}T *\textgreater{}(e1)\tabularnewline
S * & If e1 has known bounds, same as above.

Otherwise:

assume\_bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2)

assume\_bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3) & If e1 has known bounds, same as above.

Otherwise:

assume\_bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2)

assume\_bound\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3). & If e1 has known bounds, same as above.

Otherwise:

assume\_bounds\_cast\textless{}T\textgreater{}(e1), & C cast operation
of the form (T *) e1\tabularnewline
\bottomrule
\end{longtable}

\protect\hypertarget{ux5fToc424307715}{}{}

\subsection{\texorpdfstring{\protect\hypertarget{ux5fToc437460802}{}{\protect\hypertarget{ux5fToc440445483}{}{\protect\hypertarget{ux5fToc440449265}{}{\protect\hypertarget{ux5fToc440551915}{}{\protect\hypertarget{ux5fToc426641112}{}{\protect\hypertarget{ux5fToc435434971}{}{}}}}}}Bounds-safe
conversions for pointers to incomplete types, including pointers to
void}{Bounds-safe conversions for pointers to incomplete types, including pointers to void}}\label{bounds-safe-conversions-for-pointers-to-incomplete-types-including-pointers-to-void}

The prior section , the source and destination pointer types in a
bounds\_cast or core\_bounds\_cast operation must be complete types or
have a referent type of void. However, there is one important exception:
ptr\textless{}T\textgreater{} can always be safely converted to T *,
even if T is incomplete. This follows from treating sizeof(T) as a
symbolic constant in the rules for computing bounds and the runtime
checking rules for bounds\_cast and core\_bounds\_cast.

This exception is useful when converting code incrementally from unsafe
pointer types to safe pointers. One may have converted the body of a
function to use safe pointers, but not yet have converted some functions
that it calls.

C allows pointer types to be freely converted to void * types and void *
types to be freely converted back to pointer types. For safe pointer
types, any kind of safe pointer type can be freely converted to the same
kind of pointer type with a referent type of void. However, explicit
casts must be used when converting from any kind of safe pointer type
with a referent type of void:

\begin{longtable}[c]{@{}lllll@{}}
\toprule
To From & T * & ptr\textless{}T\textgreater{} &
array\_view\textless{}T\textgreater{} &
array\_ptr\textless{}T\textgreater{}\tabularnewline
\midrule
\endhead
void * & Follow existing C rules & ptr\_cast\textless{}T\textgreater{},
if bounds are known.

assume\_ptr\_cast\textless{}T\textgreater{}, otherwise &
bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{},
if bounds are known:

- check relative alignment

assume\_bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2): e2 is length. No relative alignment check needed

assume\_bound\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3). e2/e3 are lower/upper bounds.

- check relative alignment &
bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}:
- has bounds(none) if bounds are unknown.

- check relative alignment if bounds are known.

assume\_bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2): e2 is length, no relative alignment check needed

assume\_bound\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}(e1,
e2, e3): e2/e3 are lower/upper bounds

- check relative alignment\tabularnewline
ptr\textless{}void\textgreater{} & Only the following unsafe operator is
available.

assume\_unsafe\_ptr\_cast: no check &
ptr\_cast\textless{}T\textgreater{}

\emph{\textbf{TODO: need unsafe operator}} & Not allowed & Not
allowed\tabularnewline
view\textless{}void\textgreater{} & unsafe\_ptr\_cast: check that memory
accessible by pointer dereference is in bounds

assume\_unsafe\_ptr\_cast: no check &
ptr\_cast\textless{}T\textgreater{}

check that memory accessible by pointer dereference is in bounds &
bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}:

- check relative alignment &
bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}:

- check relative alignment\tabularnewline
array\_ptr\textless{}void\textgreater{} & unsafe\_ptr\_cast: check that
memory accessible by pointer dereference is in bounds

assume\_unsafe\_ptr\_cast: no check &
ptr\_cast\textless{}T\textgreater{}

check that memory accessible by pointer dereference is in bounds &
bounds\_cast\textless{}array\_view\textless{}T\textgreater{}\textgreater{}:

- check relative alignment &
bounds\_cast\textless{}array\_ptr\textless{}T\textgreater{}\textgreater{}:

- check relative alignment\tabularnewline
\bottomrule
\end{longtable}

\subsection{\texorpdfstring{\protect\hypertarget{ux5fToc426641113}{}{\protect\hypertarget{ux5fToc435434972}{}{\protect\hypertarget{ux5fToc437460803}{}{\protect\hypertarget{ux5fRef437611522}{}{\protect\hypertarget{ux5fToc440445484}{}{\protect\hypertarget{ux5fToc440449266}{}{\protect\hypertarget{ux5fToc440551916}{}{}}}}}}}Bounds-safe
interfaces to existing unsafe
functions}{Bounds-safe interfaces to existing unsafe functions}}\label{bounds-safe-interfaces-to-existing-unsafe-functions}

The new pointer types capture specific properties of pointers. One would
like to update existing C code to use these new pointer types. However,
this will not be possible when backward compatibility requirements
exist. Consider C runtime functions or OS APIs. It may be feasible to
modify the header files for the runtime function or OS API. It may be
impossible to require all uses of these functions or APIs be updated.
Code written by 3\textsuperscript{rd} parties may use these APIs and it
is not reasonable for an existing shipping OS to require all
3\textsuperscript{rd} parties update their existing code to use the new
types.

Consider what would happen if the signature for memcpy were updated to
use \textbf{array\_ptr}. The function

void *memcpy(void *dest, const void *src, size\_t count);

becomes

void *memcpy(array\_ptr\textless{}void\textgreater{} dest,
array\_ptr\textless{}const void\textgreater{} src, size\_t count);

This, of course, breaks every piece of existing code that uses memcpy.
The code will no longer compile. C does not have method overloading, so
one cannot simply define multiple overloaded versions of memcpy. That
would also be duplicative and potentially increase program sizes.

The reverse problem also exists: suppose the signature for memcpy is not
updated. Then every ``safe'' method that calls memcpy would need to cast
the arguments to unsafe pointer types!

Given that we may not be able to change the pointer types of existing
APIs, we need to adopt an approach that supports backwards
compatibility, enables new safe code to be written easily, and maintains
the safety of new code.

We address this by:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Allowing programmers to declare bounds-safe interfaces to code and
  data structures that use unsafe pointers. A bounds-safe interface for
  a function, for example, describes bounds for unsafe pointer
  parameters.
\item
  In checked scopes, where only safe pointers are allowed, unsafe
  pointer types in bounds-safe interfaces are reinterpreted as safe
  pointer types. This makes the code in those scopes straightforward to
  understand: only safe pointers are used, all memory accesses are
  bounds checked or in bounds, and bounds-safe interfaces are trusted
  and respected.
\item
  In unchecked scopes, where safe and unsafe pointer types are allowed,
  we separate type checking concerns from bounds checking concerns. We
  allow implicit coercions at uses of bounds-safe interfaces between
  safe pointer types and unsafe pointer types. We also allow implicit
  coercions from unsafe pointer types to safe pointer types, subject to
  the limitation the bounds checking must also succeed.
\end{enumerate}

Functions that have parameters with unsafe pointer types or that return
values with unsafe pointer types can have bounds declared for the unsafe
pointer parameters or the unsafe pointer return value. Bounds must be
declared for all parameters with unsafe pointer types and the return
value, if it has an unsafe pointer type. In the case where a parameter
has \textbf{ptr} type, this can be declared specially.

Here is the bounds-safe interface for memcpy:

void *memcpy(void *dest : count(len), const void *src : count(len),
size\_t len)

where return\_value : bounds(dest, dest + count)

The correctness of bounds information is enforced at compile-time when
memcpy is passed safe pointer arguments. It is not enforced when memcpy
is passed unsafe pointer arguments.

Similarly, for data structures, members with unsafe pointer types can
have bounds declared. If bounds are declared for one member of a
structure with an unsafe pointer type, they must be declared for all
members with unsafe pointer types.

Here are the bounds for a structure that is a counted buffer of
characters.

struct S \{

char *arr : count(len);

int len;

\}

We may have a method that takes a counted buffer of characters and
counts the number of instances of a specific character. The \textbf{ptr}
declaration can be used to declare an unsafe pointer to a singleton
object of a type:

int count\_char(S *str where ptr, char arg);

It is very important to understand that the \emph{semantics of unsafe
pointers does not change even when bounds are declared for the
pointers}. The declared bounds are used only when checking safe code
that calls unsafe functions or uses unsafe data structures. Unsafe
pointer dereferences do not have bounds checks added to them. A method
that declares a bounds-safe interface and whose body consists of only
unsafe code is compiled as though the bounds-safe interface has been
stripped from its source code.

\subsection{\texorpdfstring{\protect\hypertarget{ux5fRef424639711}{}{\protect\hypertarget{ux5fToc426641114}{}{\protect\hypertarget{ux5fToc435434973}{}{\protect\hypertarget{ux5fToc437460804}{}{\protect\hypertarget{ux5fToc440445485}{}{\protect\hypertarget{ux5fToc440449267}{}{\protect\hypertarget{ux5fToc440551917}{}{}}}}}}}implicit
conversions}{implicit conversions}}\label{implicit-conversions}

In unchecked scopes, we allow implicit coercions from safe pointer types
to the corresponding unsafe pointer types in the following cases. In
each case, one or more types is reinterpreted and type checking proceeds
with the reinterpreted types:

\begin{itemize}
\item
  Function call:

  \begin{itemize}
  \item
    If the function being called has a bounds-safe interface for unsafe
    pointer type arguments and an argument expression has a safe pointer
    type, then the type of each argument of a safe pointer type will be
    reinterpreted as the corresponding unsafe pointer type.
  \end{itemize}
\item
  Field assignment: if the left hand side has an unsafe pointer type,
  the right-hand side has a safe pointer type, and the left-hand side is
  a member of a type with a bounds-safe interface, then the right-hand
  side type will be reinterpreted as the corresponding unsafe pointer
  type.
\end{itemize}

We allow coercions from unsafe pointer types to the corresponding safe
pointer types in the following cases:

\begin{itemize}
\item
  Function call:

  \begin{itemize}
  \item
    If a function being called has a parameter of a safe pointer type
    and the type of an argument is an unsafe pointer, then the type of
    the argument will be reinterpreted as the corresponding safe pointer
    type.
  \end{itemize}
\item
  Assignment: if the left hand side has a safe pointer type to T, the
  right-hand side has an unsafe pointer type to T, then the right-hand
  side type will be reinterpreted as the corresponding safe pointer
  type.
\end{itemize}

The rules for checking bounds are applied separately. These rules are
extended to deal with bounds-safe interface functions as follows.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Respecting bounds interfaces:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    If function call has arguments with safe pointer types that are
    converted implicitly to unsafe pointer types, then the bounds for
    the arguments must satisfy the bounds requirements for the unsafe
    pointer parameters. In addition,

    \begin{enumerate}
    \def\labelenumiii{\roman{enumiii}.}
    \item
      If an argument corresponds to a parameter that has a bounds
      declaration, the argument will be checked to see if it is in
      bounds following the bounds declaration.
    \item
      If an argument corresponds to a parameter that has \textbf{ptr}
      declaration, the argument will be checked to see if it is in
      bounds of its computed bounds.
    \end{enumerate}
  \item
    TBD: field assignment to a member of a type with a bound-safe
    interface (the issue is that we never infer when a bounds is valid).
  \end{enumerate}
\item
  Trusting bounds interfaces:

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \item
    If a function call returns an unsafe pointer and the function has a
    bounds-safe interface, the bounds for the return value will be
    computed the same as if the function returned an \textbf{array\_ptr}
    type.
  \item
    If a member access returns an unsafe pointer and the member access
    is to a type with a bounds-safe interface, the member access will
    have the bounds declared for it by the member bounds declared in the
    type.
  \end{enumerate}
\end{enumerate}

Here are some examples:

void f()

\{

int a;

// the type of \&a will be int *. This will be implicitly converted to

// ptr\textless{}int\textgreater{}.

ptr\textless{}int\textgreater{} pa : bounds(\&a, \&a + 1) = \&a;

int arr{[}5{]}{[}5{]};

// the type of arr will be int{[}5{]} *. This will be implicitly
converted to

// ptr\textless{}int{[}5{]}\textgreater{}

ptr\textless{}int{[}5{]}\textgreater{} parr : bounds(arr, arr + 1) =
arr;

...

\}

void copy(array\_ptr\textless{}int\textgreater{} dest : count(len),

array\_ptr\textless{}int\textgreater{} src : count(len), int len)

\{

// dest, src will be converted to a void *

// The checking of bounds information succeeds at compile time.

// The runtime bounds checks that dest and src are in range are

// guaranteed to succeed

memcpy(dest, src, len);

\}

f(S s)

\{

int len = s.len;

array\_ptr\textless{}char\textgreater{} sp : count(len) = s.arr;

\ldots{}

if (len \textgreater{} 0) \{

sp{[}0{]} = `a';

\}

\}

The following example will fail at compile time. The bounds for sp will
be computed as \textbf{bounds(none)}, which clearly does not match
\textbf{count(sp, sp + 1)}.

char *random();

f() \{

array\_ptr\textless{}char\textgreater{} sp : count(1) = random();

\}
 
\chapter{Bounds for structure types}\label{bounds-for-structure-types}

This section extends reasoning about bounds to variables with structure
types by introducing bounds for members of structures.

Structure types may have members with \arrayptr\ types. Those
members must have \emph{member bounds} associated with them in order for
the values stored there to be used to access memory. A structure member
declaration may include a \keyword{where} clauses that declares member
bounds. The bounds for a member also may be placed inline at the
declaration of the member. The list of declarations of structure members
may also include where clauses at top-level. Here are examples:

\begin{verbatim}
struct S {
   array_ptr<int> data : count(num);
   int num;
};
\end{verbatim}

or

\begin{verbatim}
struct S {
    array_ptr<int> data where data : count(num);
    int num;
}
\end{verbatim}

or

\begin{verbatim}
struct S {
    array_ptr<int> data;
    int num;
    where data : count(num);
}
\end{verbatim}

Member bounds are invariants that are assumed to be true by default for
objects of that type. A member bound may be suspended for a specific
object to allow for initialization of the object or modification of the
members involved in the member bounds declarations. The member bound
must be declared to hold again before \arrayptr\ field covered
by the bounds can be used to access memory. Here is an example of
variable of type S being initialized:

\begin{verbatim}
void f(int len) {
    S y 
    where suspends(y.data);
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len))
    y.data = newarr;
    y.num = len
    where holds(y.data);    // the member bounds for y.data now holds
    …
}
\end{verbatim}

Suspends and holds are dataflow-sensitive declarations of the state of
the member bounds for a specific member of variables. They can be
applied to variable members that have member bounds.

They also can be applied to variables or variable members with structure
type as a syntactic short-hand. In that case, they apply the nested
members of the variable or variable member. The example could also be
written as:

\begin{verbatim}
void f(int len) {
    S y 
    where suspends(y);
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len))
    y.data = newarr;
    y.num = len
    where holds(y);    // the member bounds for y.data now holds
    ...
}
\end{verbatim}

Making member bounds be invariants provides a way to deal with issues
causing by aliasing. There can be pointers to data structures or members
of data structures. There may be multiple pointers to a single object or
member of an object stored in memory. When there are multiple pointers,
the pointers are said to be aliases because they all name the same
memory location. The object is aliased. Aliasing makes it hard to reason
about the behavior of the program.

Consider the example:
\begin{verbatim}
f(S *q, S *r, bool b)
{
   if (b) {
      q->arr = malloc(sizeof(int)*5);
      q->len = 5;
   }
   else {
      r->arr = malloc(sizeof(int)*5);
      r->len = 5;
   }
}
\end{verbatim}

Even when b is true, the value \texttt{r-\textgreater{}arr} may still be
changed by a call to f. This can happen when \texttt{q} and \texttt{r}
are the same value and are aliases for the same memory location.
Changing one named value (\texttt{q-\textgreater{}arr}) can have the
effect of changing some other value with a distinct name
(\texttt{r-\textgreater{}arr}). In general, it is difficult to know
whether an assignment through one pointer variable is affecting the
members of other pointer variables.

Member bounds being invariants for structure members allow localized
reasoning about bounds. A programmer can assume that the bounds are true
for objects of that type. The member bounds may be suspended temporarily
for specific objects while they are being initialized or modified.

The bounds declarations for variables with structure types and the
suspend and hold declarations will be checked statically for validity.
Section 8 extends the rules from Section 0 to variables with structure
types and to suspends and holds declarations.

In the rest of this section, to simplify the description, assumptions
about address-taken variables similar to those in Section 3.7 are made.
It is assumed that none of the variables or members of variables on the
left-hand side of bounds-declarations have their addresses taken. It is
assumed also that the values of variables or members of variables whose
addresses are taken are not used in bounds expressions.

\section{Declaring bounds for structure members}\label{declaring-bounds-for-structure-members}

Member bounds declarations have the form:

\var{member-bounds-decl}:

\begin{quote}
\var{member-path} : \var{member-bounds-exp}
\end{quote}

\var{member-path:}

\var{identifier}

\var{member-path} \texttt{.} \var{identifier}

A member path is a sequence of one or more member names, separated by
the `.' operator. The sequence of members must be a valid sequence of
member accesses for the structure type. The common case of using a
member of the structure type is simply a member path of length 1.

Member bounds expressions are similar to the bounds expressions
described in Section 4.1, except that members of the structure type are
used in place of variables in the non-modifying expressions. In
addition, pointer indirection and indirect member references are
excluded.

A structure member whose type is \arrayptr\ or an incomplete
checked array type may have at most one bounds declared for it. The
typing rules for member bounds declarations are the same as those for
bounds declarations. For bounds declarations of the form
\var{member-path} \texttt{:} \texttt{count(}\var{e1}\texttt{)}, the
member-path must have an \arrayptr\ type and cannot be the type
\arrayptrvoid . The expression
\var{e1} must have an integral type. For bounds declarations of the
form \var{member-path} \texttt{:} \bounds{\var{e1}}{\var{e2}}, the types of \var{x}, \var{e1}, and \var{e2}
must be \arrayptr\ types. The types must be the same type,
except that any of them can be
\arrayptrvoid .

A structure consists of a list of member declarations, each of which
consists of type specifier followed by one or more structure member
declarators. Structure member declarators are changed to allow an
optional where clause or in-line specification of member. The in-line
specification of member follows syntax that is already used for
declaring bitfields:

\var{struct-member-declarator:}

\begin{quote}
\var{declarator where-clause\textsubscript{opt}}

\var{declarator\textsubscript{opt}} \texttt{:}
\var{constant-expression}

\var{declarator} \texttt{:} \var{member-bounds-exp}
\var{where-clause\textsubscript{opt}}
\end{quote}

The list of member declarations is extended to include \keyword{where}
clauses:

\var{struct-member-declaration:}

\begin{quote}
\ldots{}

\var{where-clause}\textsubscript{opt}
\end{quote}

The remaining syntax for specifying a structure remains unchanged:

\var{struct-or-union-specifier:}

\begin{quote}
\var{struct-or-union identifier\textsubscript{opt}} \texttt{\{}
\var{struct-member-declaration-list} \texttt{\}}
\end{quote}

\var{struct-member-declaration-list:}

\begin{quote}
\var{struct-member-declaration}

\var{struct-member-declaration-list struct-member-declaration}
\end{quote}

\var{struct-member-declaration:}

\begin{quote}
\var{specifier-qualifier-list struct-declarator-list} \texttt{;}
\end{quote}

\var{struct-declarator-list:}

\begin{quote}
\var{struct-declarator}

\var{struct-declarator-list} \texttt{,} \var{struct-declarator}
\end{quote}

A member bounds expression can use members and child members of the
structure being declared. Any member paths occurring in the member
bounds expressions must start with members of the structure type being
declared. Here is an example of the use of child members:

\begin{verbatim}
struct A {
   array_ptr<int> data;
}

struct N {
    int num;
}

struct S {
   A a
   where count(a.data) == n.num;
   N n;
};
\end{verbatim}

Allowing member bounds to use nested members of members complicates
explaining concepts. Sometimes concepts will be explained using member
bounds that use only immediate members and then generalized to handle
nested members.

\section{Bounds declarations for variables with structure types}\label{bounds-declarations-for-variables-with-structure-types}

To describe facts about members of specific variables, the left-hand
sides of bound declarations are generalized to allow members of
variables. The term \emph{variable member path} stands for variables or
variables with member accesses. Variable member paths are used where
variables were allowed:

\var{bounds-decl:}

\begin{quote}
\var{var-member-path} \texttt{:} \var{bounds-exp}
\end{quote}

\var{var-member-path:}

\var{identifier}

\var{var-member-path} \texttt{.} \var{identifier}

The first identifier in a variable member path must be the name of a
local variable or parameter. The rest of the path, if there is one, must
describe a member path for the structure type that has an
\arrayptr\ type. The member path can be used as a name for its
associated member bounds. Inline bounds declarations are still
restricted to variables.

\section{Declaring the state of member bounds for variables}\label{declaring-the-state-of-member-bounds-for-variables}

Programmers may declare the state of a member bounds for a variable
using two kinds of facts:

\var{fact:}

\var{\ldots{}}

\texttt{suspends(}\var{var-member-path}\texttt{)}

\texttt{holds(}\var{var-member-path}\texttt{)}

If the \var{var-member-path} has an \arrayptr\ type, it must
have the form \var{x.path,} where x is local variable or parameter
name. The fact \texttt{suspends(}\var{x.path}\texttt{)} means that the
member bounds declared by the type of x for \var{path} does not
currently hold for x. The fact \texttt{holds(}\var{x.path}\texttt{)}
means that the member bounds declared by the type of x for \var{path}
holds now for x.

As a convenient short-hand notation, the \var{var-member-path} can have
a structure type. In that case, the declaration applies to all member
bounds for the structure type and child members of the structure type.

\subsection{Parameters and return values}\label{parameters-and-return-values}

The state of members bounds can be declared for parameters and return
values using suspends and holds as well. By default, the state is
\texttt{holds}.

Consider the following structure type definitions:

\begin{verbatim}
struct S {
    array_ptr<int> data : count(num);
    int num;
}

struct T {
    S arr1;
    S arr2;
    array_ptr<float> weights : count(len);
    int len;
}
\end{verbatim}

Here are some function declarations involving the state of member
bounds:
\begin{verbatim}
T f(T x where holds(x)) where holds(return_value)   // the default 

T f(T x where suspends(x.arr1))
where suspends(return_value.arr2)

T f(T x where suspends(x.arr1.data)
where suspends(return_value.arr1.data)
\end{verbatim}

\begin{quote}
\emph{One thing to consider is whether to allow functions to be
parametric with respect to the state of member bounds. This might be
useful to describe a function that sets one of the members of a
structure type and does not affect the state of other members.}
\end{quote}

\subsection{Extent of declarations of member bounds state for variables}\label{extent-of-declarations-of-member-bounds-state-for-variables}

Declarations of the state of member bounds are dataflow-sensitive and
follow rules similar to flow-sensitive bounds declarations.

We first define the set of state declarations that apply to a function
component, where a function component is an expression statement,
variable declaration, or part of a compound statement.

The state declarations for variables and variable members with structure
types are expanded to state declarations of the individual members with
\arrayptr\ type. It is assumed that declarations of automatic
structure variables without initializers implicitly have suspends
declarations for the variables. All other declarations of structure
variables are assumed implicit to have holds declarations for the
variables. The other declarations are either automatic variables with
initializers or variables with static storage, which are initialized to
0. Any array\_ptr members initialized to 0 have \boundsany, so
they satisfy their member bounds declarations.

For any declaration of member bounds state for \var{v}.\var{mp}, where
v is variable and \var{mp} is a member path, if

\begin{enumerate}
\item
  There is some path from the declaration to the function component, and
\item
  \var{v} occurs in the function component, and
\item
  There is no other declaration of member bounds state for \var{v.mp}
  along the path
\end{enumerate}

then

\begin{enumerate}
\item
  The declaration of member bounds state applies
\end{enumerate}

This condition ensures the consistency of member bounds state
declarations for variables:

\begin{enumerate}
\item
  \emph{Agreement of bounds declarations}: If a variable occurring in a
  function component has more than one state declaration that applies to
  it at the component, then all the state declarations applying to it at
  the component must be syntactically identical. This avoids ambiguity
  about which state declaration applies to an occurrence of a variable.
  It an error for the member bounds state declarations to disagree.
\end{enumerate}

The following example illustrates the declaration of member bounds
state. The structure S represents variable length array, where data
holds a pointer to the data for the array and num is the length of the
array. The function f takes a length parameter len and creates an
initialized instance of S in the variable y. It then copies y to z.

\begin{verbatim}
struct S {
   array_ptr<int> data
   where count(data)== num;
   int num;
};
\end{verbatim}

Here is a version of f where all member bounds state declarations are
explicit. For structure variable members whose member bounds is
suspends, the bounds declarations are explicit as well.

\begin{verbatim}
void f(int len) {
    S y where suspends(y.data);
    S z where suspends(z.data);
    int i, j;
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len))
    y.data = newarr
    where y.data : count(len);
    y.num = len
    where holds(y.data);   // the member bounds for y.data now holds
    z = y
    where holds(z.data);
}
\end{verbatim}

This can be written more succinctly as:

\begin{verbatim}
void f(int len) {
    S y;
    S z;
    int i, j;
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len))
    y.data = newarr
    where y.data : count(len);
    y.num = len
    where holds(y);   // y is initialized now
    z = y
    where holds(z);   // z is initialized now
}
\end{verbatim}

\section{Integration of member bounds and bounds for variables}\label{integration-of-member-bounds-and-bounds-for-variables}

A member of a structure variable may be covered by its member bounds
declaration and a bounds declaration at the same time. This coexistence
happens when a member is initialized to satisfy its member bounds
declaration. Here is a version of f that is annotated with both member
bounds and bounds declarations for members of a variable.
\begin{verbatim}
void f(int len) {
    S y;
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len))
    y.data = newarr
    where newarr : count(len) && y.data : count(len)
    y.num = len
    where holds(y.data) && y.data : count(len) && 
          y.data : count(y.num)
    ...
}
\end{verbatim}

After the assignment \texttt{y.num = len}, the member bounds holds for
y.data and so does the bounds \texttt{y.data : count(y.num)}.

\subsection{Determining bounds for a use of an \arrayptr\ member of a variable}\label{determining-bounds-for-a-use-of-an-arrayux5fptr-member-of-a-variable}

When a member path \var{mp} of a variable \var{x} is used and
\var{x}\texttt{.}\var{mp} has type \arrayptr, the bounds for
\var{x}\texttt{.}\var{mp} are determined using these rules:

\begin{itemize}
\item
  If the use is within the extent of a bounds declaration
  \var{x}\texttt{.}\var{mp} \texttt{:} \var{bounds-exp} and
  \var{bounds-exp} is not \boundsnone, \var{bounds-exp} is
  the bounds.
\item
  Otherwise, if the state of the member bounds for
  \var{x}\texttt{.}\var{mp} is \texttt{holds}, the member bounds for
  \var{x}\texttt{.}\var{mp} is used.
\item
  Otherwise, the bounds of \var{x}\texttt{.}\var{mp} is
  \boundsnone.
\end{itemize}

\subsection{Suspends declarations and bounds for variables.}\label{suspends-declarations-and-bounds-for-variables.}

When the member bounds \var{m}b for a variable member is suspended by a
statement of the form:

\var{e2} \keyword{where} \texttt{suspends(}\var{x.mp}\texttt{);}

where \var{x} is a variable and \var{mp} is a member path, there is an
implicit bounds declaration for \var{x}\texttt{.}\var{mp} at the point
of suspension. This happens unless \var{e2} modifies a member \var{m}
of \var{x} that occurs in \var{mb}. In addition, the state of the
member bounds for \var{x}\texttt{.}\var{mp} must be \texttt{holds}
before the statement. The member bounds declaration \var{mb} is
converted to a bounds declaration by prefixing each occurrence of a
member path in \var{mb} with the expression ``\var{x}\texttt{.}''.

For example, given

\begin{verbatim}
 S  copy_and_resize(S arg, int len) {
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len)
       where suspends(arg);
    for (int i = 0; i < arg.num; i++) {
       newarr[i] = arg.data[i];
    }
    arg.data = newarr where arg.data : count(len);
    arg.num = len where arg.data : count(arg.num)
    where holds(arg);   // member bounds for arg holds now
    return arg;
}
\end{verbatim}


There is implicitly a bounds declaration at the suspension of the member
bounds for arg:

\begin{verbatim}
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len)
       where suspends(arg) && arg.data : count(arg.num);
\end{verbatim}

If the suspends were done after the assignment to \texttt{arg.data}:

\begin{verbatim}
    arg.data = newarr
    suspends(arg);
\end{verbatim}

there would not be an implicit bounds declaration because arg.data is
modified by the assignment.

At a declaration of a structure variable x, no implicit bounds
declarations are inserted if the declaration suspends the member bounds
for a member of x. There was no point at which the member bounds was
known to be true. For example,

\begin{verbatim}
f(S arg where suspends(arg))
\end{verbatim}

does not have an implicit bounds declaration of the form \verb|arg.data :count(arg.len)|.

\subsection{Holds declarations and bounds for variables}\label{holds-declarations-and-bounds-for-variables}

At a holds declaration for a member path mp of a structure variable x,
the bounds declarations that are true about members of x, as well as any
facts that are true at the point of the holds declaration, must imply
that the member bounds for mp holds.

\begin{quote}
\emph{To do: this is just a special case of the fact that a member
bounds for a structure variable must be true after all statements in the
scope of the variable, unless the member bounds is suspended after the
statement. }

\emph{To do: it seems that requiring programmers to explicitly call out
interesting facts involving equality of variables or variable members
leads to a lot of verbosity in programs. We should reconsider whether
these must be explicitly declared by the programmer.}
\end{quote}

\section{Bounds-safe interfaces}\label{bounds-safe-interfaces}

Just as existing functions can have bounds-safe interfaces declared for
them, existing structure types can have bounds-safe interfaces declared
for them. This allows safe code to use those data structures and for
those uses to be checked. Existing unsafe code is unchanged.

To create a bound-safe interface for a structure type, a programmer
declares member bounds for structure members with unsafe pointer types.
A programmer may also declare whether an unsafe pointer should be
treated as \ptr\ type by safe code.

Here is a bound-safe interface for a structure that is a counted buffer
of characters:

\begin{verbatim}
struct CountedBuffer {
     char *arr : count(len);
     int len;
}
\end{verbatim}

Here is a bounds-safe for interface for a structure for a node in a
binary tree. The node contains two pointers to two other nodes. Pointer
arithmetic on those two other nodes is not allowed.

\begin{verbatim}
struct BinaryNode {
    int data;
    BinaryNode *left : ptr;
    BinaryNode *right : ptr;
}
\end{verbatim}

If bounds information is declared for one member of a structure with an
unsafe pointer type, it must be declared for all other members of the
structure with unsafe pointer types.

It is important to understand that the \emph{semantics of unsafe
pointers does not change even when bounds are declared for the
pointers}. The declared bounds are used only by safe code that uses the
data structure, when storing safe pointers into the data structure, and
when converting unsafe pointers data structures, and when reading safe
pointers from the data structure unsafe functions or uses unsafe data
structures.

\section{Bounds for pointers with information stored in unused bits}\label{bounds-for-pointers-with-information-stored-in-unused-bits}

C programs sometimes store information in unused bits of pointers. This
is typically done to save space in data structure. For example, a
program might store a tag in the least significant bits or most
significant bits of some pointers, knowing that those bits are always
zero otherwise. This section covers how to represent the bounds of these
pointers and extends the rules for checking bounds declarations to
expressions that modify bits of pointers.

The bounds of such a pointer are easy to described: they are the bounds
of the original pointer. If a pointer variable or member is used in its
own bounds, the additional information must be removed first. This is
done by masking out the bits that always 0.

For example, suppose there is the following structure:

\begin{verbatim}
struct S {
   array_ptr<int> p : bounds(p, p + 4);
   int tag : 2;
}
\end{verbatim}

A programmer might know that on a machine with 32 bit pointers, the
least 2 significant bits of p are always 0, so tag could be stored
within p. The bounds would be changed to:

\begin{verbatim}
struct S {
   array_ptr<int> p : bounds((array_ptr<int>) ((size_t) p & ~3), 
                             (array_ptr<int>) ((size_t) p & ~3) + 4) rel_align(char);
}
\end{verbatim}

There is one important caveat: tags cannot be stored in null pointers. A
null pointer may have bounds that are not valid. This is fine because
the null pointer may not be used to access memory. However, tagging a
null pointer could result in a non-null pointer with bounds that are not
valid. This non-null pointer could be used to incorrectly access memory.

\subsection{Extending bounds checking rules to integral
expressions}\label{extending-bounds-checking-rules-to-integral-expressions}

C programs modify bits in pointers by converting pointers to integers,
operating on integers, and converting the integers back to pointers. The
rules for inferring bounds for expressions are extended to track bounds
through integral expressions:

\begin{itemize}
\item
  Given e1 op e2, where op is an additive, multiplicative, or bitwise
  binary operator on integral types, the bounds of e1 and e2 can be
  computed:

  \begin{itemize}
  \item
    If e1 has bounds b, where b is not bounds(none), and e2 has
    bounds(none), and it can be proved that e1 != 0, then e1 op e2
    \texttt{:-} b.
  \item
    If the special variable \texttt{expr\_current\_value} occurs in b

    \begin{itemize}
    \item
      If e1 op e2 is invertible, then inverse of e1 op e2 is substituted
      for \texttt{expr\_current\_value}.
    \item
      Otherwise the bounds of the expression are altered to be
      bounds(none).
    \end{itemize}
  \item
    Similar rules apply for the reverse situation where e1 has
    bounds(none) and e2 has bounds b, where b is not bounds(none).
  \end{itemize}
\item
  Given e1 op e2 where op is a shift operator, e1 is the integral value
  being shifted, and e2 is the shift amount,

  \begin{itemize}
  \item
    If e1 has bounds b, where b is not bounds(none), and e2 has
    bounds(none), and it can be proved that e1 != 0, then e1 op e2
    \texttt{:-} b.
  \item
    If the special variable \texttt{expr\_current\_value} occurs in b,
    bounds of the expression are altered to be bounds(none). Shift
    expressions are not invertible because they lose information.
  \end{itemize}
\end{itemize}

\subsection{An example}\label{an-example-1}

The following code shows a tag of 1 can be set in a non-null pointer:

\begin{verbatim}
#define untagged_bounds(x) \
   bounds((array_ptr<int>) ((size_t) x & ~3), \
          (array_ptr<int>) ((size_t) x & ~3) + 4) rel_align(char)

S set(S s) 
{
  array_ptr<int> a : untagged_bounds(a) = s.p;
  if (a != NULL) {
    size_t y : untagged_bounds(a) = ((size_t) a) | 1;
    dynamic_assert(y & ~0x3 == (size_t) a & ~0x3); // always true
    // legal by substitution of y & 0x3 for a & ~0x3
    where y : object_bounds(y & ~0x3, y & ~0x3) relative_align(none);
    // exp : object_bounds(a,b) implies exp : bounds(a,b), no matter what
    // the value of exp
    where y : bounds(y ~0x3, y & ~0x3);
    // satifies member bounds requirements
    s.p = (array_ptr<int>) y;
   }
}
\end{verbatim}

This could be condensed to:
\begin{verbatim}
S set(S s) 
{
   array_ptr<int> a : bounds(a & ~0x3, a & ~0x3) = s.p;
   if (a != NULL) {
       size_t y : bounds(a & ~0x3, a & ~0x3) rel_align(char) = ((size_t) a) | 1;
       dynamic_assert(y & ~0x3 == a & ~0x3);
       where y : object_bounds(y & ~0x3, y & ~0x3) rel_align(char);
       s.p = (array_ptr<int>) y;
   }
} 
\end{verbatim}

\chapter{Checking bounds for structure types}\label{checking-bounds-for-structure-types}

In this section, to simplify the presentation, it is assumed that none
of the local variables, parameters, or variable member paths that appear
in a bounds expression have their addresses taken. The prefix paths of
variable member paths cannot have their address taken also. The one
exception is that an address-taken variable or variable member path may
appear as the operand to an address (\&) operator on the right-hand side
of a bound expression.

This lets us avoid complicating the explanation with the subtleties of
handling aliasing of variables. Section 11 will discuss address-taken
variables.

\section{Bounds for expressions without assignments}\label{bounds-for-expressions-without-assignments}

This section discusses expressions without assignments. It generalizes
Section 5.1 to handle variables of structure type. Generally, this
consists of allowing variable member paths to occur where variables
could occur. Variable member paths are a syntactic generalization of
variables: they consist of a variable or a variable with a sequence of
member access.

\subsection{Variable member paths}\label{variable-member-paths}

If the variable member path is simply a variable, the rules in Section
5.2.2 still apply. Otherwise, it is member path of the form
x.\var{path}, where x is a variable and \var{path} is a sequence of
one or more members separated by `.' operators.

\subsubsection{Paths with type \arrayptr}\label{paths-with-type-arrayux5fptr}

If \var{x.path} has the type \arrayptr, the bounds information for
\var{x.path} is determined using Section 7.4.1. If the resulting bounds
information is a bounds expression, it is used directly.

If the result is a member bounds, the result must be translated to a
variable-level bounds expression. Let \var{prefix} be \var{x.path} with the
last member access removed. Then for each member path \var{mp} that
occurs in the member bounds, substitute \var{prefix.mp} in place of mp
to create the variable-level bounds.

Consider the example:
\begin{verbatim}
struct S {
   array_ptr<int> data : count(num);
   int num;
};

void f(int len) {
    S y;
    int i, j;
    array_ptr<int> newarr : count(len) = (array_ptr<int>) malloc(sizeof(int) * len));
    y.data = newarr
    where suspends(y.data) && y.data : count(len);
    y.num = len
    where holds(y.data);   // the type-level invariant for y.data now holds
    z = y;
    …
    i = z.data[0];
    j = y.data[0];
}
\end{verbatim}

For the assignment \texttt{i = z.data[0]}, the bounds for
\texttt{z.data} must be determined. The member bounds is \texttt{data:
count(num)}. In this case, the prefix of \texttt{z.data} is simply
\texttt{z}, so the member bounds is transformed to the variable-level
bounds \texttt{z.data : count(z.num)}.

For the assignment \texttt{j = y.data[0]}, the variable-level bounds
\texttt{y.data : count(len)} holds, in addition to the member bounds.
The variable-level bounds will be used, avoiding a load of the length
from \texttt{y.num}.

\subsection{Paths with type array}\label{paths-with-type-array}

If \var{x.path} has an array type with a known number of elements n,
such that \var{x.path} is being converted implicitly to a pointer type,
the bounds is:

\var{x.path} : bounds(\var{x.path}, \var{x.path} + n)

\subsection{Paths with structure type}\label{paths-with-structure-type}

\emph{TODO: This type of expression produces an intermediate value that
needs a name. We will need to describe the variable-level bounds and the
state type-level invariants for individual members of this intermediate
value. It could be simple as saying that we create a variable whose name
is distinct from other variable names in the program and describe the
invariants in terms of members of that variable. The name `current'
could be a placeholder for the variable name.}

\subsection{Addresses of variable member paths}\label{addresses-of-variable-member-paths}

A variable member path \var{p} whose address is taken is considered an
array of one element. It has the bounds:

\&p : bounds(\&p, \&p + 1)

\subsection{Function calls}\label{function-calls-1}

\emph{TODO: fill this in}

\section{Bounds for assignment expressions}\label{bounds-for-assignment-expressions}

\emph{TODO: fill this in}

\chapter{Member bounds and pointers to structure types}\label{member-bounds-and-pointers-to-structure-types}

A member bounds may be suspended for an object that is referenced using
a pointer. The syntax for this is:

\var{fact ::=}

\texttt{suspends(}\var{exp}\texttt{-\textgreater{}}\var{identifier}\texttt{)}

\texttt{holds(}\var{exp}\texttt{-\textgreater{}}\var{identifier\texttt{)}}

\var{exp} must have type \ptrinst{\textit{S}}, where
\var{S} is some struct type, and \var{identifier} must be a field of
\var{S}. In practice facts of the form (*\var{exp}).\var{identifier}
will be allowed also. In this description,
(*\var{exp}).\var{identifier} is omitted because it is semantically
identical to \var{exp}\texttt{-\textgreater{}}\var{identifier}.

A member bounds may be suspended for an expression on entry to a
function or on exit to a function. If it is suspended on exit, the
expression must involve only the return value and parameter variables
and the parameter variables cannot be changed during the body of the
method.

Here are examples of several functions with suspended member bounds on
function entry and exit:

\begin{verbatim}
struct S {
     array_ptr<int> a : count(len);
     int len;
}

// Member bounds for arg is suspended and remains suspended
// on exit
void f1(S *arg where suspends(arg->a)) where suspends(arg->a)
{
   ...
}

 // Member bounds for arg is suspended on entry and holds on exit
void *f2(S *arg where suspends(arg->a))
{ 
     ...
}

// Member bounds is suspended for the return value.
S *f3() where suspends(return->a)
{
    ...
}

// Member bounds is suspended for the argument on entry.
// It is suspended on exit for the return value and the argument.
S *f3(S *arg) where suspends(return->a) &&  suspends(arg->a)
{
    ...
}
\end{verbatim}

While a member bounds is suspended for an object, the
\arrayptr\ field of that object covered by that invariant
cannot be used to access memory. The possibility of aliasing makes
enforcing this rule complicated. Other variables or memory locations may
hold pointers to the object pointed to by \var{exp}. The
\texttt{suspends} and \texttt{resume} annotations apply to \var{exp}
only. The other variables or memory locations may not be annotated as
having suspended member bounds, so they could be used to access memory
using an \arrayptr\ field in an inconsistent fashion.

To prevent this, restrictions are placed on what code can do while a
member bounds is suspended. The restrictions make conservative
assumptions about the possible aliases of exp. In practice, member
bounds should only be suspended for brief pieces of code. Section 9.1
describes the rules that enforce these restrictions. Section 9.3
contains proposals for loosening these restrictions by relying on
additional information about pointer aliasing.

We assume for now that the address of a field in a structure type that
is used in a member bounds cannot be taken. If it could be taken, it
would be trivial to break the member bounds.

\section{\texorpdfstring{\protect\hypertarget{ux5fRef419201770}{}{\protect\hypertarget{ux5fRef420578671}{}{\protect\hypertarget{ux5fToc420589208}{}{\protect\hypertarget{ux5fToc422906999}{}{\protect\hypertarget{ux5fToc424307728}{}{\protect\hypertarget{ux5fToc426641105}{}{\protect\hypertarget{ux5fToc435434987}{}{\protect\hypertarget{ux5fToc437460820}{}{\protect\hypertarget{ux5fToc440445501}{}{\protect\hypertarget{ux5fToc440449283}{}{\protect\hypertarget{ux5fToc440551933}{}{}}}}}}}}}}}avoiding
aliased accesses to object members with member boundss suspended via a
pointer}{avoiding aliased accesses to object members with member boundss suspended via a pointer}}\label{avoiding-aliased-accesses-to-object-members-with-member-boundss-suspended-via-a-pointer}

To allow efficient compilation, it is important to require only local
analyses of aliasing behavior and to avoid requiring whole-program
analyses of aliasing behavior. The following conservative assumptions
are made about possible aliasing to allow local analysis:

\begin{itemize}
\item
  Variables of structure type represent distinct objects from each
  other.
\item
  Only variables that are address-taken can be have pointer aliases to
  their storage. A variable is address-taken if the \& (address-of)
  operator is used to obtain its address or the address of a member of
  the variable.
\item
  Any two pointers to structures can be aliases for the same object,
  even if the pointers point to different structure types. It is
  possible to cast from \ptrinst{\textit{S}} to
  \ptrT if \var{S} and
  \var{T} are compatible types. Autobahn Design Note 3 will cover
  pointer casts and rules for compatible types. For now, with no
  definition of compatible types, we will assume that all structure
  types are potentially compatible.
\end{itemize}

The following rules enforce that an \arrayptr\ field of an
object is not used to access memory while the type-level invariant for
the object is suspended.

We will all paths in a function that start at a point of suspension of a
type-level bounds via a pointer. The point of suspension may be a
statement with an annotation
\texttt{suspends}(\var{exp}\textgreater{}\var{identifier}\texttt{)}.
It may also be the entry to the function, if
\texttt{suspends}(\var{exp}-\textgreater{}\var{identifier}) is true on
entry to the function.

\begin{enumerate}
\item
  For every path from the suspend point, either

  \begin{enumerate}
  \item
    There must be a statement with a
    \texttt{holds(}\var{exp}-\textgreater{}\var{identifier}\texttt{)}
    annotation along the path.
  \item
    Or the path must end at an exit point of the function (a
    \texttt{return} statement, or for a \texttt{void} function that
    returns nothing, the end of the function) and the type-level
    invariant for \var{exp} must be suspended on exit to the function.
  \end{enumerate}
\item
  The limited part of the path will be defined as either

  \begin{enumerate}
  \item
    The part of path between the suspend point and the \texttt{holds}
    expression, if there is one.
  \item
    The entire path otherwise.
  \end{enumerate}
\item
  For the limited part of the path,

  \begin{enumerate}
  \item
    There cannot be a memory read or write through an
    \arrayptr\ member accessed via a structure operator
    \texttt{-\textgreater{}}.
  \item
    There cannot be a memory read or write through an
    \arrayptr\ member of an address-taken variable that was in
    scope at the point of suspension.
  \item
    Any function call must either

    \begin{enumerate}
    \item
      Take \texttt{exp} as an argument, to ensure that 3a and 3b are
      followed while the type-level member bounds is suspended for
      \texttt{exp}.
    \item
      Or the called function must be annotated as following rules 3a and
      3b above.
    \end{enumerate}
  \item
    The value of \texttt{exp} cannot change:

    \begin{enumerate}
    \item
      There cannot be an assignment to a variable used in \texttt{exp}
    \item
      exp cannot read memory that is modified by the limited part of the
      path. For now, this will be approximated the rule that
      \texttt{exp} cannot contain a pointer dereference or a function
      call.
    \end{enumerate}
  \end{enumerate}
\end{enumerate}

We also need to extend facts and checking of facts to handle equality of
pointer-dereferenced members and variables:

\var{fact} ::=

\var{exp}\texttt{-\textgreater{}}\var{identifier} == var

\var{var} \texttt{==} exp\texttt{-\textgreater{}}\var{identifier}

The following kinds of assignments invalidate these types of facts:

\begin{itemize}
\item
  Assignment through an unsafe pointer.
\item
  Assignment to any structure member through a pointer expression other
  than \var{exp}. The other expression could be an alias for the object
  pointed to by \var{exp}. This can happen even if the other expression
  involves a different struct type than \var{exp}.
\item
  Any assignment to a member of an address-taken variable. \var{exp}
  could be an alias for the address-taken variable.
\end{itemize}

\section{Examples}\label{examples-1}
\section{Loosening restrictions with better alias information}\label{loosening-restrictions-with-better-alias-information}

\chapter{Reasoning about bounds and simple program invariants}

Programmers and compilers will need to reason about bounds as variables
are modified. In doing so, they will also need to reason about simple
program invariants. This section introduces extensions to C to support
reasoning about program invariants.

There are a variety of reasons why programmers and compilers may need to
reason about bounds:

\begin{itemize}
\item
  A programmer may wish to narrow the area of memory that can be
  accessed via an array pointer by modifying the bounds of the pointer.
\item
  A programmer may introduce a temporary variable and may wish to
  re-express existing bounds in terms of that new variable.
\item
  A programmer may write a loop that depends on a variable with bounds
  and also modifies one or more variables used in those bounds. Some
  simple reasoning may be needed to show that the loop body preserves
  the bounds.
\item
  A programmer may do a dynamic check to ensure that a bounds can be
  satisfied.
\item
  A compiler may need to check that the arguments to a function call
  satisfy the bounds requirements of the function parameters.
\item
  A programmer may want to write performance-critical code that is free
  of dynamic bounds checks. The programmer may introduce checks outside
  the performance-critical code that guarantee no dynamic checks are
  needed. The compiler may need to check that the bounds are statically
  satisfied in the performance-critical code.
\end{itemize}

We incorporate reasoning about bounds into the language because checking
the correctness of bounds statically is often the only practical choice.
If we were to ignore the correctness of the reasoning about bounds, we
would have to track the bounds for all pointer values dynamically to
ensure correct operation of programs. C programs often operate at such a
low level in the system that there may be no practical way to do this.

Because the reasoning about bounds is part of the language, compilers
will check the correctness of the reasoning, just as they check the
correctness of types. They must do so predictably and efficiently. Two
compilers for C with these extensions should always produce the same
answer. Compile times should be relatively unaffected and checking
should scale to code bases with millions of lines of code. This rules
out incorporating program verification techniques that are
heuristic-based or computationally expensive.

The computational limits for production compilers are severe. For
production compilers, compiler developers aim for algorithms that are
O(N) or (N lg N) time in terms of the size of a method or a program.
Compilers may encounter methods may have hundreds of thousands of lines
of code and whole programs that have millions of lines of code.
Production compiler developers use O(N\textsuperscript{2}) time
algorithms for individual functions only with great care, typically
including code to disable an algorithm, reduce precision, or switch to
an alternate algorithm that has better behavior at the expense of
producing worse code.

To handle the computational limits of compilers, we view the compiler's
job as one of proof checking. The compiler will check that individual
steps in a proof are correct. It will do limited inference in the
process of checking those steps. It will not try to infer which of the
many possible facts about a large method are relevant; the programmer
will need to state the relevant facts to use in inference.

\section{Facts about program points}

We start with facts about program points that a programmer may use to
reason about bounds. A fact is a bounds declaration or a relational
statement about a variable and a non-modifying expression:

\var{fact: }

\begin{quote}
\var{bounds}

\var{var relop non-modifying-exp}

\var{range-exp relop var}
\end{quote}

where \var{relop} is one of \textless{}, \textless{}=, ==, !=,
\textgreater{}=, \textgreater{}. Recall that range-expressions are a
subset of C expressions restricted to variables, constant expressions,
and addition, subtraction, and address-of operations. The variable and
non-modifying expression in a fact must have pointer types or integral
types.

Facts may be declared at expression statements or in parameter lists
using \keyword{where} clauses. For expression statements, the compiler
will check that the where clause is true using the facts true before the
expression statement and the effect of the expression. For a parameter,
the where clause becomes a precondition that must be true at the call
site. The compiler will check this precondition at the call sites. The
grammar for where clauses is generalized to:

\var{expression-statement}:

\begin{quote}
\var{expression\textsubscript{opt}}\texttt{;}

\var{expression\textsubscript{opt} where-clause}\texttt{;}
\end{quote}

\var{where-clause}:

\begin{quote}
\keyword{where} \var{facts}
\end{quote}

\var{facts}:

\begin{quote}
\var{fact}
\end{quote}

\var{act} \texttt{\&\&} \var{facts}

The expression can be omitted, in which case a where clause may stand on
its own as a set of invariants and bounds declarations:
\begin{verbatim}
where x>=0 && x<=10;
\end{verbatim}

Facts are automatically inferred for the clauses of if-statements and
the cases of switch statements. For if-statements, the test has to have
the form of a fact. For a switch statement, the fact is deduced from the
switch expression and the case statement:

Here are some simple examples where the fact created by a control-flow
statement is explicitly declared using a (redundant) where clause:

\begin{verbatim}
if (x < 5) {
    where x < 5;
}
else {
    where x >= 5;
} 

switch (x) {
    case 0: {
        where x == 0;
        break;
    }
    case 1: {
        where x == 1;
        break;
     }   
    default: {
        where x != 0 && x != 1;
        break;
    }
}
\end{verbatim}

Here is a simple example that introduces a fact that i is always
\textgreater{}= 0:

\begin{verbatim}
int sum10(array_ptr<int> buf where bounds(buf) == (buf, buf + 10)) {
    int sum = 0;
    int i = 0
    where i >= 0;
    while (i<10) {
        sum += buf[i];
        i = i + 1
        where i >= 0;
    }
}
\end{verbatim}

From this fact, it can be deduced that the access to buf is always in
range. A where clause can be used double check this:

\begin{verbatim}
int sum10(array_ptr<int> buf where bounds(buf) == (buf, buf + 10)) {
    int sum = 0;
    int i = 0
    where i >= 0;
    while (i<10) {
        where (i>= 0 && i<10);
        sum += buf[i];
        i = i + 1
        where i >= 0;
    }
}
\end{verbatim}

\section{Checking facts}

The compiler checks facts in a \keyword{where} clause by gathering known
facts before an assignment statement and checking that the facts
declared in the \keyword{where} clause can be inferred (easily) from
known facts and the effect of the assignment statement. The compiler
finds known facts by examining each path from the beginning of the
function to the statement and identifying facts that are true along all
paths. Facts are introduced by where clauses and control-flow
statements. Facts are removed by assignments to any variable in a fact.

A programmer can find the facts that are available before an assignment
statement by looking at assignments that precede the statement. The
programmer usually only has to look at assignments to variables in the
where clause for the assignment statement. The programmer can then check
the facts along all paths from those assignments to the statement.

This analysis of facts available before a statement is similar to the
``available expression'' analysis done by optimizing compilers for
common-subexpression elimination. For common-subexpression elimination,
a compiler looks at all expressions. For analyzing available facts, a
compiler only looks at expressions in where clauses or inferred from
control-flow statements.

\subsection{Algorithm for checking correctness of facts}\label{algorithm-for-checking-correctness-of-facts}

To infer whether a fact is true in a where clause, the compiler first
computes the set of facts that are true after the expression statement.
We describe the common case where the expression is an assignment of the
form x:= e1.

\begin{enumerate}
\item
  If e1 is invertible and must have a well-defined value (cannot
  overflow or fails on overflow), the compiler takes the facts true
  before the statement and substitutes the inverse expression of e1 for
  any occurrences of x in the facts.
\item
  If e1 is not invertible or may not have a well-defined value, the
  compiler takes the facts before the statement and removes any facts
  where x occurs.
\item
  If e1 is a valid non-modifying expression, the compiler adds the fact
  x == e1 to the set of facts.
\end{enumerate}

For variables that are declared to be equal, the compiler chooses one of
them as the representative variable and substitutes it for all the other
variables. That is, given x == y and y == z, the compiler chooses one of
the variables (say, x) and substitutes it for y and z. The compiler
applies this substitution to both the set of facts and the fact that is
being checked.

The compiler then reduces the set of relational operators to the set
\textless{}, \textless{}=, ==, and != by swapping operands and replacing
\textgreater{} and \textgreater{}= with \textless{}= and \textless{}
instead.

The compiler then puts each bounds declaration into a normal form so
that syntactic identity can be used to compare facts. For example,
operands for addition operations are commuted so that constant operands
appear first, followed by the remaining subexpressions in lexicographic
order. Integer subtraction a -- b is turned into a + (-b). Additions
with only constant operands are simplified and algebraic identities for
addition and subtraction such as x + 0 are applied

The compiler next checks if the fact being checked is in the set of
facts. If it is not, it applies transitivity rules involving
\textless{}, \textless{}=, and ==. It also checks to see if \textless{}
implies != is true, and if \textless{}= and \textgreater{}= imply ==.

\subsection{Bounds declarations and facts}\label{bounds-declarations-and-facts}

Bounds declarations are treated the same way as other facts. During the
checking process, the same simplifications that are applied to other
facts are applied to the right-hand side bounds expressions: the
compiler chooses representative variables and puts the non-modifying
expressions that make up a bounds expression into normal forms.

The rules for checking bounds declarations include rules for
transitivity. For x : bounds(e1, e2), if e1 \textless{}= e3, then e3 can
be substituted for e1. If e4 \textless{}= e2, e4 can be substituted in
e2. For x : count(e1), if e2 \textless{}= e1, e2 can be substituted for
e1.

\subsection{Pointer arithmetic and facts}\label{pointer-arithmetic-and-facts}

The rules used to check facts include the identities x \textless{} x + k
for positive k and x + k \textless{} x for negative k, where k is a
constant and x is a new pointer type (\ptr\,
\arrayview, or \arrayptr). These identities are true
because pointer arithmetic overflow is defined as a runtime error for
these pointer types. This guarantees that adding x and k produces either
an in-range value or a runtime error (no value).

\subsection{Integer arithmetic and overflow}\label{integer-arithmetic-and-overflow}

Integral arithmetic may overflow. This consequence of that is that the
rules used to check facts do not include the identities x \textless{} x
+ k for positive k and x + k \textless{} x for negative k, where k is a
constant and x has an integral type. These identities are not true in C
because the computation x + k may overflow. According to C language
rules, program behavior is undefined in that case.

To use these identities for integers, the compiler needs to prove for
positive k that x + k \textless{}= MAXINT and for negative k that MININT
\textless{}= x + k. There are four rules that can be used to prove this:

\begin{itemize}
\item
  Given an integer c and a positive integer k, if x \textless{}= c and c
  + k \textless{}= MAXINT, then x + c \textless{}= MAXINT.
\item
  Conversely, given an integer c and a negative integer k, if c
  \textless{}= x and c + k \textgreater{}= MININT, then x +
  k\textgreater{}= MININT
\item
  Given x \textless{} y, where y is any variable, then x + 1
  \textless{}= MAXINT
\item
  Conversely, given x\textgreater{}y, where y is any variable, then x-1
  \textgreater{}= MININT
\end{itemize}

To determine whether an expression e is invertible, the compiler uses
the facts that are true before the expression to prove that MININT
\textless{}= e and e \textless{}= MAXINT.

Note that to invert an integer expression, the compiler also needs to
prove that it cannot overflow.

\subsection{Checking function calls}\label{checking-function-calls}

A function call is checked by substituting the actual parameters for the
formal parameters and checking that the where clauses are true, given
the facts true before the call. For the where clause for the returned
value, the actual parameters are substituted for the formal parameters.
The facts in the clause are then added to the set of facts true after
the call. The programmer still has to declare any interesting facts.

\subsection{Avoiding bounds checks at runtime}\label{avoiding-bounds-checks-at-runtime}

It can be important to avoid dynamic bounds checks at runtime. The
built-in method in\_bounds(e1) can be used to do this. It can be applied
to expression of type \arrayptr. At compile time, the compiler
checks that the bounds expressions for e1 are always true given the
facts true before the evaluation of e1. At runtime, in\_bounds(e1)
simply returns the value of e1. Compilers generate code for
*in\_bounds(e1) with no dynamic bounds checks. The prior example can be
written as:

\begin{verbatim}
int sum10(array_ptr<int> buf where bounds(buf) == (buf, buf + 10)) {
    int sum = 0;
    int i = 0
    where i >= 0;
    while (i<10) {
        sum += *in_bounds(buf + i);
        i = i + 1
        where i >= 0;
    }
}
\end{verbatim}

\section{Examples}

Here is a simple example of capturing the lower bounds of an
\arrayptr\ variable using another variable:

\begin{verbatim}
int sum(array_ptr<int> buf : bounds(buf, end), 
         array_ptr<int> end) {
    array_ptr<int> tmp = buf;
    where buf : bounds(tmp, end); // substitute tmp for buf
    int sum = 0;
    while (buf < end) {
        sum += *buf;   
        buf = buf + 1; // buf bounds do not change, do not need to be redeclared
    }
    return sum;
}
\end{verbatim}

Here is a more complicated example where \texttt{buf} is incremented
\emph{and} \texttt{buf} is the lower bound:

\begin{verbatim}
int sum(array_ptr<int> buf : bounds(buf, end), 
        array_ptr<int> end) {
    int sum = 0;
    while (buf < end) {
        sum += *buf;   
        buf = buf + 1
        where buf : bounds(buf, end);
    }
    return sum;
}
\end{verbatim}

Here are the steps that the compiler goes through, illustrated using a
where statements. First, the compiler computes the facts true after
\texttt{buf = buf + 1}. The compiler computes the inverse expression for
\texttt{buf + 1}, which is \texttt{buf - 1}. It substitutes it into the
bounds expression that is true before the increment, producing the set
of facts after the increment of \texttt{buf : bounds(buf -- 1, end)}:

\begin{verbatim}
int sum(array_ptr<int> buf : bounds(buf, end), 
        array_ptr<int> end) {
    int sum = 0;
    while (buf < end) {
        sum += *buf;   
        buf = buf + 1
        where buf : bounds(buf - 1, end); 
    }
    return sum;
}
\end{verbatim}

The next step is for the compiler to show that that \texttt{buf :
bounds(buf - 1, end)} implies \texttt{buf : bounds(buf, end)}. The
transitivity rule for bounds expressions implies that the compiler must
show buf -- 1 \textless{}= buf. This follows from the identity x -- k
\textless{} x, completing the validation of the bounds expression:

\begin{verbatim}
int sum(array_ptr<int> buf where bounds(buf) == (buf, end), 
        array_ptr<int> end) {
    int sum = 0;
    while (buf < end) {
        sum += *buf;   
        buf = buf + 1
        where bounds(buf) == (buf, end) 
    }
    return sum;
}
\end{verbatim}

\chapter{Bounds for pointer referents that are \arrayptr\ types}
\label{bounds-for-pointer-referents-that-are-arrayux5fptr-types}

\emph{\texttt{Under construction -- do not bother reading this yet.}}

A program may have pointers to \arrayptr s. These pointers will be the
addresses of locations that contain \arrayptr\ s. The \arrayptr\ values
stored in those location must have bounds declared in order to be used
to access memory.

Here are some examples of variable declarations of pointers to
\arrayptr s:
\begin{verbatim}
array_ptr<array_ptr<int>> x;
ptr<array_ptr<int>> y;
\end{verbatim}

The \arrayptr\ values stored at that location must have bounds
declared in order to be used to access to memory. The pointer itself may
be a \ptr\ or an \arrayptr.

We will use the terminology `pointer referent' to describe the value
stored at an address given a pointer.

\chapter{Lessons from Existing Research}\label{lessons-from-existing-research}

There has been substantial research on showing the correctness or type
safety of C programs with pointer arithmetic. The research is a
combination of applied type theory, program logics, program
verification, and dynamic techniques that can be used when static
checking becomes too complicated. The research has not been productized
by industry, even though flaws in C and C++ programs have caused
widespread, costly security problems \emph{(to do: citation).} What
lessons can we learn from existing research?

CCured uses whole-program static analysis to identify different uses of
pointers in C programs. It identifies pointers that are used to read or
write values only (safe pointers), pointers that are used in pointer
arithmetic also (sequence pointers), and pointers that are involved in
possibly non-type safe casts (wild pointers). It uses a multi-machine
word representation for sequence pointers and wild pointers. It also
changes the representation of data pointed to by wild pointers. This
changes data layouts and causes interoperation problems. The CCured
results clear show that many pointers are never used with pointer
arithmetic. It suggests that new types of pointers should be introduced
into C for pointers that have different safety requirements. This would
be an easy and low-risk way to improve the safety of C programs.

Deputy uses dependent types to avoid runtime layout changes in pointers
involved in pointer arithmetic. The dependent types allow the bounds of
the pointers to be specified as part of the types of the pointers and
the bounds to depend on runtime values. Deputy requires programmers to
annotate function parameters, data structures, and global parameters
with dependent types. It then infers dependent type annotations for
local variables and adds runtime checks to make the dependently-typed
program type check. The runtime checks enforce that pointer values stay
in bounds. The checks apply to pointer arithmetic and pointer
dereferencing.

Havoc goes beyond Deputy and allows types to be combined with program
verification. It allows a programmer to specify program invariants that
imply type safety and can verify these invariants statically. It can
handle unsafe code such as using a pointer to a field to access a prior
field in a data structure.

There are some high-level conclusions that we can draw from these
systems. First, it is not feasible in practice to require widespread
data layout changes, as CCured did. Second, this means that use of
program invariants and/or runtime system support will be required to
establish that pointer uses are in bounds. Third, it can be arbitrarily
hard to show the type safety statically of unsafe low-level systems
code. The code may be safe at runtime. A programmer may intuitively know
that it is safe and be able to argue informally for correctness.
However, writing down the invariants may be hard and may require deep
knowledge of program verification techniques. It may also lead to
invariants that are longer and more complicated than the original code.
It may be better for a programmer to just rewrite the code to be type
safe.

Extensions for safe pointer operations will require a trade-off between
dynamic techniques for checking pointer bounds (which are easy to reason
about and understand, but require data layout changes) and static
techniques (which may not be easy to reason about and understand, but do
not require data layout changes).

We can draw the following chart of principles versus techniques:

\begin{longtable}[c]{@{}lll@{}}
\toprule
& Dynamic techniques & Static techniques\tabularnewline
\midrule
\endhead
Minimal & \texttt{Yes} & \texttt{No}\tabularnewline
Succinct and clear & \texttt{Yes} & \texttt{Sometimes}\tabularnewline
Incremental & \texttt{No} & \texttt{Yes}\tabularnewline
\bottomrule
\end{longtable}

One concern about the work is that the more applied work, such as
CCured, Deputy, and SAL, has not been adopted by programmers
enthusiastically. SAL is widely used within Microsoft because it is a
mandated part of the software development process, not because
programmers are enthusiastic about it. It has not been adopted widely
outside of Microsoft. It is unclear why these approaches have not been
adopted. There are many plausible possible reasons, including inertia,
lack of a product-quality toolchain, lack of perceived benefit relative
to the effort, and perhaps being difficult to use. It is important to
aim for something that programmers like. When we are facing design
choices, we recommend using user studies of programmers to evaluate the
choices, instead of relying on hunches or opinions.

\section{Using dependent types to enforce checking of pointer bounds}\label{using-dependent-types-to-enforce-checking-of-pointer-bounds}

Deputy adds dependent types to C to specify and track pointer bounds. A
dependent type is a type that may depend on a value at runtime.
Dependent types are built using type constructors that are applied to
types and values. The type constructors capture specific properties of
runtime values. For example, Deputy introduces a type constructor
\verb|Array| that can be applied to an integer value (the length of the
array) and an element type. \verb|Array 5 int| describes the type of
integer arrays with 5 elements. The \verb|Array| type constructor can be
applied to a program variable or an expression, so the type can depend
on a runtime value. For example, \verb|Array n int| describes the type
of integer arrays with n elements.

The following example illustrates the use of dependent types in Deputy.
It is adapted from Figure 3 of the Deputy OSDI paper , which in turn was
adapted from the Deputy version of the Linux e1000 network card driver.

The example has an annotation on the \texttt{buffer\_info} field of
\texttt{e1000\_tx\_ring}. The annotation means that
\texttt{buffer\_info} points at an array element and that at least
\texttt{info\_count} elements are valid (specifically, it is valid to
access memory between \texttt{buffer\_info} and \texttt{buffer\_info +
info\_count -- 1}). This information is part of the type of
\texttt{buffer\_info}.

The type checking rule for adding a pointer of \verb|Array| type with an
integer requires that the integer value be in bounds for the array. To
type check \texttt{tx\_ring-\textgreater{}buffer\_info[i]}, the type
checker must show at compile time that \texttt{i \textgreater{}= 0} and
\texttt{i \textless{}= tx\_ring-\textgreater{}count}. In general, taking
an arbitrary program and establishing equality between runtime values at
compile time is undecidable, which means that type checking would be
undecidable. To make type checking decidable, Deputy examines statements
whose type checking rules require establishing facts at compile-time
that involve runtime values. Deputy systematically inserts run time
checks that establish the relationships are true before the statements.
If a relationship between runtime values is not true, the checks cause
the program to fail at run time. Of course, these runtime checks can be
eliminated by later optimization. In this specific case, the compiler
injects a runtime check \verb|assert(0 <= i && i < tx\_ring->info\_count);| into the program. 
In the example, the runtime checks are italicized assert statements.

\begin{alltt}
struct e1000_tx_ring \{
    ...
    unsigned int info_count;
    struct e1000_buffer * count(info_count)
        buffer_info;
    ...
\};

static boolean t
e1000_clean_tx_irq(
    struct e1000_adapter *adapter,
    struct e1000_tx_ring *tx_ring)
\{
    ...
    \textit{assert(tx_ring != NULL);}
    spin lock(&tx_ring->tx_lock);
    ...
    i = tx_ring->next_to_clean;
    \textit{assert(0 <= i && i < tx_ring->info_count);}
    eop = tx_ring->buffer_info[i]
    .next to watch;
    ...

    spin unlock(&tx_ring->tx_lock);
\}
\end{alltt}

\section{Problems with making c function bodies dependently type }\label{problems-with-making-c-function-bodies-dependently-typed}

C function bodies need to be rewritten to use dependent types and to be
properly typed according to dependent typing rules. Local pointer
variables must be modified to be dependently-typed. As explained
earlier, this means that runtime checks must be added to the code.
Dependently-typing local pointer variables also requires the addition of
computations to track array bounds and local variables to hold the
results of those computations.

Deputy proposes the use of an inference and rewriting step for C
function bodies automatically during compilation to make C function
bodies dependently-typed. Deputy takes a C program, does inference, and
rewrites the programs so that local variables are properly
dependently-typed. Deputy is able to do this automatically given
programs where method parameters, data structures, and global variables
are annotated with dependent types. Deputy introduces local variables
and computations to track missing dependent information. It also
introduces runtime assertions that check that pointers remain within
range. It is an impressive technical feat that this can be done
automatically.

The rewriting step, however, breaks the principle of preserving the
efficiency and control of C. It introduces computations into the program
that may have significant cost and that are not under programmer
control. For C, it is highly desirable that programmers control the
computations that are added to programs to enforce bounds checking. The
rewriting step also potentially violates the principle of clarity
because understanding program failures may require understanding these
computations.

The following code example from Figure 1 of the Deputy ESOP paper shows
this. Here is the original code:
\begin{verbatim}
int sum (int * buf, int * end) {
    int sum = 0;
    while (buf < end) {
        sum += * buf;
        buf = buf + 1;
    }
    return sum;
}
\end{verbatim}

Here is the Deputy-generated code, assuming that the function parameters
are annotated with dependent types. The new code inserted by Deputy has
been italicized:

\begin{alltt}
int sum (int * count(end - buf) buf, int * end) \{
    int sum = 0;
    while (buf < end) \{
        \textit{assert(0 < end - buf);}
        sum += * buf;
        int tmplen = (end - buf) - 1;
        \textit{assert(0 <= 1 <= end - buf);}
        int * count(tmplen) tmp = buf + 1;
        \textit{assert(0 <= end - tmp <= tmplen);  // how to explain this failure??}
        buf = tmp;
    \}
    return sum;
\}
\end{alltt}

The program now has computations of \texttt{end -- buf} and \texttt{end
-- tmp} that track the bounds of the array \texttt{buf}. A C programmer
would not expect instructions for these computations to be injected into
the program. This makes the program less efficient and these
instructions are also not introduced under programmer control. In
addition it might be difficult for a programmer to understand a bounds
failure in this program at runtime when the failure involves a
synthesized expression such as \verb|end - tmp <= tmplen| that did not
exist in the original source code.

The conclusion is that the automatic inference and rewriting during
compilation that Deputy does is not appropriate for C. We will not do
this in Autobahn.

\section{Problems with dependently-typed C}\label{problems-with-dependently-typed-c}

We have ruled out using an automatic inference and rewriting step during
compilation. If we want to use dependent types to enforce bounds
checking in C, this means that programmers will have to write code
directly in a variant of C that is dependently-typed. It would be
possible to use a Deputy-like to automatically rewrite existing C
programs into this dependently-typed C, provided that dependent-type
annotations have been provided for parameters, global variables, and
data structures. Code could be converted and then programmers could
continue developing their software in a dependently-typed C.

There are several problems with using a dependently-typed variant of C
directly for programming. First, dependent types are a big change to the
C type system and C type checking. Dependent types are a rather abstract
concept that may be hard for many programmers to understand. Even if
programmers can understand dependent types, type checking now becomes a
complicated exercise: to type check a dependently-typed statement, the
type checker must prove that certain runtime invariants are true before
the statement. To illustrate this, consider the type checking rule for
variable assignment from the Deputy paper (\emph{add citation)}. This
rule requires that the type checker prove that certain invariants must
be true at runtime before the statement. Type checking becomes entangled
in general reasoning about program invariants.

Second, dependent types do not interact nicely with imperative
programming. The program always has to be well-typed according to
dependent-typing rules. To address this, Deputy introduced a programming
operator that may seem odd to a C programmer: a new parallel assignment
operator.

Consider a structure with a pointer field whose size depends on another
field:
\begin{verbatim}
struct S {
   int * count(len) arr;
   int len;
}
\end{verbatim}

If there is a local variable of type S, neither field of the variable
can be updated independently of the other field:

\begin{verbatim}
S y;
int * count(5) tmp = malloc(sizeof(int) 5);
y.arr = tmp;
y.len = 5;
\end{verbatim}

The assignment to y.arr will fail to type check because y.len is
out-of-date. Reversing the order of assignments does not help. The
solution in Deputy was to introduce a parallel assignment operator. This
is just a specific instance of the problem of initializing a data
structure that satisfies an invariant. In an imperative language,
programmers expect to be able to initialize a data structure using
several assignments and only assert an invariant at the end of
initialization.

Finally, using dependent types makes programs too verbose: explicit
checks to enforce safety have to be inserted all over the code. To our
knowledge, there are no widely-used languages with array-bounds checking
that requires this level of verbosity. In Java and C\#, the checks are
implicitly done. This was the case in older languages such as FORTRAN
and Pascal, as well.

The conclusion is that dependently-typed C is not a good idea. Given
that dependent typing is just one way of enforcing program invariants,
it suggests that we should explore other ways to enforce program
invariants necessary for bounds safety for C.

\section{Tracking pointer bounds dynamically}\label{tracking-pointer-bounds-dynamically}

A requirement that local variable array bounds be tracked by program
invariants could lead to many invariants. The Deputy authors observe
that the Deputy inference algorithm for local variables produces a
result similar to fat pointers: ``Deputy introduces a fat representation
for locals, whereas for data structures, function parameters, and global
parameters, the programmer must specify how to compute the metadata from
data already existing in the program.'' The bounds for a pointer are
tracked explicitly using other local variables. This suggests that fat
pointers could be used as an alternative to program invariants for local
variables, in cases where using program invariants makes code too
verbose and there is not a constraint on data layout.

Suppose there is a \arrayview\ type constructor where
\arrayview\ is a struct that has a pointer field and lower and
upper bounds on the valid range of memory associated with a pointer.
\arrayview\ values can be used where pointer values can be
used, with safety checks added for various operations. Consider the
original example in Section 12.2. Here is the code for the method using
\arrayview .

\begin{verbatim}
int sum (int * count(end - tmpbuf) tmpbuf, int * end) {
    array_view<int> buf = new array_view(tmpbuf, tmpbuf, end);
    int sum = 0;
    while (buf < end) {
        sum += *buf;   // checks that buf is in  bounds before dereferencing it        
        buf = buf + 1; // new struct with updated pointer, same bounds
    }
    return sum;
}
\end{verbatim}

Appendix A illustrates how optimizing compilers can make using local
variables of type \arrayview\ efficient.

\section{Summary of lessons}\label{summary-of-lessons}

It is clear from the CCured results that many C pointers are never used
with pointer arithmetic. This suggests strongly that new types of
pointers should be introduced into C for pointers that have different
safety requirements. This would be an easy and low-risk improvement to
the safety of C programs.

For pointers where pointer arithmetic is allowed, a combination of
dynamic and static techniques will be needed to ensure safe pointer
operations. Dynamic techniques that change pointer representations allow
succinct and clear code, at the expense of changing data layout and
causing problems with interoperation and likely efficiency. Static
annotations allow programmers to express bounds information for existing
data structures and parameters and support interoperation. The use of
static annotations for local variables is not required: automatic
inference and insertion of computations to maintain bounds information
and check bounds can be done instead. However, the inference and
automatic insertion of computation compromises the control, efficiency,
and clarity desired by C programmers. This suggests that this approach
should not be used. A more suitable approach for C seems to be to embed
the bounds information for local variables directly into programs.

Static annotations that introduce the complex notion of dependent types
into C programs are problematic. We should explore other formulations of
programs invariants may fit better with C.

\chapter{Experience applying to this to OpenSSL}\label{experience-applying-to-this-to-openssl}

\chapter{Open issues}\label{open-issues}

\section{Language and library features to be addressed}\label{language-and-library-features-to-be-addressed}

\begin{itemize}
\item
  Decide what to about null terminated arrays. Do we have special rules
  for them?
\item
  Old-style function declarations where argument list length or
  parameter/argument types could be mismatched at compile time, leading
  to undefined behavior.
\item
  Function pointers: the where clauses must become part of the signature
  of the pointer type.
\item
  Variable arguments
\item
  Pointer casts that produce incorrectly aligned pointers have undefined
  behavior, according to the C11 standard. This hole should be filled in
  for safe pointer types. For safe pointer types, we should specify
  either (1) dereferencing an incorrectly aligned pointer shall cause a
  runtime error or (2) the cast itself shall check any alignment
  requirements. For case 1, note that safe pointer arithmetic is already
  defined to preserve misalignment.
\end{itemize}

\section{Bounds and null values}\label{bounds-and-null-values}

It is troublesome that the current meaning of bounds expressions is
conditional on values not being null. From Section 4:

\begin{quote}
The meaning of a bounds expression can be defined more precisely. At
runtime, given an expression \var{e} with a bounds expression
\texttt{bounds(}\var{lb}\texttt{,} \var{ub}\texttt{)}, let the runtime
values of \var{e}, \var{lb}, and \var{ub} be \var{ev}, \var{lbv},
and \var{ubv}, respectively. The value ev will be \texttt{NULL} or have
been derived via a sequence of operations from a pointer to some object
\var{obj} with \texttt{bounds(}\var{low}\texttt{,}
\var{high}\texttt{)}. The following statement will be true at runtime:
\var{ev} \texttt{== 0 \textbar{}\textbar{} (}\var{low}
\texttt{\textless{}=} \var{lbv} \texttt{\&\&} ubv \texttt{\textless{}=}
\var{high}\texttt{)}. In other words, if \var{ev} is null, the bounds
may or may not be valid. If \var{ev} is non-null, the bounds must be
valid. This implies that any access to memory where \var{ev} \texttt{!=
0 \&\&} lbv \texttt{\textless{}=} \var{ev} \texttt{\&\&} \var{ev}
\texttt{\textless{}} \var{ubv} will be within the bounds of \var{obj}.
\end{quote}

The problem with this is that it means that e: bounds(lb, ub) does not
imply e + 4 : bounds(lb, ub). The counter-example is the runtime value
of e being 0. Let ev be the runtime value of e and ev == 0. For the
first expression, ev == 0 \textbar{}\textbar{} (low \textless{}= lbv
\&\& ubv \textless{}= high) must be true. For the second expression ev +
4 == 0 \textbar{}\textbar{} (low \textless{}= lbv \&\& ubv \textless{}=
high) must be true. This means the first expression must imply that (low
\textless{}= lbv \&\& ubv \textless{}= high) is true. It does not: (A
\textbar{}\textbar{} B) being true does not imply B.

We handle this by forbidding pointer arithmetic involving null pointers,
which requires runtime checking. However, this breaks down in the
presence of casts between integers and pointer and bitwise manipulation
of pointers. Given a variable \arrayptrint\ x,
the following two expressions should be equivalent:

\texttt{x + 1} and \texttt{(\arrayptrint) (((size\_t) x) + sizeof(int))}

When x is \texttt{0}, the first expression results in a runtime failure,
while the second does not.

This suggests that we have defined the meaning of bounds in a way such
that a ``core'' property is not captured. An alternate ``core''
definition of bounds would be:

\begin{quote}
The meaning of a bounds expression can be defined more precisely. At
runtime, given an expression \var{e} with a bounds expression
\texttt{object\_bounds(}\var{lb}\texttt{,} \var{ub}\texttt{)}, let the
runtime values of \var{e}, \var{lb}, and \var{ub} be \var{ev},
\var{lbv}, and \var{ubv}, respectively. The value ev have been derived
via a sequence of operations from a pointer to some object \var{obj}
with \texttt{object\_bounds(}\var{low}\texttt{,} \var{high}\texttt{)}.
The following statement will be true at runtime: \var{low}
\texttt{\textless{}=} \var{lbv} \texttt{\&\&} ubv \texttt{\textless{}=}
\var{high}. In other words, the bounds are always valid. This implies
that any access to memory where lbv \texttt{\textless{}=} \var{ev}
\texttt{\&\&} \var{ev} \texttt{\textless{}} \var{ubv} will be within
the bounds of \var{obj}.
\end{quote}

Then, given \texttt{object\_bounds(}\var{lb}\texttt{,}
\var{ub}\texttt{)}, we would define the meaning of \var{e} :
\texttt{bounds(}\var{lb},\var{ub}\texttt{)} as \var{e} \texttt{== 0
\textbar{}\textbar{}} \texttt{object\_bounds(}\var{lb},
\var{ub}\texttt{)}.

If we go down the path of using the introduction of
\texttt{object\_bounds} to eliminate the need to check for null pointer
arithmetic, it seems likely we will run into serious problems. It seems
like \texttt{bounds(}lb, ub\texttt{)} becomes hard (impossible?) to use
for functions that take in null pointer or a pointer to a valid object:

Consider:
\begin{verbatim}
f(array_ptr<int> x : bounds(x, x + 5) {
    array_ptr<int> y = x + 1;
    ...
}
\end{verbatim}

Let us suppose we want to declare bounds for \texttt{y}. The following
is now incorrect because \texttt{x + 1} does not fault when x is
\texttt{0} (null):

\begin{verbatim}
f(array_ptr<int> x : bounds(x, x + 5) {
    array_ptr<int> y : bounds(x, x + 5) = x + 1;
    ...
}
\end{verbatim}

To see why, suppose the runtime value of \texttt{x == 0}. The bounds
expression for x is valid at runtime: \texttt{x == 0
\textbar{}\textbar{} object\_bounds(0, 5)}. However, the bounds
expression for y is not valid. Its meaning is \texttt{1 == 0
\textbar{}\textbar{} object\_bounds(0, 5)} The first condition is false,
so the second condition \texttt{object\_bounds(0, 5)} must be true.
However, no object bounds(0, 5) has ever existed. y has not been derived
via a sequence of operations from a pointer to some object with
bounds(0, 5).

It is easier to see the problem by expanding the definition of bounds:

\begin{verbatim}
f(array_ptr<int> x : x == 0 || object_bounds(x, x + 5) {
    array_ptr<int> y : y == 0 || object_bounds(x, x + 5) = x + 1;
    ...
}
\end{verbatim}

There is another direction that seems promising, though:

\begin{itemize}
\item
  Still make safe pointer arithmetic that involving a runtime failure.
\item
  Introduce the notion of object\_bounds to handle the case where the
  bounds are known to represent bounds for a real object. This can be
  deduced from \var{e} : bounds(lb, ub) when \var{e} is non-null.
\item
  Once an expression has object\_bounds, any operation can be applied to
  the value of that expression and the resulting value still has the
  same object\_bounds annotation. We would need to have a version of
  bound expressions where relative alignment is not guaranteed.
\item
  Conversely, given \var{e} : object\_bounds(\var{lb}, \var{ub}),
  this can be used to deduce bounds(\var{lb}, \var{ub}) always.
\end{itemize}

This can be used in code that modifies bits of pointers, provided that
the pointers are non-null to start through. In general, it could be used
to track bounds through unsafe code. We could allow a pointer with
actual bounds to be converted to an integer, modified, and stored back
in a variable.

Suppose we add a modifier that allowed us to declare the
relative\_alignment that a pointer and its bounds satisfies. It could
either take a type or the keyword none. For example,
relative\_aligment(int) or relative\_alignment(none).

We could have code of the form:

\begin{verbatim}
array_ptr<int> x : bounds(x, x + 5) relative_alignment(none) = malloc(sizeof(int) * 5);
if (x ! = null) {
    array_ptr<int> y : object_bounds(x, x + 5) relative_alignment(none)  = x;
    size_t bit_pattern : object_bounds(y, y + 5) relative_alignment(none) = (size_t) x;
    bit_pattern |= 0xabcd;
    y = (array_ptr<int>) bit_pattern;
    ... *y ...  // checks that *y does not access outside of the bounds (x, x + 5);
}
\end{verbatim}

Suppose a clever programmer knows the lowest 2 bits of a pointer are
always 0 and wants to use them encode additional information about an
object:
\begin{verbatim}
struct S {
    array_ptr<int> m where m : count(10);
}
\end{verbatim}

Here is how the programmer can do this:
\begin{verbatim}
struct S  {
     array_ptr<int> m where m : bounds(m & ~0x3, m & ~0x3 + 10);
}

S set(S s) 
{
  array_ptr<int> a : bounds(a & ~0x3, a & ~0x3) relative_align(none) = s.m;
  if (a != NULL) {
    // legal because a != NULL
    where a : object_bounds(a & ~0x3, a & ~0x3) relative_align(none);
    size_t y : object_bounds(a & ~0x3, a & ~0x3) relative_align(none) = ((size_t) a) | 1;
    dynamic_assert(y & ~0x3 == a & ~0x3); // always true
    // legal by substitution of y & 0x3 for a & ~0x3
    where y : object_bounds(y & ~0x3, y & ~0x3) relative_align(none);
    // exp : object_bounds(a,b) implies exp : bounds(a,b), no matter what
    // the value of exp
    where y : bounds(y ~0x3, y & ~0x3);
    // satifies member bounds requirements
    s.m = (array_ptr<int>) y;
   }
}
\end{verbatim}

This could be condensed to:
\begin{verbatim}
S set(S s) 
{
   array_ptr<int> a : bounds(a & ~0x3, a & ~0x3) = s.m;
   if (a != NULL) {
       size_t y : object_bounds(a & ~0x3, a & ~0x3) relative_align(none) = ((size_t) a) | 1;
       dynamic_assert(y & ~0x3 == a & ~0x3);
       where y : object_bounds(y & ~0x3, y & ~0x3) relative_align(none);
       s.m = (array_ptr<int>) y;
   }
} 
\end{verbatim}

\section{Conditional bounds or disjunction}\label{conditional-bounds-or-disjunction}

We have omitted disjunction for the language of bounds expressions. We
believe that it will be needed for coding patterns that appear in
practice. Here is an example of a coding patterns:

\begin{verbatim}
    //the return buffer has bounds count(len) when *success == SUCCESS.
    int* ValidIfSuccess(int *success, int len); 
\end{verbatim}

This bounds on the return value might be written as:
\begin{verbatim}
    where return_value : *success ? bounds(none) : count(len)
\end{verbatim}

This is syntactic sugar for the expression:

\begin{verbatim}
    (*success && return_value : bounds(none)) || (!(*success) && return_value : count(len))
\end{verbatim}

It is unclear what effect allowing disjunction in logical expressions
would have on the cost of the static checking required by the system. It
is clear that allowing arbitrary sized expressions with conjunction and
disjunction would be problematic. To even check that two expressions are
equivalent, they have to be put in a normal form, either disjunctive
normal form or conjunction normal form. For some expressions, this
conversion to a normal form can lead to an exponential increase in the
number of terms.

For example, the current expressions used by the system are implicitly
in conjunctive normal form

\begin{verbatim}
exp1 && exp2 && exp3
\end{verbatim}

If we want to put a logical expression of the form
\begin{verbatim}
(x && y) || e
\end{verbatim}

into conjunctive normal form, we end up with

\begin{verbatim}
(x || e) && (y || e)
\end{verbatim}

which duplicates the expression e. A simple approach to that problem
would be to limit the size of expressions that are arguments to a
disjunction operator. We could require that disjunction only be applied
to subexpressions of size k, where k is relatively small (say 5). Size
is measured by the number of interior nodes in the expression.

 \section{Concrete syntax}\label{concrete-syntax}

\subsection{Post-condition syntax}\label{post-condition-syntax}

The current syntax for describing post-conditions places a where clause
after the function parameter list declaration:

\begin{verbatim}
f( …)
where cond1 ...
\end{verbatim}

This syntax might lead to confusion. We might want to adopt an alternate
syntax that makes this clearer. At the design discussion on 7/29/2015,
it was discovered that the group did not understand that the where
clause after the function parameter list applied to post-conditions.

Some suggestions are the keywords \texttt{on\_return} or \texttt{after}:

\begin{verbatim}
f( …)
where cond1 ...

f( …)
after cond1 ...
\end{verbatim}

\section{Discussion of optimizing bounds check and overflow}\label{discussion-of-optimizing-bounds-check-and-overflow}

We had the following discussion in Section 4.10 that distracted from the
main point of the section. It's also confusing the overflow check for x
+ c is omitted. The point of the example below is that we can make code
efficient. That deserves a fuller discussion and should be buttressed by
empirical data.

Consider as an example, z = *(x+5); where x : bounds(x, x + c). The
compiler will produce code of the form

\begin{quote}
\begin{verbatim}
assert(x != null);
t1 = x + 5;
check x + 5 for overflow
assert(t1 != null && x <= t1 && t1 < x + c);
z = *t1;
\end{verbatim}
\end{quote}

This simplifies to:

\begin{quote}
\begin{verbatim}
assert(x != null);
t1 = x + 5;
check for overflow x + 5
assert(x <= t1 && t1 < x+c);
z = *t1;
\end{verbatim}
\end{quote}

This compiler can recognize that x \textless{}= t1 is always true,
leading to:-

\begin{quote}
\begin{verbatim}
assert(x != null);
t1 = x + 5;
check for overflow of x + 5
assert(t1 < x + c);
z = *t1;
\end{verbatim}
\end{quote}

\chapter{Design choices considered but not chosen}\label{design-choices-considered-but-not-chosen}

\section{Support for \arrayptr\ and \arrayview\ pointers that are not relatively aligned}\label{support-for-arrayux5fptr-and-arrayux5fview-pointers-that-are-not-relatively-aligned}

We considered supporting the case of \arrayptr\ or
\arrayview\ pointers where pointers and their bounds are not
guaranteed to be relatively aligned. A programmer might use such
pointers in coding patterns where code strides through an array of bytes
interpreted as an array of integers or structures. Typically, the code
checks that it has not gone too far before accessing memory. For
example, given an array of bytes, a programmer may wish to replace byte
operations with aligned 32-bit operations because they are more
efficient. Extra bytes at the beginning or end of an array would be
handled using special-case code.

When bounds and pointers are not relatively aligned, the bounds checks
against the upper bound for a pointer requires extra instructions. Given
a pointer p, *p accesses the memory from p to p + sizeof(T) -- 1. Given
an upper bound \var{ub}, the upper bounds check for \var{p} becomes p
+ sizeof(T) -- 1 \textless{} ub. Note that the computation of p +
sizeof(T) -- 1 would also need an overflow check, so it would typically
result in several extra instructions, not just an extra addition.

The upper bounds check would be harder to optimize. Most programmers
would write code that strides through an array using comparison that
\var{p} \textless{} \var{ub}. The comparison \var{p} \textless{}
\var{ub} does not imply \var{p} + sizeof(T) -- 1 \textless{}
\var{ub}, so it would not be sufficient for a compiler to optimize away
the upper bounds check. A compiler would have to know that the pointer
and bounds are relatively aligned in order to eliminate the upper bounds
check. It would be hard for a compiler to prove this because that would
require interprocedural or whole-program analysis.

If all \arrayptr\ operations with bounds checks used the more
general bounds check in order to support pointers that are not
relatively aligned, there would be significantly more bounds checks in
optimized code and the checks would also be more costly.

We considered the alternative of introducing a new pointer modifier,
such as ``ragged'', that could be used with \arrayptr\
or \arrayview\ types to indicate that pointers and bounds may
not be relatively aligned. A type with the ragged modifier would have
the more costly upper bounds check. Because ragged and regular
\arrayptr\ pointers would have different bounds checking
sequences, casting away the unaligned modifier would compromise the
integrity of bounds checking. It would be illegal to cast a ragged
\arrayptr\ or \arrayview\ pointer to an
\arrayptr\ or \arrayview\ with no ragged modifier.

We chose not to add the ragged modifier to the language because it would
be adding a new type modifier to support a relatively rare situation.
This would add language complexity for little-to-no benefit in practice.
For example, code that would use this feature typically also has logic
to detect or handle leftover bytes. This logic can be adapted to compute
bounds that are properly relatively aligned.

\section{Allowing pointer variables to be assigned values with no relationship to their bounds}\label{allowing-pointer-variables-to-be-assigned-values-with-no-relationship-to-their-bounds}

We considered allowing pointer variables to be assigned pointer values
not derived in some way from the object with which their bounds are
associated. The idea would be to avoid unnecessary restrictions on
operations involving pointers and give pointers more leeway to encode
information by modifying bits in pointers.

In this approach, the meaning of a bounds expression would be defined
differently than that given in Section 4 . The meaning would be th
following. Given an expression \var{e} with a bounds expression
\texttt{bounds(}\var{lb}\texttt{,} \var{ub}\texttt{)}, let the runtime
values of \var{e}, \var{lb}, and \var{ub} be \var{ev}, \var{lbv},
and \var{ubv}, respectively. If \var{ev} is not null, there will
always exist some object at runtime with the bounds (\var{low},
\var{high}) such that \var{low} \texttt{\textless{}=} \var{lbv} \&\&
\var{ubv} \texttt{\textless{}=} \var{high}. In other words, the
requirement is that expression bounds are always a subrange of the range
of memory for some valid object. This is provided that the value of the
expression with which those bounds are associated is non-null.

The problem with this approach is that it has unexpected consequences
for the bounds that are allowed to be declared for pointer variables.
Any valid pointer bounds could be declared for a variable because there
is no longer a requirement that a pointer stored in the variable is
derived from a pointer to the object associated with the bounds. The
following example would be valid:

\begin{verbatim}
array_ptr<int> x : count(5) = malloc(sizeof(int) * 5);
array_ptr<int> y : bounds(x, x + 5) = malloc(sizeof(int) * 2);
\end{verbatim}

Because the bounds are disassociated from the actual pointer values,
there is much more potential for errors to be made by programmers that
are only detected at runtime. This approach was not pursued further for
this reason.

\section{Address-of and array-to-pointer conversion always produce safe pointer types}\label{address-of-and-array-to-pointer-conversion-always-produce-safe-pointer-types}

We considered a designed where the address-of operator (\&) and
array-to-pointer type conversion always produced safe pointers. To
preserve compatibility with existing C code, we introduce implicit
conversions from safe pointers to unsafe pointers. We found that we were
not able to preserve backwards compatibility for the address-of operator
and that implicit array-to-pointer conversions required bounds checking.

\subsection{Proposed rules for an address-of operator that produces safe pointer type.}\label{proposed-rules-for-an-address-of-operator-that-produces-safe-pointer-type.}

The address-of operator (\texttt{\&}) applied to an lvalue expression of
type \var{T} would produce a value of type
\ptrT.

Existing C code expects the address-of operator to produce a \var{T} *.
To allow most code to compile without changes, we add an implicit cast
rule: \ptrT can be cast
implicitly to a \var{T} * in those situations where a \var{T}
\texttt{*} type is expected, except for pointer arithmetic operators
that add or subtract a pointer and an integer. Those situations include
pointer assignment, arguments to function calls, return statements, and
conditional expressions. In all these situations a \var{T} \texttt{*}
type must have been declared explicitly in the code already, so this
implicit cast does not introduce unsafe pointer types where none existed
before.

Pointer arithmetic operators are excluded to avoid the silent
introduction of unsafe pointer types and to preserve the value of having
the \ptrT type. If
there were always an implicit cast from \ptrT to \var{T} \texttt{*},
then any expression that uses pointer arithmetic could do pointer
arithmetic on \ptrT
values.

Code takes the address of an array element and immediately does pointer
arithmetic will still fail to type check, introducing a potential
backward compatibility issue:
\begin{verbatim}
f()
{
    int a[10];
    int *x = &a[0] + 5; // &a[0] has type ptr<T>.  Pointer arithmetic is not allowed
    ...
}
\end{verbatim}

We expect this kind of code to be rare because the succinct style is to
use \texttt{a} instead of \texttt{\&a[0]}, but is nonetheless a
possibility, so this proposal still violates the principle of not
changing the meaning of existing C code.

\begin{verbatim}
f()
{
    int a[10];
    int *x = ((int *) &a[0]) + 5; // redundant but OK under old rule
    …
}
\end{verbatim}

\subsection{Proposed rules for conversion of array types to pointer types}\label{proposed-rules-for-conversion-of-array-types-to-pointer-types}

Array types may be complete or incomplete. A complete array type
specifies the number of elements in the array using a constant
expression. In incomplete array type does not specify the number of
elements in the array. Examples of complete array types are int[10]
and int[10][10]. Examples of incomplete array types are
int[] and int[][10].

If the type of an expression or a subexpression is an ``array of
\var{T}'', the following rules would apply. If the array is a complete
type, the type of the expression is altered to
\arrayptrT . If it is
an incomplete type, the type of the expression is altered to \var{T} *.
This alteration does not happen if the expression is an operand of an
address-of operator, \texttt{++}, \texttt{-\/-}, \texttt{sizeof}, or the
left operand of an assignment operator or the `\texttt{.}' operator.

These rules would have an interesting effect for arrays of complete
types: all array references involving those arrays would be bounds
checked. Any address computations involving those arrays will be checked
for overflow also. Because the existing C language definition leaves
out-of-bounds access of arrays of complete type undefined, as well as
the meaning of overflowing address computations undefined, this is
compatible with the existing C language definition.

However, these rules by themselves are problematic for existing C code.
It is common in C code to use array types interchangeably with pointer
types. The rule that complete array types are converted to
\arrayptr\ types could cause problems for such code

\begin{verbatim}
f(int *arg, int len)
{ 
   ...
}

g() {
   int x[10];
   f(x, 10);
}

h() {
   int x[10];
   int *ptr = x;
   f(ptr, 10);
}
\end{verbatim}

To allow existing code to continue to compile unchanged, we adopt the
rule that an \arrayptrT\ can be
implicitly cast to a \var{T} * in situations where a T * type is
expected. Those situations may include pointer assignment, arguments to
function calls, return statements, and conditional expressions. For
conditional, expressions of the form exp1 \texttt{?} exp2 \texttt{:}
exp3, the implicit coercion occurs when exp2 or exp3 has type T * and
the other expression has type
\arrayptrT. These situations do not
include array references and adding or subtracting a pointer type and an
integer. \arrayptrT\ is an acceptable
type for those operations and a coercion to T * is not needed.

We allow \arrayptr\ values to not be within bounds. Because of
this, any implicit conversion of an \arrayptr\ value with a
bounds to an unsafe pointer type must be bounds checked. Otherwise, it
is easy to write ``safe'' code that creates undetected buffer overruns:

\begin{verbatim}
// f looks safe, but does something bad that is undetected before calling unsafe code
f(array_ptr<int> p where bounds(p) == (p, p + 10))
{
    // first argument implicitly converted to int *
    poke(p + random_large_value(), 31415);  
}

void poke(int *p, int val)
{
    *p val
}
\end{verbatim}

The silent introduction of a bounds check at a call to a method violates
the design principles of control and clarity. The implicit conversion
introduces an invisible failure point in a program where one does not
otherwise exist. Pointer arithmetic is not normally bounds checked, so
it is not expected fail.

\section{Alternate definitions of the semantics of bounds declarations}\label{alternate-definitions-of-the-semantics-of-bounds-declarations}

There are a variety of different possible definitions of the semantics
of bounds declarations. A bounds declaration has the form:

\var{bounds-decl:}

\begin{quote}
\var{x} \texttt{:} \var{bounds-exp}
\end{quote}

\var{bounds-exp:}

\begin{quote}
\texttt{count(}\var{non-modifying-exp}\texttt{)}

\texttt{bounds(}\var{non-modifying-exp}\texttt{,}
\var{non-modifying-exp}\texttt{)}

\boundsany

\boundsnone
\end{quote}

It may be attached to declarators or an assignment statement:

\var{init-declarator} :

\begin{quote}
\var{declarator inline-bounds-specifier\textsubscript{opt}
where-clause\textsubscript{opt}}

\var{declarator inline-bounds-specifier\textsubscript{opt}
where-clause\textsubscript{opt}} \texttt{=} \var{initializer
where-clause\textsubscript{opt}}

\ldots{}
\end{quote}

\var{parameter-declaration} :

\begin{quote}
\var{declaration-specifiers declarator}
\var{inline-bounds-specifier\textsubscript{opt}
where-clause\textsubscript{opt}}
\end{quote}

\var{inline-bounds-specifier:}

\begin{quote}
\texttt{:} \var{bounds-exp}
\end{quote}

\var{where-clause}:

\begin{quote}
\keyword{where} \var{facts}
\end{quote}

\var{expression-statement}:

\begin{quote}
\var{expression\textsubscript{opt}
where-clause\textsubscript{opt}}\texttt{;}
\end{quote}

The information in the bounds declaration is used at pointer
dereferences involving either (1) the variable or (2) pointers
constructed from the value of the variable.

One question is when the values of the bounds expressions in a bounds
declaration are computed. One possibility is to compute them eagerly at
the point of the bounds declaration. This make sense in that expressions
are evaluated at the point where they occur in C programs. However, a
problem with evaluating bounds expressions early is that they may fault,
even though their value is not needed.

Consider code that calls malloc, which returns null if memory cannot be
allocated. The code checks that malloc succeeded before using the
result.
\begin{verbatim}
array_ptr<int> result = malloc(size) where result : bounds (result, result + size)
if (result != NULL) {
      ... *result = ...
}
\end{verbatim}

In this case, the bounds expression result + size will fault when null
is returned. One way to think about the problem is that it is acceptable
for null pointers to have meaningless bounds expressions. They cannot be
used to access memory, after all. Of course, this is a problem if the
bounds expression causes a runtime fault. Another way to think about
this is that the problem is that the bounds expression is being
evaluated whether it is needed or not. The evaluation should be deferred
until it is definitely required.

There are currently several different definitions of extent under
consideration. The definitions differ on two axes:

\begin{enumerate}
\item
  The set of program points to which a declaration applies. The
  possibilities include:

  \begin{enumerate}
  \item
    The set of statements up to the first assignment to any variable
    used in the bounds declaration. We will name this set of statements
    the ``direct'' set
  \item
    All statements after the declaration where the variables involved in
    the declaration in scope and a new declaration has not superseded
    this definition. We will name this set the ``always'' set.
  \item
    Various sets of program points in between the two extremes of (a)
    and (b). For the sake of discussion, we will name this set the
    ``intermediate'' set.

    \begin{enumerate}
    \item
      The set of statements up to the first non-invertible assignment to
      any variable used in the declaration (an assignment is
      non-invertible if the old value of the variable cannot be
      calculated from the new variable).
    \item
      The set of statements up to the first assignment to any variables
      used in the bounds expressions in the declaration.
    \item
      The set of statements up to the first assignment where the bounds
      declaration can no longer be proved to be true (where the
      right-hand side of the bounds declaration may no longer be a valid
      range.
    \end{enumerate}
  \end{enumerate}
\item
  When the bounds expressions in a bounds declaration are evaluated. The
  possibilities being considered are:

  \begin{enumerate}
  \item
    By-value (eagerly at the point of declaration)
  \item
    By-reference (at the point of use of the variable with the variable
    declaration).
  \end{enumerate}
\end{enumerate}

Here is the matrix of different permutations:

\begin{longtable}[c]{@{}llll@{}}
\toprule
Set of program points & By-value & By-reference & General
comments\tabularnewline
\midrule
\endhead
Direct & & & By-value and by-reference evaluation is indistinguishable.
Because there are no assignments, both produce the same
result\tabularnewline
Always & Introduces hidden temporary variables that hold bounds value.
May lead to runtime failures if the lhs variable is assigned a pointer
to an object outside of the declared bounds & Modification of variables
used in bounds expressions requires declaring a new bounds for the lhs
for variable. &\tabularnewline
Intermediate & Introduces hidden temporary variables that hold bounds
value.

May lead to runtime failures if the lhs variable is assigned a pointer
to an object outside of the declared bounds. & &\tabularnewline
General comments & We would need to check that all pointer variables in
bounded expressions are non-null before evaluating bounds at
declaration.

Otherwise evaluation may fail at runtime if a variable on the right-hand
side is null. & &\tabularnewline
\bottomrule
\end{longtable}

\appendix

\chapter{Generating efficient code for local variables of type \arrayview}\label{appendix-a-generating-efficient-code-for-local-variables-of-type-arrayux5fview}

This appendix gives an example of how a compiler can generate efficient
code when \arrayview\ is used in place of \arrayptr\
for local variables. The compiler can do this by applying well-known
optimizations: inlining operations for \arrayview , replacing
struct members with local variables, copy propagation, reverse copy
propagation, and eliminating identity assignments.

Here is a possible implementation of \arrayviewT (in C++). It
uses the proposed extensions to C. The italicized assert in
\texttt{Deref} represents code that is injected by the compiler to check
the bounds at run time.

\begin{verbatim}
struct array_view<T>
{
    array_ptr<T> current;
    where bounds(current) == (low, high);

    array_ptr<T> low;
    array_ptr<T> high;
      
    array_view<T>(array_ptr<T> ptrVal 
                  where bounds(ptrVal) == (lowerBound, upperBound),
                  array_ptr<T> lowerBound, array_ptr<T> upperBound)
    {
        current = ptrVal;
        low = lowerBound;
        high = upperBound
        where bounds(current) == (low, high);
    }

    T Deref(array_view<T> av) 
    {
        array_ptr<T> tmp = av.current;
        assert(tmp>= av.low && tmp < av.high);
        return *tmp;
    }

    array_view<T> Add(array_view<T> av, int delta) 
    {
        array_view<T> tmp = av;
        tmp.current = tmp.current + delta;
        return tmp;
    }
}
\end{verbatim}

Here is a version of the sum routine where the local variable buf has
type \arrayview. This means that no bounds need to be declared
for buf.

\begin{verbatim}
int sum(array_ptr<int> argbuf where bounds(argbuf) == (argbuf, end), 
        array_ptr<int> end) {
    array_view<int> buf = new array_view(argbuf, argbuf, end);
    int sum = 0;
    while (buf < end) {
        sum += *buf;   // checks that buf is in  bounds before dereferencing it        
        tmp = buf + 1; // new struct with updated pointer, same bounds
        buf = tmp;
    }
    return sum;
}
\end{verbatim}

The compiler can inline the code for the \arrayview\ struct operations
and place struct members in local variables:
\begin{verbatim}
int sum (array_ptr<int> argbuf where bounds(argbuf) == (argbuf, end),
         array_ptr<int> end) {
    // buf = new array_view(argbuf, argbuf, end);
    array_ptr<int> buf_ptr = argbuf; 
    array_ptr<int> buf_lo = argbuf;
    array_ptr<int> buf_hi = end
    where bounds(buf_ptr) == (buf_lo, buf_hi);
    int sum = 0;
    while (buf_ptr < end) {
        array_ptr<int> tmp1 = buf_ptr
        assert(tmp1 >= buf_lo && tmp1 < buf_hi);
        sum += *tmp1;
        // array_view<int> tmp = buf + 1;
        array_ptr<int> tmp_ptr = buf_ptr + 1;
        array_ptr<int> tmp_lo = buf_lo;
        array_ptr<int> tmp_hi = buf_hi
        where bounds(tmp_ptr) == (tmp_lo, tmp_hi)
        buf_ptr = tmp_ptr;
        buf_lo = tmp_lo;
        buf_hi = tmp_hi
        where bounds(buf_ptr) == (buf_lo, buf_hi);
    }
    return sum;
}
\end{verbatim}

The compiler can then apply copy propagation and reverse copy
propagation:

\begin{verbatim}
int sum (array_ptr<int> argbuf where bounds(argbuf) == (argbuf, end), 
         array_ptr<int> end) {
    // buf = new array_view(argbuf, argbuf, end);
    array_ptr<int> buf_ptr = argbuf; 
    array_ptr<int> buf_lo = argbuf;
    array_ptr<int> buf_hi = end
    where bounds(buf_ptr) == (buf_lo, buf_hi);
    int sum = 0;
    while (buf_ptr < end) {
        assert(buf_ptr >= buf_lo && buf_ptr < buf_hi);
        sum += *buf_ptr;
        // array_view<int> tmp = buf + 1;
        buf_ptr = buf_ptr + 1;  // result of reverse copy prop
        buf_lo = buf_lo;
        buf_hi = buf_hi;
        where bound(buf_ptr) = (buf_lo, buf_hi);
    }
    return sum;

}
\end{verbatim}

It can then eliminate eliminating identity assignments:

\begin{verbatim}
int sum (array_ptr<int> argbuf where bounds(argbuf) == (argbuf, end), 
         array_ptr<int> end) {
    // buf = new array_view(argbuf, argbuf, end);
    array_ptr<int> buf_ptr = argbuf; 
    array_ptr<int> buf_lo = argbuf;
    array_ptr<int> buf_hi = end
    where bounds(buf_ptr) == (buf_lo, buf_hi);
    int sum = 0;
    while (buf_ptr < end) {
        assert(buf_ptr >= buf_lo && buf_ptr < buf_hi);
        sum += *buf_ptr;
        // array_view<int> tmp = buf + 1;
        buf_ptr = buf_ptr + 1
        where bound(buf_ptr) == (buf_lo, buf_hi)
    }
    return sum;
}
\end{verbatim}

It can do another round of copy propagation and dead-code elimination,
producing:

\begin{verbatim}
int sum(array_ptr<int> argbuf where bounds(argbuf) == (argbuf, end), 
        array_ptr<int> end) {
    // buf = new array_view(argbuf, argbuf, end);
    buf_ptr = argbuf;
    where bounds(buf_ptr) == (argbuf, end);
    int sum = 0;
    while (buf_ptr < end) {
        assert(buf_ptr >= argbuf && buf_ptr < end);
        sum += *buf_ptr;
        // array_view<int> tmp = buf + 1;
        buf_ptr = buf_ptr + 1
        where bound(buf_ptr) == (argbuf, end);
    }
    return sum;
}
\end{verbatim}

Finally, the compiler can analyze this code and realize that the assert
statement is redundant. The condition \texttt{(buf\_ptr \textless{}
end)} is redundant with the while condition. The variable
\texttt{buf\_ptr} always monotonically increases and is not subject to
overflow:
\begin{verbatim}
int sum(array_ptr<int> argbuf where bounds(argbuf) == (argbuf, end), 
        array_ptr<int> end) {
    // buf = new array_view(argbuf, argbuf, end);
    buf_ptr = argbuf;
    where bounds(buf_ptr) == (argbuf, end);
    int sum = 0;
    while (buf_ptr < end) {
        sum += *buf_ptr;
        // array_view<int> tmp = buf + 1;
        buf_ptr = buf_ptr + 1
        where bound(buf_ptr) == (argbuf, end);
    }
    return sum;
}
\end{verbatim}

The \keyword{where} clauses are static only and the compiler can erase
them from the final code:

\begin{verbatim}
int sum(array_ptr<int> argbuf where bounds(argbuf) == (argbuf, end), 
        array_ptr<int> end) {
    // buf = new array_view(argbuf, argbuf, end);
    buf_ptr = argbuf;
    int sum = 0;
    while (buf_ptr < end) {
        sum += *buf_ptr;
        // array_view<int> tmp = buf + 1;

        buf_ptr = buf_ptr + 1
    }
    return sum;
}
\end{verbatim}

\chapter{Random Fragments}\label{appendix-b-random-fragments}

Here are some fragments of ideas that need to be more fully developed.

\texttt{Incompleteness of static checking}

The invariant checking algorithm is not complete, in that there may be
invariants about the program that are true, but which the invariant
checker does not report as true. First, the invariant checker only uses
declared invariants. An invariant may be true after a particular
statement, but if it is not declared, the invariant checker may not be
able to use it for subsequent statements. If a programmer declares an
invariant x \textless{} y but neglects to declare the invariant y
\textless{} z, the checker will not be able to reason several statements
later that x \textless{} z, even though it may be true about the
program. This is a consequence of the compiler being a checker, not a
theorem prover. Second, the underlying logic used by the checker is not
complete: the invariants require first-order Presburger arithmetic,
complete with disjunction (or) because of the presence of min and max.
The logic used by the checker does not include axioms for disjunction or
min/max.

\texttt{Partial correctness}

We are pursuing a strategy of being able to prove partial correctness
when these undefined behaviors are possible. Specifically, we would
assume that some undefined behaviors do not occur in some parts of code.
We would be able to prove given this assumption that other undefined
behaviors do not occur in other parts of the program. For example, we
might assume memory allocation and type casts are in fact correct. We
might also assume that unsafe code never reads or writes through
out-of-bounds pointers. We would then be able to provide that safe code
is guaranteed to never read or write through out-of-bounds pointers.

To arrive at more complete correctness guarantees about systems, we will
use the approaches of narrowing the amount of code about which
assumptions have to be made and narrowing the types of assumptions that
have to be made (that type casts are correct and memory allocation is
correct). For example, we will narrow the amount of unsafe code so that
assumptions are needed about less and less code.

\texttt{Discussion of facts involving members}

\var{fact: }

\begin{quote}
\var{bounds}

\var{var-member-path relop range-exp}

\var{range-exp relop var-member-path}
\end{quote}

\texttt{Loop invariants and dataflow-sensitive bounds declarations}

\texttt{Array\_ptr} variables with dataflow-sensitive bounds declarations also
need loop invariants if the variables are updated in a loop. Those
invariants must be declared before the loop and cannot occur cannot
occur only within the loop, unless the loop is completely unreachable
from the beginning of the function, in which case it is dead code.

To understand why, suppose the bounds declaration only occurs in the
loop body at or after the read of a variable. There will be a path from
the beginning of the function to the read of the variable. From
condition 2 of consistency, that path must also have a bounds
declaration, which is a contradiction.

\end{document}
